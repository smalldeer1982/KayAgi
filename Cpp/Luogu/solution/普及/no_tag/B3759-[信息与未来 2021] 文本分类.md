# [信息与未来 2021] 文本分类

## 题目背景

“分类” 是人工智能中很重要的一项任务，例如区分视频中的一帧图像是否存在异常事件、辨别图片中是否有待检索的目标、划分音频中词语的分界位置等。

## 题目描述

虽然属于“人工智能”的范畴，但分类问题也可以简单理解成是一个计算机函数 $f$，它输入一系列数据（例如代表图片颜色的二维数组、代表文本的字符串等），$f(x)$ 返回 $0$ 或 $1$，其中 $1$ 则代表 $x$ 具有某种特征，属于这⼀分类。

今天，大家要挑战一项文本的分类任务：识别一个单词序列是由英文书写的，还是由汉语拼音书写的。以下分别是两段文字，是用汉语拼音和英文书写的，你能正确地分类吗？

1. While a number of definitions of artificial intelligence (AI) have surfaced over the last few decades, John McCarthy offers the following definition in this 2004 paper, " It is the science and engineering of making intelligent machines, especially intelligent computer programs. It is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable."

1. Ren gong zhi neng shi yan jiu、kai fa yong yu mo ni、yan shen he kuo zhan ren.de zhi neng de li lun、fang fa ji ying yong xi tong de yi men xin de ji shu ke xue.

## 说明/提示

对于 $100\%$ 的数据，满足 $1\leq T\leq 10,10^3\leq n\leq 10^4$ 并且文本都来自真实、易于人类阅读的文本。

>本题原始满分为 $15\text{pts}$。

## 样例 #1

### 输入

```
2
14 zhe ge ti mu qi shi bi ni xiang xiang de yao jian dan
6 this problem has a simple solution```

### 输出

```
Pinyin
English```

# 题解

## 作者：chen_zhe (赞：72)

欢迎报名[洛谷网校](https://class.luogu.com.cn/)，期待和大家一起进步！

本题并非传统意义上的算法竞赛题。本题考察做题直觉。

题目要求区分是汉语拼音还是英文写的文本。我们来回忆我们学过的拼音，拼音的最长长度是 $6$，例如说创（chuang），装（zhuang），霜（shuang）。而英语通常能够出现长度大于 $6$ 的单词，例如说 `Pumas are large, cat-like animals which are found in America.`（出自新概念英语 3 第一课  _A puma at large_ ），其中的 `animals`，`America` 都是长度大于 $6$ 的单词。因此，如果一篇文本存在一个单词长度大于 $6$，判断它是英语即可。

```cpp
bool flag = true;
cin >> n;
for (int i = 1; i <= n; i++) {
    string s;
    cin >> s;
    if (s.length() > 6)
        flag = false;
}
if (flag)
    cout << "Pinyin" << endl;
else
    cout << "English" << endl;
```

有的人可能会说，如果出现下面这样的例子应当如何处理呢？`one two three four five six seven eight nine ten`。实际上，本题的文本都来自真实、易于人类阅读的文本，对于一篇长度超过 $1000$ 个字符的文本，其很难出现类似于这个例子中如此简单的词汇堆砌。当然也确实存在这样的文本，例如（贡献者：[MatrixGroup](https://www.luogu.com.cn/user/483824)）：


once upon a time there was a mouse and a lion the mouse was little but the lion was large the mouse was weak but the lion was very strong they lived in the wild with joy one day a lot of food began to appear in a sudden how lucky we are mr lion said the little mouse yes indeed said the lion they both felt so happy that they began to sing and dance thing did not go well always though the lion said that he should eat more since the mouse was weaker so the mouse did not need to eat a lot the mouse did not think so he said they should get the same amount of food a war broke out at once they argued they fought the lion was not weak indeed but the but the mouse was nimble and clever a day passed a week passed a month passed the war still did not come to an end they both felt very tired as a result the mouse gave advice why not just eat the food every day and wait until the food have been eaten out said the mouse it is a good idea said the lion but what if i eat a lot more than i should eat every day the mouse began to think for a while and gave a reply well said the little mouse i do not think that you can eat much more food than you need every day you are right how clever you are said the lion from then on they lived with joy again in the wild they ate and they did not need to look for food how joyful they were at that time sadly as the little mouse said the food would be eaten up one day the day came at last they had to look for food busily every day again due to days of being lazy they could hardly find any food after being hungry for days they could not bear the starve any more the mouse began to learn how to eat grass but what about the lion was he going to eat the mouse he seemed to start doing that it was a close call but all of a sudden a melon rolled down a hill and hit the lion the lion was very angry at first but after he found that the melon could be eaten he was not angry any more what is more he found that the melon was very sweet and juicy the lion and the mouse wanted to get more melons like that that is the reason why they walked day by day with no stop when they were hungry they ate grass when they were very tired they said to each other if we arrive there there will be a lot of melons and maybe some other food on their way there the views were very fair the flower danced with the wind the birds sang lovely songs the water flowed fast the mouse and the lion was deeply moved how magic the nature is how great the nature is they cried with the joy of fair views they got there at the end it was a jungle there were a lot of trees what is more there were all kinds of trees there are also many plants on the ground the mouse and the lion both began to shout what an ideal place to live with the free fruit they became happy again but this time they would not become lazy as the saying goes a fall into the pit a gain in your wit they began to run around the trees every day the mouse was no longer weak and the lion became as strong as he used to be one day some wolves came they said the jungle was their place and they did not allow the mouse and the lion to live in the jungle the little mouse was so afraid of the wolves that he could not say any words it was lucky for the mouse that the lion could never be afraid since lions are the king of the animal world the lion fought with some wolves for a while and none of them was alive all the wolves left began to raise the white flag the mouse and the lion lived with the wolves from then on the wolves also gave them a lot of help say when it rained a lot so it was very hard to walk the wolves took them to the places where a lot of food was stored that was great if there came a storm they also gave some help to the wolves in return when others tried to attack the wolves the lion came to help they lived in the jungle with great joy they also had fun in the jungle they had a party four times a year during a party they sang they danced and they ate a lot birds also sang with them one day the flood broke out a lot of water flowed here and there in the jungle they had no choice but to escape they left the jungle and each of them is alone after the lion became safe he felt very lonely will i meet the mouse and the wolves again one day he began to wonder he felt so blue that he even could not eat he stayed there just to wait for the mouse and the wolves to find him an idea came into his mind in a sudden why not go and find them by myself he began to think then he began to run and never had a rest he really wanted to live with the little mouse and the wolves he really missed that time though he knew that this might be a search that would never end he kept going day by day on the way back

参考翻译：

> 从前，有一只老鼠和一头狮子。老鼠很小，而狮子很大；老鼠很弱，而狮子非常强壮。他们快乐地生活在荒野中。  
>有一天，突然出现了很多食物。  
> “小狮先生，我们真是太幸运了！”小老鼠说道。  
> “确实如此。”狮子回答。  
> 他们都感到非常高兴，以至于开始唱歌跳舞。然而，事情并不总是顺利。狮子认为自己应该吃得更多，因为老鼠比他弱，不需要吃那么多。但老鼠不同意，他认为他们应该获得相同的食物份量。  
> 于是，一场战争爆发了。他们争论，他们打斗。狮子确实不弱，但老鼠却敏捷又聪明。一天过去了，一周过去了，一个月过去了，战争仍未结束。他们都感到非常疲惫。  
> 最终，老鼠提出了一个建议：“我们每天吃食物，直到食物吃完为止，如何？”  
> “这是个好主意。”狮子说道，“但如果我每天吃得比我应该吃的还要多呢？”  
> 老鼠思考了一会儿，然后回答道：“嗯，我不认为你每天能吃比自己所需更多的食物。”  
> “你说得对，你真聪明！”狮子赞叹道。  
> 从那以后，他们又快乐地生活在荒野里。他们吃着现成的食物，不再需要寻找食物，生活充满了欢乐。  
> 然而，正如小老鼠所说，食物终有吃完的一天。最终，这一天还是来了。他们不得不再次忙碌地寻找食物。然而，由于长时间的懒惰，他们很难找到食物。几天的饥饿让他们难以忍受。小老鼠开始学着吃草，但狮子呢？他会吃掉老鼠吗？看起来他似乎正打算这么做。千钧一发之际，突然，一个大瓜从山上滚下来，砸到了狮子。  
> 狮子起初很生气，但当他发现这个瓜可以吃时，他便不再生气了。而且，这个瓜又甜又多汁。狮子和老鼠想要找到更多这样的瓜。  
> 于是，他们日复一日地不停行走。当他们饿了，就吃草；当他们疲惫时，他们彼此鼓励：“如果我们到达那里，就会有许多瓜，也许还有其他食物。”  
> 一路上，风景秀丽：花儿随风起舞，鸟儿唱着美妙的歌，流水潺潺。狮子和老鼠深受感动，他们欢呼：“大自然真神奇！大自然真伟大！”  
> 最终，他们到达了一个丛林。那里有许多树，各种各样的树，还有地上的植物。老鼠和狮子兴奋地喊道：“多么理想的居住之地啊！”他们可以自由地吃果子，变得幸福起来。但这一次，他们不会再变得懒惰了。正如那句谚语所说：“吃一堑，长一智。”他们每天都围着树跑步锻炼。老鼠不再弱小，而狮子也恢复了往日的强壮。  
> 一天，一群狼来了。它们说这片丛林是它们的地盘，不允许狮子和老鼠在这里生活。小老鼠害怕得说不出话来。幸运的是，狮子从不害怕，因为狮子是动物世界的王者。狮子与狼群激战了一番，最后所有的狼都败下阵来，剩下的狼纷纷举起了白旗。  
> 从那以后，狮子和老鼠与狼群一起生活。狼群也给予了他们很多帮助，比如在大雨使道路难行时，狼带他们去储藏食物的地方。狮子和老鼠也会回报狼群的帮助，比如当有敌人袭击狼群时，狮子会挺身而出保护他们。  
> 他们在丛林里过着快乐的生活。他们还会在每年举行四次盛大的聚会，唱歌、跳舞、尽情享受美食，鸟儿们也会与他们同乐。  
> 然而，有一天，洪水爆发了，大量的水冲刷着丛林，他们不得不逃离。他们四散奔逃，各自失散了。  
> 狮子在安全后感到非常孤独。他开始思考：“我还能再见到小老鼠和狼群吗？”他的心情非常低落，甚至吃不下东西。他停留在原地，等待小老鼠和狼群来找他。  
> 突然，他灵光一闪：“为什么不自己去找他们呢？”  
> 想到这里，他立刻行动，开始奔跑，从未停歇。他真的很想再次和小老鼠、狼群生活在一起。他真的很怀念那段时光。尽管他知道，这或许是一个永无止境的寻找旅程，但他依然日复一日地奔跑在回去的路上……

---

再分享另外一种做法，可以抓住英语单词中最高频的词汇们：this，that，the，its，his，her，your 等常见的代词，如果读入的文本出现了这些代词，那么它就是英语。但是 AI 依然能帮助我们构造此类反例，下一段例文来自 Deepseek R1：

Spring awakens dormant flora. Blossoms burst from branches, painting hillsides with vibrant hues. Gentle rains nourish roots, encouraging growth across meadows. Birds construct nests among leafy canopies while insects hum in sunlit fields.

Summer radiates relentless warmth. Rivers shimmer under bright skies, reflecting cotton-like clouds. Cicadas drone in sync with rustling grass. Farmers tend crops under golden daylight, harvesting ripe produce for bustling markets.

Autumn chills air, turning foliage crimson and amber. Crisp winds scatter fallen leaves, forming carpets on forest floors. Squirrels gather acorns, storing food for colder months. Fog settles over valleys at dawn, softening horizons.

Winter arrives with silent snowfall. Icicles cling to rooftops, glinting in pale moonlight. Footprints mark trails through powdery drifts as smoke curls from chimneys. Frozen lakes mirror starry nights, capturing stillness in crystalline surfaces.

Nature’s cycles continue endlessly, each phase shaping environments anew. Observers witness beauty in transitions, finding wonder in Earth’s perpetual dance.

参考翻译：

> 春唤醒沉睡植物。花朵从枝头绽放，以明艳色彩点染山坡。细雨滋润根系，催发草甸蓬勃生长。鸟类在繁茂树冠间筑巢，昆虫在阳光倾洒的田野嗡鸣。   
> 夏散发炽热能量。河流在晴空下粼粼闪光，倒映棉絮般的云朵。蝉鸣与窸窣草叶共振。农人在金色日光下照料庄稼，为喧闹集市采收成熟果实。   
> 秋携寒意浸染空气，将树叶染作绯红与琥珀。清冽风卷落叶，于林间铺就斑斓地毯。松鼠收集橡果，为严寒时节储藏食物。晨雾漫过山谷，柔化天地交界。   
> 冬伴随寂静飘雪降临。冰棱悬垂屋檐，在苍冷月色中闪烁微光。足迹穿越蓬松雪堆，炊烟自烟囱袅袅升起。冰封湖泊映出繁星夜空，将凝滞时刻封存于剔透冰面。   
> 自然规律永恒轮转，每个阶段重塑环境样貌。观者于变迁中捕捉美，在地球永续舞动里寻得惊叹。

但是除非是这种刻意构造的情况，其他的情况下本文所述的做法都可以被认为是正确的。

---

## 作者：MathCore (赞：33)

## 题目理解

识别一个单词序列是由英文书写的，还是由汉语拼音书写的。

## 题解方法

由于 cz 需要神经网络的题解，所以考虑简单神经网络。

既然是简单神经网络，所以模型结构为：字符嵌入，句子表示，线性分类器。

训练这个神经网络我使用了简单的训练数据（详见代码的 `tdata`）和优化。

### 字符嵌入

简单来说，就是我把字符（$\text{a}\sim\text{z}$）映射到了一个高维向量，并把它随机初始化（选用这个是因为简单）。

### 句子表示

将输入文本的所有字符的嵌入向量求平均，得到句子的全局特征向量 。

举个栗子：`"hello"` 这个字符串的特征向量是 `(emb['h'] + emb['e'] + ... + emb['o']) / 5` （就是求每个字符映射到的向量的平均值）。

### 线性分类器

这个不太好理解，使用线性层（权重 $W$ 和偏置 $b$）将特征向量转换为 $\text{logit}$ ，再通过 `Sigmoid` 函数得到概率 $p$。

详细一点：

线性层：通过 $ z = Wx + b $ 将特征向量映射为 $\text{logit}$（线性组合结果）。

`Sigmoid` 函数：将 $\text{logit}$ 转换为概率 $ p $，便于解释和决策。

整体用 $\LaTeX$ 书写的流程：

$$
x \xrightarrow{\text{线性层}} z = Wx + b \xrightarrow{\text{Sigmoid}} p = \frac{1}{1 + e^{-z}}
$$

这个过程对二分类问题很好用（判断 `English` 和 `Pinyin` ，正好符合）。

### 训练中的优化

学习率 `rate=0.1`，迭代次数 `epo=100`，随机种子固定，为了保证结果可以复现出来。

## 具体代码

```cpp
#include <iostream>
#include <cmath>
#include <cstdlib>
#include <ctime>
#include <string>
#include <cctype>
#define FastIO_DP return 0
using namespace std;
const int vsize=26;
const int edim=8;
const int seed=42;

double emb[vsize][edim];
double W[edim];
double b=0.0;
struct Node{
    double avg[edim];
    double z;
    double p;
};

Node fw(const string& str){
    Node ans;
    int n=str.size();
    if(n==0){
        for(int i=0;i<edim;++i)ans.avg[i]=0.0;
        ans.z=0.0;
        ans.p=0.5;
        return ans;
    }
    for(int i=0;i<edim;++i)ans.avg[i]=0.0;
    for(char c:str){
        c=tolower(c);
        int idx=c-'a';
        if(idx<0||idx>=vsize)continue;

        for(int i=0;i<edim;++i)ans.avg[i]+=emb[idx][i];
    }
    for(int i=0;i<edim;++i)ans.avg[i]/=n;
    ans.z=0.0;
    for(int i=0;i<edim;++i)ans.z+=W[i]*ans.avg[i];

    ans.z+=b;
    ans.p=1.0/(1.0+exp(-ans.z));

    return ans;
}

void bw(const string& str,double y,double rate){
    Node ans=fw(str);
    double dtz=ans.p-y;
    double grad_W[edim];

    for(int i=0;i<edim;++i)grad_W[i]=ans.avg[i]*dtz;
    double grb=dtz;

    double gre[vsize][edim];
    for(int i=0;i<vsize;++i)
        for(int j=0;j<edim;++j)gre[i][j]=0.0;

    int n=str.size();
    for(char c:str){
        c=tolower(c);
        int idx=c-'a';
        if(idx<0||idx>=vsize)continue;
        double scl=dtz/n;

        for(int i=0;i<edim;++i)gre[idx][i]+=W[i]*scl;
    }
    for(int i=0;i<edim;++i)W[i]-=rate*grad_W[i];
    b-=rate*grb;

    for(int i=0;i<vsize;++i)
        for(int j=0;j<edim;++j)emb[i][j]-=rate*gre[i][j];
}

pair<string,double> tdata[]{ //普普通通的训练数据
    {"hello",1.0},
    {"world",1.0},
    {"apple",1.0},
    {"zhangsan",0.0},
    {"lishi",0.0},
    {"xiaoming",0.0},
    {"computer",1.0},
    {"beijing",0.0},
    {"shanghai",0.0},
    {"john",1.0},
    {"smith",1.0},
    {"lihua",0.0},
    {"mathematics",1.0},
    {"zhongguo",0.0}
};

void tr(double rate,int epo){
    for(int i=0;i<epo;++i){
        double loss=0.0;
        for(const auto&j:tdata){
            const string&in=j.first;
            double y=j.second;
            Node ans=fw(in);
            loss+=-y*log(ans.p)-(1-y)*log(1-ans.p);

            bw(in,y,rate);
        }
    }
}

int main(){
    srand(seed);
    for(int i=0;i<vsize;++i)
        for(int j=0;j<edim;++j)emb[i][j]=(double)rand()/RAND_MAX*0.02-0.01;

    for(int i=0;i<edim;++i)W[i]=(double)rand()/RAND_MAX*0.02-0.01;

    b=(double)rand()/RAND_MAX*0.02-0.01;
    double rate=0.1;
    int epo=100;
    tr(rate,epo);

    int T;
    cin>>T;
    for(int t=0;t<T;++t){
        int n;
        cin>>n;
        string s;

        for(int i=0;i<n;++i){
            string word;
            cin>>word;
            for(char&c:word)c=tolower(c);
            s+=word;
        }

        cout<<(fw(s).p>=0.5?"English":"Pinyin")<<endl;
    }
    FastIO_DP;
}
```

## 复杂度

- 时间复杂度：$O(T × M)$。

- 空间复杂度：$O(M)$。

注意：$M$ 是单个测试用例的总字符数（单词长度之和）。

---

## 作者：skyx (赞：16)

# B3759 [信息与未来2021]文本分类-题解
## 题意简述
给定 $n$ 个字符串，判断这些字符串是拼音还是英文。
## 思路
解题关键的一点是，若输入的为拼音，则每一个单词只对应一个字，又有妙然天成的数据范围：

>对于 $100\%$ 的数据，满足 $1\leq T\leq 10,10^3\leq n\leq 10^4$ 并且文本都来自真实、易于人类阅读的文本。

根据小学英语知识，我们可以确定满足上述要求的英语文本不可能全部由类似于 `an` 这样的冠词或其他可能与拼音重合的简单词汇构成。因此，我们可以通过判断每个字符串是否为有效的拼音音节来准确区分文本的语言类型。

该做法充分体现了跨学科的时代精神，好！

```cpp
#include <bits/stdc++.h>
using namespace std;

unordered_set<string> pinyin = {
    "a", "ai", "an", "ang", "ao", "ba", "bai", "ban", "bang", "bao", "bei", "ben", "beng", "bi", "bian", "biao", "bie", "bin", "bing", "bo", "bu",
    "ca", "cai", "can", "cang", "cao", "ce", "cen", "ceng", "cha", "chai", "chan", "chang", "chao", "che", "chen", "cheng", "chi", "chong", "chou", "chu", "chua", "chuai", "chuan", "chuang", "chui", "chun", "chuo", "ci", "cong", "cou", "cu", "cuan", "cui", "cun", "cuo",
    "da", "dai", "dan", "dang", "dao", "de", "dei", "den", "deng", "di", "dian", "diao", "die", "ding", "diu", "dong", "dou", "du", "duan", "dui", "dun", "duo",
    "e", "ei", "en", "eng", "er",
    "fa", "fan", "fang", "fei", "fen", "feng", "fo", "fou", "fu",
    "ga", "gai", "gan", "gang", "gao", "ge", "gei", "gen", "geng", "gong", "gou", "gu", "gua", "guai", "guan", "guang", "gui", "gun", "guo",
    "ha", "hai", "han", "hang", "hao", "he", "hei", "hen", "heng", "hong", "hou", "hu", "hua", "huai", "huan", "huang", "hui", "hun", "huo",
    "ji", "jia", "jian", "jiang", "jiao", "jie", "jin", "jing", "jiong", "jiu", "ju", "juan", "jue", "jun",
    "ka", "kai", "kan", "kang", "kao", "ke", "ken", "keng", "kong", "kou", "ku", "kua", "kuai", "kuan", "kuang", "kui", "kun", "kuo",
    "la", "lai", "lan", "lang", "lao", "le", "lei", "leng", "li", "lia", "lian", "liang", "liao", "lie", "lin", "ling", "liu", "long", "lou", "lu", "lv", "luan", "lve", "lun", "luo",
    "ma", "mai", "man", "mang", "mao", "me", "mei", "men", "meng", "mi", "mian", "miao", "mie", "min", "ming", "miu", "mo", "mou", "mu",
    "na", "nai", "nan", "nang", "nao", "ne", "nei", "nen", "neng", "ni", "nian", "niang", "niao", "nie", "nin", "ning", "niu", "nong", "nou", "nu", "nv", "nuan", "nve", "nuo",
    "o", "ou",
    "pa", "pai", "pan", "pang", "pao", "pei", "pen", "peng", "pi", "pian", "piao", "pie", "pin", "ping", "po", "pou", "pu",
    "qi", "qia", "qian", "qiang", "qiao", "qie", "qin", "qing", "qiong", "qiu", "qu", "quan", "que", "qun",
    "ran", "rang", "rao", "re", "ren", "reng", "ri", "rong", "rou", "ru", "ruan", "rui", "run", "ruo",
    "sa", "sai", "san", "sang", "sao", "se", "sen", "seng", "sha", "shai", "shan", "shang", "shao", "she", "shei", "shen", "sheng", "shi", "shou", "shu", "shua", "shuai", "shuan", "shuang", "shui", "shun", "shuo", "si", "song", "sou", "su", "suan", "sui", "sun", "suo",
    "ta", "tai", "tan", "tang", "tao", "te", "teng", "ti", "tian", "tiao", "tie", "ting", "tong", "tou", "tu", "tuan", "tui", "tun", "tuo",
    "wa", "wai", "wan", "wang", "wei", "wen", "weng", "wo", "wu",
    "xi", "xia", "xian", "xiang", "xiao", "xie", "xin", "xing", "xiong", "xiu", "xu", "xuan", "xue", "xun",
    "ya", "yan", "yang", "yao", "ye", "yi", "yin", "ying", "yong", "you", "yu", "yuan", "yue", "yun",
    "za", "zai", "zan", "zang", "zao", "ze", "zei", "zen", "zeng", "zha", "zhai", "zhan", "zhang", "zhao", "zhe", "zhei", "zhen", "zheng", "zhi", "zhong", "zhou", "zhu", "zhua", "zhuai", "zhuan", "zhuang", "zhui", "zhun", "zhuo", "zi", "zong", "zou", "zu", "zuan", "zui", "zun", "zuo"
};

int main() {
    int T;
    cin >> T;
    while (T--) {
        int n;
        cin >> n;
        bool isPinyin = true;
        string s;
        for (int i = 0; i < n; ++i) {
            cin >> s;
            if (!pinyin.count(s)) {
                isPinyin = false;
            }
        }
        cout << (isPinyin ? "Pinyin" : "English") << '\n';
    }
    return 0;
}
```

---

## 作者：GoodCoder666 (赞：15)

本题直接计算单词最大长度即可通过，然而我想借此题给各位介绍一些自然语言处理 (NLP) 的基本概念和方法。

于是，我们将借助 **循环神经网络 (RNN)** 模型来完成文本分类任务。

楼上 @FastIO_DP 的做法也使用了基于机器学习的方法，可惜这种方法只能解决非常简单的任务，对通用型任务无能为力。可以证明，将所有嵌入向量平均的方法等价于对字母出现概率的逻辑回归，也就是说，它仅对词频进行了建模，并没有考虑到前后字词的关联性。

### 基础知识 & 问题形式化

我们用 **监督学习** 的方法来解决此问题。它可以描述为：通过训练集 $\{(x_1,y_1),\dots,(x_N,y_N)\}$ 进行学习，建立从输入空间 $X$ 到输出空间 $Y$ 的映射 $f : X\to Y$。在此题中，$X$ 为所有合法句子的集合，$Y=\{\text{English}, \text{Pinyin}\}$（后面分别用 $0$ 和 $1$ 替代）。找到的映射 $f$ 就是我们的模型。

在机器学习中，模型通常是固定形式的，而其中不确定的参数 $\boldsymbol \theta$ 通过学习算法得到，这种称为 **参数化模型**，记作 $f_{\boldsymbol \theta}$。

上面讲的可能有点抽象，我们举个例子，用 $y=kx+b$ 去拟合数据点 $\{(x_1,y_1),\dots,(x_N,y_N)\}$：

- 需要的映射：$f : \R \to \R$。

- 参数：$\boldsymbol \theta = (k,b)$。

- 模型：$f_{\boldsymbol \theta}(x)=kx+b$，即 $f_{\boldsymbol \theta}(x)=\boldsymbol \theta_1 x+\boldsymbol \theta_2$。

- 根据 **最小二乘法**[^1] 的原理，我们希望最小化：
  $$
  \mathcal{L} = \frac{1}{N} \sum_{i=1}^N (f(x_i)-y_i)^2
  $$
  显然，在数据集确定的情况下，$\mathcal{L}$ 的取值只跟 $\boldsymbol \theta$ 有关。它表示对于每个训练数据点，模型预测与实际值的误差的平方的平均值。这个数越小，说明模型整体越能反映数据的实际趋势。

- 使用梯度下降法找到最优的 $\boldsymbol \theta$，具体可以参考[我的博客](https://www.luogu.com.cn/article/2elyq4hw)。

- 损失函数（目标函数）：**均方误差 (MSE) 函数**。

- 学习算法（优化器）：**梯度下降法 (GD)**。

- 其中一些不能被自动优化的数值称为**超参数**，例如 $\boldsymbol \theta$ 中共有 $2$ 个参数，$2$ 这个值无法在学习过程中改变。这些需要用人类智慧进行设定，通常凭借经验即可获得不错的结果。

[^1]: https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%9

大家可以尝试动手实现上面的例子，相信会对理解监督学习的过程有很大帮助。

我们从中获得几点启发：

- **数据集必须有效。** 高质量的数据才能驱动模型学习到正确的“知识”。
- **损失函数必须连续。** 反之，梯度下降法将无法正常工作。
- **模型要适合数据。** 例如不能用一个线性模型拟合指数数据（欠拟合），或者用一个高次多项式拟合带噪声的二次函数数据点（过拟合）。[^2]

> 以上知识对大语言模型 (LLM) 同样适用，希望能对各位理解 AI 原理有所启发。

[^2]: https://www.cnblogs.com/zhhfan/p/10476761.html

回到题目，我们要解决的问题称为 **二分类问题**。模型将输出其认为样本属于正类（$\text{Pinyin}$）的概率：
$$
f(x)=P(x \in \text{Pinyin}) \in [0, 1]
$$
当 $f(x)>0.5$ 时就判定为正类，反之亦然。

一般来说，此类任务中我们会使用 **Binary Cross Entropy（BCE，二元交叉熵）** 损失函数：
$$
\mathcal{L} = -\frac{1}{N} \sum_{i=1}^N \left[y_i \log f(x_i) + (1-y_i) \log (1-f(x_i))\right]
$$

请读者自行思考三个问题：

- BCE 的式子在表达什么？
- BCE 相比 MSE 有什么好处？
- 为什么不将模型的预测准确率作为训练目标？

本部分到此为止！下面我们使用 PyTorch 训练模型，并使用 NumPy/C++ 进行推理。请确保你的 Python 环境中包含 `torch`、`datasets`  和 `tqdm` 库。限于篇幅，本题解不介绍这些工具库的具体使用方法，如果不会用可以让 AI 解释我的示例代码。

### 准备数据

对于此题，我们可以考虑手动构造一个较小的语料库[^3]供训练，但为了方法的通用性，我们从大型公开语料库中合成数据：

[^3]: 由连续的自然语言文本组成的数据集一般称为“语料库”。

- 英文：采用 [**WikiText**](https://huggingface.co/datasets/Salesforce/wikitext)，来自维基百科的英文词条。

- 中文：采用 [**SogouNews**](https://huggingface.co/datasets/community-datasets/sogou_news)，来自搜狗新闻，且全部提前转换成了拼音，减少预处理难度。

二者数据量都很大，我们只取其中一小部分用于训练模型。

**词元化 (Tokenization)**

一般来说，我们会在 NLP 任务中将文本分割为 **词元 (Token)** 以减小模型学习难度。大多数任务中，一个单词被作为一个词元。但由于此题任务难度小，且不适合使用大型的词元库，所以将一个字符（小写英文字母或空格）作为一个词元，仅有 $27$ 个，以减小模型复杂度。

**语料库整理**

两个语料库都由多段连续的文本或句子组成。此处为了简单起见，我们直接将来自不同位置的文本用一个空格连接，以便减小训练代码难度。（这样做也是因为此任务无需关注上下文关系）

```python
# loader.py
import os

os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com/'

import re

import numpy as np
from datasets import load_dataset
from tqdm import tqdm

def load_wikitext(num_lines=10000):
    ds = load_dataset('Salesforce/wikitext', 'wikitext-2-raw-v1', split='train')[:num_lines]['text']
    with tqdm(ds, desc='Loading wikitext') as pbar:
        res = []
        for line in pbar:
            line = line.strip()
            if not line or line.startswith('='):
                continue
            words = line.lower().split()
            res.extend(word for word in words if word.isalpha() and word.isascii())
        res = ' '.join(res)
        print(f'Loaded {len(res)} chars from wikitext')
        return res

pinyin_pattern = re.compile(r'[a-z]+\d[a-z]*')
def load_sgn(num_lines=1000):
    ds = load_dataset('community-datasets/sogou_news', split='test')[:num_lines]['content']
    with tqdm(ds, desc='Loading sogou_news') as pbar:
        res = []
        for line in pbar:
            words = line.split()
            for word in words:
                if pinyin_pattern.fullmatch(word):
                    word = ''.join(ch for ch in word if ch.isalpha())
                    res.append(word)
        res = ' '.join(res)
        print(f'Loaded {len(res)} chars from sogou_news')
        return res

def tokenize(text):
    arr = np.frombuffer(text.encode('ascii'), dtype=np.uint8)
    return np.where(arr == 32, 0, arr - 96).astype(np.uint32)

def build_dataset():
    en, zh = load_wikitext(), load_sgn()
    en, zh = tokenize(en), tokenize(zh)
    en_pos = np.flatnonzero(en[:-260] == 0) + 1
    zh_pos = np.flatnonzero(zh[:-260] == 0) + 1
    return en, zh, en_pos.tolist(), zh_pos.tolist()

```

数据集会从 Hugging Face Hub 上下载，第一次导入需要等待一段时间。

对外提供的接口为 `tokenize` 和 `build_dataset`。前者将文本转换为数字序列（词元化），后者将英文和拼音语料库分别加载到内存中，并返回它们的词元化结果和分隔符位置。

### 选择模型

RNN[^4] 是最简单的语言模型。它通过循环结构处理序列数据，每个时间步[^5] $t$ 的隐藏状态 $\boldsymbol{h}_t$ 由当前输入 $\boldsymbol{x}_t$ 和前一状态 $\boldsymbol{h}_{t-1}$ 共同决定：

[^4]: https://en.wikipedia.org/wiki/Recurrent_neural_network

[^5]: 输入序列中的一个词元对应一个时间步。按顺序将输入序列中每个词元分别输入 RNN 即可迭代到最终的隐藏状态。

$$
\boldsymbol{h}_t = \tanh(\boldsymbol{W}_{xh} \boldsymbol{x}_t + \boldsymbol{W}_{hh} \boldsymbol{h}_{t-1} + \boldsymbol{b}_h)
$$

输出正类（$\text{Pinyin}$）概率：

$$
y = \sigma(\boldsymbol{W}_{hy} \boldsymbol{h}_T + \boldsymbol{b}_y)
$$

其中 $\sigma$ 为 sigmoid 函数：
$$
\sigma(x) = \frac {1} {1+e^{-x}}
$$

直观上，这类模型的设计很符合人类的阅读方式。你想想，你理解一个句子过程大体上是不是这样的：

- 从前往后，依次读取每个字（$\boldsymbol{x}_1 \to \dots \to \boldsymbol{x}_T$）。
- 分别根据读到字的含义，迭代地基于原来的理解（$\boldsymbol{h}_{t-1}$）和新的字（$\boldsymbol{x}_t$）更新对整个句子的理解（$\boldsymbol{h}_t$）。
- 根据最终的理解（$\boldsymbol{h}_T$），得出需要的信息（$y$）。

于是有模型部分代码：

```python
# net.py
import torch
from torch import nn

class MiniTextRNN(nn.Module):
    def __init__(self, embed_size=4, hidden_size=4, num_layers=1):
        super().__init__()
        self.embedding = nn.Embedding(27, embed_size)
        self.rnn = nn.RNN(embed_size, hidden_size, num_layers=num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        x = self.embedding(x)
        out, _ = self.rnn(x)
        out = self.fc(out)
        return out.squeeze(-1)

    def predict(self, x):
        with torch.inference_mode():
            x = self.embedding(x)
            _, h = self.rnn(x)
            out = self.fc(h)
            return torch.sigmoid(out)
```

这里 `forward` 返回对所有时间步中隐藏状态分别应用预测层的结果，`predict` 返回最终状态（$\boldsymbol{h}_T$）的预测结果。

### 训练

训练的流程非常简单，从数据集中反复获得采样并对样本进行梯度下降即可。这里采样的方法较为简单，从语料库中随机获得 $N$ 个长度为 $L$ 的字串（确保开头不是空格），构成一批样本（batch）。

一些超参数的选择主要凭经验（也需要少量实验）：

- 批大小（batch size）：$N=256$
- 采样长度（sample length）：$L=64$
- 训练轮数（epochs）：$5000$
- 优化器（optimizer）：Adam
- 学习率（learning rate）：初始 $10^{-2}$，每 $1000$ 轮减半
- 权重衰减（weight decay，类似于 L2 正则化）：$\lambda = 2\times 10^{-4}$

如果直接按上述方法训练模型，可以通过此题。然而，它容易误判一些短句，比如 `i sing a song`、`see you again` 等。

合理推测这种问题是模型过度依赖句子长度（$L = 64$），从而忽略一些语言特征导致的。为了提升它在短句上的表现，我们作出如下修改：

- 训练目标改为：对句子的每个前缀（而不是只有整句）分类，最小化加权总损失（仍采用 BCE）。

- 权重计算：$i\in [0,L)$ 表示句中位置，$w_i$ 表示位置权重，$m_i$ 是中间量
  $$
  m_i = \exp(-0.04i) \\
  w_i = \frac {m_i} {\sum m_i}
  $$

这样，通过给短前缀赋予更高权重，模型能学会通过更有限的信息完成任务，提升了泛化能力。下面给出完整训练代码实现。

```python
# train.py
import random

import torch
from torch import nn, optim
import torch.nn.functional as F

from loader import build_dataset
from net import MiniTextRNN

torch.manual_seed(42)
random.seed(42)

en_set, zh_set, en_pos, zh_pos = build_dataset()
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
en_set, zh_set = torch.LongTensor(en_set), torch.LongTensor(zh_set)

def _sample_from_dataset(dataset, start_positions, batch_size, sample_len):
    return torch.stack([
        dataset[i: i + sample_len]
        for i in random.sample(start_positions, batch_size)
    ])

epochs = 5000
batch_size = 256
sample_len = 64

def sample():
    half_b = batch_size // 2
    en_samples = _sample_from_dataset(en_set, en_pos, half_b, sample_len)
    zh_samples = _sample_from_dataset(zh_set, zh_pos, half_b, sample_len)
    samples = torch.cat([en_samples, zh_samples], dim=0)
    labels = torch.zeros(batch_size, dtype=torch.float32)
    labels[half_b:] = 1
    return samples, labels

model = MiniTextRNN().to(device).train()
optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=2e-4)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5)

weights = F.softmax(-0.04 * torch.arange(sample_len, dtype=torch.float32, device=device), dim=0)
weights = weights.unsqueeze(0).expand(batch_size, -1)
weights.requires_grad_(False)

loss = nn.BCEWithLogitsLoss(weight=weights, reduction='sum')

for epoch in range(epochs):
    inputs, targets = sample()
    inputs, targets = inputs.to(device), targets.to(device)
    optimizer.zero_grad()
    outputs = model(inputs)
    targets = targets.unsqueeze(1).expand_as(outputs)
    l = loss(outputs, targets) / batch_size
    l.backward()
    optimizer.step()
    scheduler.step()
    print(f'Epoch {epoch + 1}/{epochs}, Loss: {l.item()}')

model.eval()
torch.save(model.state_dict(), 'model.pth')
```

在 CPU 上完整运行需要 1~2min 时间，若有可用 NVIDIA GPU 则会快很多。模型参数会以 PyTorch 格式保存在 `model.pth` 中。

### 推理（PyTorch）

*推理* 指使用训练好的模型进行预测，故不会修改模型参数。下面给出一个非常简单的交互式推理代码：

```python
# eval.py
import torch
from net import MiniTextRNN
from loader import tokenize

model = MiniTextRNN()
model.load_state_dict(torch.load('model.pth'))
model.eval()

while True:
    text = input('> ')
    seq = torch.LongTensor(tokenize(text)).unsqueeze(0)
    pred = model.predict(seq).item()
    if pred > 0.5:
        label = 'Pinyin'
    else:
        label = 'English'
        pred = 1 - pred
    print(f'{label} [P = {pred:.2f}]')
```

运行即可输入句子并验证结果（预测概率也会显示）。

### 导出参数

由于洛谷上不能使用 PyTorch，我们必须将参数导出为普通数组以便复制到其他推理方法中。

```python
# export_params.py
import torch
from net import MiniTextRNN

model = MiniTextRNN()
model.load_state_dict(torch.load('model.pth', map_location='cpu'))

params = [
    param.tolist()
    for param in model.parameters()
]

print(params)
```

### 推理（NumPy）

NumPy 作为通用且高效的科学计算库，非常适合实现神经网络推理（洛谷上也支持）。推理代码如下：

```python
# forward.py
import numpy as np

def predict(x, params):
    batch_size, seq_len = x.shape
    
    # Embedding
    embedding_weight = params[0]
    x_embedded = embedding_weight[x]
    
    W_ih = params[1].T
    W_hh = params[2].T
    b_total = params[3] + params[4]
    
    hidden_size = W_hh.shape[0]
    h = np.zeros((batch_size, hidden_size))
    
    # RNN
    for t in range(seq_len):
        x_t = x_embedded[:, t, :]
        h = np.tanh(x_t @ W_ih + h @ W_hh + b_total)
        
    fc_weight = params[5].T
    fc_bias = params[6]

    # Linear
    out = h @ fc_weight + fc_bias
    return 1 / (1 + np.exp(-out))

def tokenize(text):
    return [0 if c == ' ' else ord(c) - 96 for c in text]

params = ... # 把 export_params.py 的输出复制到这里
for i, param in enumerate(params):
    params[i] = np.array(param, dtype=np.float32)

T = int(input())
sentences = []
cutoff = 16

for _ in range(T):
    s = input()
    s = s[s.find(' ') + 1:]
    sentences.append(tokenize(s[:cutoff]))

batch = np.array(sentences, dtype=np.int32)
preds = predict(batch, params).flatten()

for p in preds:
    print('Pinyin' if p > 0.5 else 'English')
```

为了将所有输入数据塞进一个 batch 中，我们定义 `cutoff = 16` 表示只取每个句子的前 $16$ 个字符进行推理。受益于前面的短句训练，这样缩句已经足够了。

这份代码符合题目交互格式，可以直接提交并获得 AC。

### 推理（C++）

最后，是 OIer 最喜欢的 —— 原生 C++ 版本推理代码。同样，将 `export_params.py` 的输出复制到对应位置即可。这里给出带参数的版本：

```cpp
#include <iostream>
#include <vector>
#include <string>
#include <cmath>
#include <algorithm>
using namespace std;

const int cutoff = 16;

vector<int> tokenize(const string &text) {
    vector<int> tokens;
    for (char c : text) {
        tokens.push_back(c == ' '? 0 : c - 'a' + 1);
    }
    return tokens;
}

struct Params {
    vector<vector<float>> embedding;
    vector<vector<float>> W_ih;
    vector<vector<float>> W_hh;
    vector<float> b_total;
    vector<float> fc_weight;
    float fc_bias;
};

Params loadParams() {
    Params params;
    params.embedding = {{1.8028215169906616, 0.9283891916275024, 1.3205686807632446, -1.5752028226852417}, {0.13235650956630707, -0.49311327934265137, -0.9034576416015625, -1.172258973121643}, {0.488021582365036, 0.7543725371360779, -0.445336252450943, 0.6823800206184387}, {0.24799521267414093, -0.06231396645307541, -0.850423276424408, 0.47710537910461426}, {0.6099422574043274, -0.16763363778591156, -0.8439192175865173, 0.6677266359329224}, {0.8494492173194885, -0.13217075169086456, 0.6258174180984497, 1.569193720817566}, {0.30578163266181946, 0.6655067205429077, -0.21990719437599182, 0.6016054153442383}, {-0.5038883090019226, -0.5056541562080383, 0.05960218608379364, -0.12365201860666275}, {-1.088889241218567, -0.576884388923645, -0.0727449506521225, 1.2157354354858398}, {-0.5948517322540283, 0.09637022763490677, -0.2701537609100342, -0.6761443018913269}, {-0.404205858707428, -0.2761806547641754, 0.8516933917999268, -0.46787896752357483}, {0.6484190225601196, 0.5022299289703369, -0.0976589098572731, 0.669188916683197}, {0.4647216796875, 0.3021875023841858, -0.6405024528503418, 0.6796223521232605}, {0.3592414855957031, 0.18491922318935394, -0.6801095604896545, 0.5701507329940796}, {-0.9694885015487671, -0.14524048566818237, 0.03966279700398445, 0.16804799437522888}, {-0.740732729434967, 0.6608019471168518, -0.40265488624572754, -1.0690840482711792}, {0.10779128223657608, 0.6879157423973083, -0.2754943370819092, 0.9154365658760071}, {0.4958310127258301, -0.2278299331665039, 0.2521037757396698, 0.2962592542171478}, {0.7540019750595093, 0.8513333201408386, -0.46456143260002136, 0.36205658316612244}, {0.5148546099662781, -0.01420197356492281, -1.3858643770217896, 0.37393471598625183}, {0.4115105867385864, 1.4900071620941162, -1.0104691982269287, 0.8417065143585205}, {-0.4887521266937256, -0.022634167224168777, -0.3625696897506714, -0.8713006973266602}, {-0.839846670627594, 0.44619613885879517, -0.48624110221862793, -0.1636740118265152}, {0.2647571563720703, 0.693376362323761, -0.12427894026041031, 1.079669713973999}, {0.04795406758785248, -0.3749895393848419, 0.7033652663230896, 0.6426048874855042}, {-0.7549335956573486, 0.5020769238471985, 1.583930253982544, 1.0305057764053345}, {-0.31936517357826233, -0.5509432554244995, 0.5316606760025024, 0.46490678191185}};
    params.W_ih = {{-0.3061768114566803, -0.5796734690666199, -0.23363934457302094, -0.6856022477149963}, {0.8776503205299377, 0.2878395915031433, 0.4609214663505554, 0.3076168894767761}, {-0.3890216648578644, 0.415404349565506, -0.031227510422468185, -1.534371018409729}, {-0.7136509418487549, -0.6914500594139099, 0.7908886075019836, -0.7499666213989258}};
    params.W_hh = {{0.6976242065429688, 0.6702086925506592, -0.36442238092422485, 0.52286297082901}, {0.3029521107673645, 0.8078854084014893, -0.41114476323127747, 1.4449198246002197}, {0.9325374960899353, -2.2087032794952393, 1.3442336320877075, -0.17874063551425934}, {1.2263154983520508, -0.0513387992978096, -0.5691488981246948, 0.45193809270858765}};
    params.b_total = {0.634063720703125, -0.10535888373851776, -0.18860894441604614, -0.8973617553710938};
    params.fc_weight = {3.1700961589813232, 3.0720882415771484, -2.5844953060150146, 4.052948474884033};
    params.fc_bias = 1.1022119522094727;
    return params;
}

float sigmoid(float x) {
    return 1.0f / (1.0f + exp(-x));
}

float rnn_forward(const vector<int> &tokens, const Params &params) {
    int embed_dim = params.embedding[0].size();
    int hidden_size = params.b_total.size();
    int seq_len = min((int)tokens.size(), cutoff);

    vector<float> h(hidden_size, 0.0f);

    for (int t = 0; t < seq_len; t++) {
        // Embedding
        const vector<float> &embed = params.embedding[tokens[t]];

        // RNN cell
        vector<float> new_h(hidden_size, 0.0f);
        for (int j = 0; j < hidden_size; j++) {
            float s = params.b_total[j];
            for (int k = 0; k < embed_dim; k++) {
                s += embed[k] * params.W_ih[j][k];
            }
            for (int k = 0; k < hidden_size; k++) {
                s += h[k] * params.W_hh[j][k];
            }
            new_h[j] = tanh(s);
        }
        h = new_h;
    }

    // Linear
    float out = params.fc_bias;
    for (int j = 0; j < h.size(); j++) {
        out += h[j] * params.fc_weight[j];
    }
    return sigmoid(out);
}

int main() {
    ios::sync_with_stdio(false);
    cin.tie(nullptr);

    int T;
    cin >> T;
    cin.ignore(numeric_limits<streamsize>::max(), '\n');

    const Params params = loadParams();
    
    while (T--) {
        string s;
        getline(cin, s);
        size_t pos = s.find(' ');
        s = s.substr(pos + 1, cutoff);
        vector<int> tokens = tokenize(s);
        float pred = rnn_forward(tokens, params);
        cout << (pred > 0.5f ? "Pinyin" : "English") << '\n';
    }
    return 0;
}
```

### 总结

我希望能通过这篇题解抛砖引玉，期待更多大佬提出更优秀的做法~

---

## 作者：volatile (赞：5)

~~这题什么时候又能写题解了~~

# 大意

应该是个人都能看懂，给你 $T$ 个句子，要么全是拼音，要么全是英语单词，判断每一句中文句子还是英语句子。

# 思路

判断有没有词语包含 `th` 即可，拼音中没有这个读音。

# 代码


```cpp
#include<iostream>
#include<string>
using namespace std;
int main()
{
	int T;
	cin>>T;
	while(T--){
		int n,flag=1;
		cin>>n;
		while(n--){
			string s;
			cin>>s;
			if(s.find("th")!=string::npos) flag=0;
		}
		if(flag) cout<<"Pinyin\n";
		else cout<<"English\n";
	}
	return 0;
}
```

---

## 作者：flying_bluecat (赞：4)

# B3759 [信息与未来 2021] 文本分类 题解

看大家都在写一些小技巧，我就写一个~~多余~~全面一点的吧。

要判断一段文本是汉语拼音还是英文，可以通过检查每个单词是否属于合法的拼音音节。拼音的每个字对应特定的音节组合，这些音节是有限的且符合特定规则。我们将所有可能的拼音音节存入集合，统计输入文本中属于这些音节的单词数量。若超过半数，则判定为拼音，否则为英文。

这个思路不见得有多方便，但一定不会出现误差（如通过超过 6 字符的单词判断容易出现问题）。

## 思路

1. **预处理拼音音节**：将所有可能的汉语拼音音节存入哈希集合，便于快速查询。
2. **统计合法音节数量**：对于每个输入的单词，检查是否存在于拼音集合中。
3. **判断结果**：若合法音节数量超过单词总数的一半，输出 `Pinyin`，否则输出 `English`。

## 代码

```cpp
#include <iostream>
#include <unordered_set>
#include <string>
using namespace std;

unordered_set<string> pinyin = {
    "a", "ai", "an", "ang", "ao", "ba", "bai", "ban", "bang", "bao",
    "bei", "ben", "beng", "bi", "bian", "biao", "bie", "bin", "bing",
    "bo", "bu", "ca", "cai", "can", "cang", "cao", "ce", "cen", "ceng",
    "cha", "chai", "chan", "chang", "chao", "che", "chen", "cheng", "chi",
    "chong", "chou", "chu", "chua", "chuai", "chuan", "chuang", "chui",
    "chun", "chuo", "ci", "cong", "cou", "cu", "cuan", "cui", "cun", "cuo",
    "da", "dai", "dan", "dang", "dao", "de", "dei", "den", "deng", "di",
    "dia", "dian", "diao", "die", "ding", "diu", "dong", "dou", "du", "duan",
    "dui", "dun", "duo", "e", "ei", "en", "eng", "er", "fa", "fan", "fang",
    "fei", "fen", "feng", "fo", "fou", "fu", "ga", "gai", "gan", "gang",
    "gao", "ge", "gei", "gen", "geng", "gong", "gou", "gu", "gua", "guai",
    "guan", "guang", "gui", "gun", "guo", "ha", "hai", "han", "hang", "hao",
    "he", "hei", "hen", "heng", "hong", "hou", "hu", "hua", "huai", "huan",
    "huang", "hui", "hun", "huo", "ji", "jia", "jian", "jiang", "jiao",
    "jie", "jin", "jing", "jiong", "jiu", "ju", "juan", "jue", "jun", "ka",
    "kai", "kan", "kang", "kao", "ke", "ken", "keng", "kong", "kou", "ku",
    "kua", "kuai", "kuan", "kuang", "kui", "kun", "kuo", "la", "lai", "lan",
    "lang", "lao", "le", "lei", "leng", "li", "lia", "lian", "liang", "liao",
    "lie", "lin", "ling", "liu", "long", "lou", "lu", "lv", "luan", "lve",
    "lun", "luo", "ma", "mai", "man", "mang", "mao", "me", "mei", "men",
    "meng", "mi", "mian", "miao", "mie", "min", "ming", "miu", "mo", "mou",
    "mu", "na", "nai", "nan", "nang", "nao", "ne", "nei", "nen", "neng", "ni",
    "nian", "niang", "niao", "nie", "nin", "ning", "niu", "nong", "nou", "nu",
    "nv", "nuan", "nve", "nuo", "o", "ou", "pa", "pai", "pan", "pang", "pao",
    "pei", "pen", "peng", "pi", "pian", "piao", "pie", "pin", "ping", "po",
    "pou", "pu", "qi", "qia", "qian", "qiang", "qiao", "qie", "qin", "qing",
    "qiong", "qiu", "qu", "quan", "que", "qun", "ran", "rang", "rao", "re",
    "ren", "reng", "ri", "rong", "rou", "ru", "ruan", "rui", "run", "ruo",
    "sa", "sai", "san", "sang", "sao", "se", "sen", "seng", "sha", "shai",
    "shan", "shang", "shao", "she", "shei", "shen", "sheng", "shi", "shou",
    "shu", "shua", "shuai", "shuan", "shuang", "shui", "shun", "shuo", "si",
    "song", "sou", "su", "suan", "sui", "sun", "suo", "ta", "tai", "tan",
    "tang", "tao", "te", "teng", "ti", "tian", "tiao", "tie", "ting", "tong",
    "tou", "tu", "tuan", "tui", "tun", "tuo", "wa", "wai", "wan", "wang",
    "wei", "wen", "weng", "wo", "wu", "xi", "xia", "xian", "xiang", "xiao",
    "xie", "xin", "xing", "xiong", "xiu", "xu", "xuan", "xue", "xun", "ya",
    "yan", "yang", "yao", "ye", "yi", "yin", "ying", "yo", "yong", "you",
    "yu", "yuan", "yue", "yun", "za", "zai", "zan", "zang", "zao", "ze",
    "zei", "zen", "zeng", "zha", "zhai", "zhan", "zhang", "zhao", "zhe",
    "zhei", "zhen", "zheng", "zhi", "zhong", "zhou", "zhu", "zhua", "zhuai",
    "zhuan", "zhuang", "zhui", "zhun", "zhuo", "zi", "zong", "zou", "zu",
    "zuan", "zui", "zun", "zuo"
}; // 直接把拼音表搬过来了QAQ

int main() {
    int T;
    cin >> T;
    while (T--) {
        int n;
        cin >> n;
        int cnt = 0;
        for (int i = 0; i < n; ++i) {
            string s;
            cin >> s;
            if (pinyin.count(s)) ++cnt;
        }
        if (cnt * 2 >= n) cout << "Pinyin\n"; // 超过半数
        else cout << "English\n";
    }
    return 0;
}
```

---

## 作者：llamn (赞：4)

人类智慧题。由于 $n \ge 10^3$，所以诸如 `man man man man man man man...` 之类的文本重复 $10^3$ 次并不能满足“真实、易于人类阅读的文本”的要求。

英语非常多而复杂，难以识别。但是拼音数量很少。所以可以将文本默认为英文，然后和拼音词库匹配。

发挥借鉴的智慧，从题面上找文本：

```
{"fen","lei","shi","ren","gong","zhi","neng","zhong","hen","zhong","yao","de","yi","xiang","ren","wu","li","ru","qu","fen","shi","pin","zhong","de","yi","zhen","tu","xiang","shi","fou","cun","zai","yi","chang","shi","jian","bian","bie","tu","pian","zhong","shi","fou","you","dai","jian","suo","de","mu","biao","hua","fen","yin","pin","zhong","ci","yu","de","fen","jie","wei","zhi","deng"
,"sui","ran","shu","yu","ren","gong","zhi","neng","de","fan","chou","dan","fen","lei","wen","ti","ye","ke","yi","jian","dan","li","jie","cheng","shi","yi","ge","ji","suan","ji","han","shu","ta","shu","ru","yi","xi","lie","shu","ju","li","ru","dai","biao","tu","pian","yan","se","de","er","wei","shu","zu","dai","biao","wen","ben","de","zi","fu","chuan","deng","fan","hui","huo","qi","zhong","ze","dai","biao","ju","you","mou","zhong","te","zheng","shu","yu","zhe","yi","fen","lei"
,"jin","tian","da","jia","yao","tiao","zhan","yi","xiang","wen","ben","de","fen","lei","ren","wu","shi","bie","yi","ge","dan","ci","xu","lie","shi","you","ying","wen","shu","xie","de","hai","shi","you","han","yu","pin","yin","shu","xie","de","yi","xia","fen","bie","shi","liang","duan","wen","zi","shi","yong","han","yu","pin","yin","he","ying","wen","shu","xie","de","ni","neng","zheng","que","di","fen","lei","ma"}
```

由于上面的词汇没有审查，所以可以加上一个简单的判断：长度大于 $6$ 则为英文。

```cpp
#include <bits/stdtr1c++.h>
#define _eggy_ using
#define _party_ namespace
_eggy_ _party_ std; 

int _,ans,n,i;
string s;

unordered_set<string> py = {"fen","lei","shi","ren","gong","zhi","neng","zhong","hen","zhong","yao","de","yi","xiang","ren","wu","li","ru","qu","fen","shi","pin","zhong","de","yi","zhen","tu","xiang","shi","fou","cun","zai","yi","chang","shi","jian","bian","bie","tu","pian","zhong","shi","fou","you","dai","jian","suo","de","mu","biao","hua","fen","yin","pin","zhong","ci","yu","de","fen","jie","wei","zhi","deng"
,"sui","ran","shu","yu","ren","gong","zhi","neng","de","fan","chou","dan","fen","lei","wen","ti","ye","ke","yi","jian","dan","li","jie","cheng","shi","yi","ge","ji","suan","ji","han","shu","ta","shu","ru","yi","xi","lie","shu","ju","li","ru","dai","biao","tu","pian","yan","se","de","er","wei","shu","zu","dai","biao","wen","ben","de","zi","fu","chuan","deng","fan","hui","huo","qi","zhong","ze","dai","biao","ju","you","mou","zhong","te","zheng","shu","yu","zhe","yi","fen","lei"
,"jin","tian","da","jia","yao","tiao","zhan","yi","xiang","wen","ben","de","fen","lei","ren","wu","shi","bie","yi","ge","dan","ci","xu","lie","shi","you","ying","wen","shu","xie","de","hai","shi","you","han","yu","pin","yin","shu","xie","de","yi","xia","fen","bie","shi","liang","duan","wen","zi","shi","yong","han","yu","pin","yin","he","ying","wen","shu","xie","de","ni","neng","zheng","que","di","fen","lei","ma"};

int main()
{
    cin >> _; while(_--)
    {
        cin >> n; ans = 0;
        for (i = 1; i <= n; i++)
        {
        	cin >> s; 
            if (s.size() > 6) ans = -10007;
            if (py.find(s) != py.end()) ans++;        
		}if (ans > 0) puts("Pinyin");
		else puts("English");
    }
    return 0;
}
```

[彩蛋](https://www.luogu.me/paste/6zgd5xwi)

---

## 作者：__szh_DNCB__ (赞：4)

真的在瞎搞。

受到 chenzhe 的 tj 启发，如果我们把单词长度、代词和冠词判断一起判断，是不是卡不掉了呢？

尝试让 DeepSeek hack，居然两次都没有成功 hack，最接近的一次因为 `ing` 突破了 $6$ 字母，hack 失败。

大胆使用这份代码，希望能有数据把我 hack 掉。

```cpp
#include <bits/stdc++.h>
using namespace std;
int main() {
	int T;
	cin >> T;
	while (T--) {
		int n;
		cin >> n;
		bool english = false;
		for (int i = 0; i < n; i++) {
			string s;
			cin >> s;
			if (s.length() > 6 || s == "I" || s == "i" || s == "it" || s == "they" || s == "them" || s == "him" || s == "her" || s == "we" || s == "us" ||
			  s == "the" || s == "on" || s == "of" || s == "by" || s == "in" || s== "before" || s == "under" || s == "for" || s == "at" || s == "though" || s == "if" || s == "but" || s == "or" ||
			 s == "first" || s == "next") {
				english = true;
			}
		}
		if (english)puts("English");
		else puts("Pinyin");
	}
	return 0;
}
```

---

## 作者：Lawrenceling (赞：3)

## 前言
这题是怎么黄的？
## 思路
注意到英语和拼音区别极大，而且：
> 文本都来自真实、易于人类阅读的文本。

这不是很简单吗？我们只需要打出几个英文最常用的单词，比如 ```the``` 和 ```this``` 等等。这样就可以通过了。

代码应该是题解里面挺短的了。

## AC CODE

```cpp
#include <bits/stdc++.h>
using namespace std;
int main() 
{
	int t,n;
	string Eng[10]={"I","that","it","this","am","are","in"};
	cin>>t;
	while(t--)
	{
		cin>>n;
		bool flag=0;
		for(int i=1;i<=n;++i)
		{
			string s;
			cin>>s;
//			if(s.size()>6)flag=1;
			for(int j=0;j<7;++j)if(s==Eng[j])flag=1;
		}
		cout<<(flag?"English\n":"Pinyin\n");
	}
	return 0;
}
```

---

## 作者：寄风 (赞：3)

考虑有效的英语单词很多，但是有效的拼音很少，所以找个拼音表就做完了？

其实是有一个问题的。就是说有些英语单词在拼音中也存在。

回顾英语的语法，发现大多数情况需要动词。

而我们回顾拼音表，发现一般动词很少（至少我只看到了 `song`），就算有的话，结合拼音表名词也出现的很少，那么我们的错误率是极小的。

又发现其实有一个在拼音表中的情态动词 `can`，所以有可能出现有 `can` 的句子。

但是考虑能出现什么句子。基本上就是 `a man can song` 这种。

我们的做法看上去到了绝境。

但是发掘题目数据范围，发现 $10^3\leq n\leq 10^4$，而这么长的真实文本显然不可能只出现这么几句话。

upd：根据作者的统计，与拼音重复的单词如下，可能不全，欢迎补充：
```cpp
n.：各种人名，zen（禅宗信徒），you，tang（特性；强烈的味道；柄脚），tan（棕褐色，棕黄色；（日晒后变成的）棕褐色皮肤；鞣料树皮；（铺路和园艺中使用的）鞣酸皮渣），tong（钳子），song（歌曲），pan（锅），long（长的），lie（存在），hen（母鸡），hang（陈列），gong（奖章），fen（沼泽），ding（钟声），beng（大麻），bang（重击），ban（禁止），die（消亡）
v.：tan（（使）晒成褐色，晒黑；鞣（革），硝（皮）；<非正式，旧> 痛打（某人），鞭打（尤指作为惩罚）），long（渴望），lie（谎言），hang（悬挂），ding（打击），bang（爆炸），ban（禁止），die（死亡）
adj.：tan（棕黄色的，棕褐色的；晒黑的），long（长久的）
adv.：long（长久地），bang（正好）
vt.：tang（使声尖锐；装刀柄于）
vi.：tang（发出铿锵声；发出当的一声）
abbr.：tan（正切）
art.an（一个），a（一个）
```
你发现这些词显然凑不出长度为 $10^3$ 的句子，所以我们的做法很正确！

所以我们证明了我们这个做法的正确率极高。

不放心的话可以特判几个英语的特殊情况，我没有特判。

```cpp
#include <bits/stdc++.h>
using namespace std;
#define int long long
string ans[] = {
    "a",
    "ai",
    "an",
    "ang",
    "ao",
    "ba",
    "bai",
    "ban",
    "bang",
    "bao",
    "bei",
    "ben",
    "beng",
    "bi",
    "bian",
    "biao",
    "bie",
    "bin",
    "bing",
    "bo",
    "bu",
    "ca",
    "cai",
    "can",
    "cang",
    "cao",
    "ce",
    "cen",
    "ceng",
    "cha",
    "chai",
    "chan",
    "chang",
    "chao",
    "che",
    "chen",
    "cheng",
    "chi",
    "chong",
    "chou",
    "chu",
    "chuai",
    "chuan",
    "chuang",
    "chui",
    "chun",
    "chuo",
    "ci",
    "cong",
    "cou",
    "cu",
    "cuan",
    "cui",
    "cun",
    "cuo",
    "da",
    "dai",
    "dan",
    "dang",
    "dao",
    "de",
    "dei",
    "deng",
    "di",
    "dian",
    "diao",
    "die",
    "ding",
    "diu",
    "dong",
    "dou",
    "du",
    "duan",
    "dui",
    "dun",
    "duo",
    "e",
    "ei",
    "en",
    "eng",
    "er",
    "fa",
    "fan",
    "fang",
    "fei",
    "fen",
    "feng",
    "fo",
    "fou",
    "fu",
    "ga",
    "gai",
    "gan",
    "gang",
    "gao",
    "ge",
    "gei",
    "gen",
    "geng",
    "gong",
    "gou",
    "gu",
    "gua",
    "guai",
    "guan",
    "guang",
    "gui",
    "gun",
    "guo",
    "ha",
    "hai",
    "han",
    "hang",
    "hao",
    "he",
    "hei",
    "hen",
    "heng",
    "hong",
    "hou",
    "hu",
    "hua",
    "huai",
    "huan",
    "huang",
    "hui",
    "hun",
    "huo",
    "ji",
    "jia",
    "jian",
    "jiang",
    "jiao",
    "jie",
    "jin",
    "jing",
    "jiong",
    "jiu",
    "ju",
    "juan",
    "jue",
    "jun",
    "ka",
    "kai",
    "kan",
    "kang",
    "kao",
    "ke",
    "ken",
    "keng",
    "kong",
    "kou",
    "kou",
    "ku",
    "kua",
    "kuai",
    "kuan",
    "kuang",
    "kui",
    "kun",
    "kuo",
    "la",
    "lai",
    "lan",
    "lang",
    "lao",
    "le",
    "lei",
    "leng",
    "li",
    "lia",
    "lian",
    "liang",
    "liao",
    "lie",
    "lin",
    "ling",
    "liu",
    "long",
    "lou",
    "lu",
    "lv",
    "luan",
    "lue",
    "lve",
    "lun",
    "luo",
    "lv",
    "lve",
    "ma",
    "mai",
    "man",
    "mang",
    "mao",
    "me",
    "mei",
    "men",
    "meng",
    "mi",
    "mian",
    "miao",
    "mie",
    "min",
    "ming",
    "miu",
    "mo",
    "mou",
    "mu",
    "na",
    "nai",
    "nan",
    "nang",
    "nao",
    "ne",
    "nei",
    "nen",
    "neng",
    "ni",
    "nian",
    "niang",
    "niao",
    "nie",
    "nin",
    "ning",
    "niu",
    "nong",
    "nu",
    "nv",
    "nuan",
    "nue",
    "nve",
    "nuo",
    "nv",
    "nve",
    "o",
    "ou",
    "pa",
    "pai",
    "pan",
    "pang",
    "pao",
    "pei",
    "pen",
    "peng",
    "pi",
    "pian",
    "piao",
    "pie",
    "pin",
    "ping",
    "po",
    "pou",
    "pu",
    "qi",
    "qia",
    "qian",
    "qiang",
    "qiao",
    "qie",
    "qin",
    "qing",
    "qiong",
    "qiu",
    "qu",
    "quan",
    "que",
    "qve",
    "qun",
    "qve",
    "ran",
    "rang",
    "rao",
    "re",
    "ren",
    "reng",
    "ri",
    "rong",
    "rou",
    "ru",
    "ruan",
    "rui",
    "run",
    "ruo",
    "sa",
    "sai",
    "san",
    "sang",
    "sao",
    "se",
    "sen",
    "seng",
    "sha",
    "shai",
    "shan",
    "shang",
    "shao",
    "she",
    "shei",
    "shen",
    "sheng",
    "shi",
    "shou",
    "shu",
    "shua",
    "shuai",
    "shuan",
    "shuang",
    "shui",
    "shun",
    "shuo",
    "si",
    "song",
    "sou",
    "su",
    "suan",
    "sui",
    "sun",
    "suo",
    "ta",
    "tai",
    "tan",
    "tang",
    "tao",
    "te",
    "teng",
    "ti",
    "tian",
    "tiao",
    "tie",
    "ting",
    "tong",
    "tou",
    "tu",
    "tuan",
    "tui",
    "tun",
    "tuo",
    "wa",
    "wai",
    "wan",
    "wang",
    "wei",
    "wen",
    "weng",
    "wo",
    "wu",
    "xi",
    "xia",
    "xian",
    "xiang",
    "xiao",
    "xie",
    "xin",
    "xing",
    "xiong",
    "xiu",
    "xu",
    "xuan",
    "xue",
    "xun",
    "ya",
    "yan",
    "yang",
    "yao",
    "ye",
    "yi",
    "yin",
    "ying",
    "yong",
    "you",
    "yu",
    "yuan",
    "yue",
    "yve",
    "yun",
    "yve",
    "za",
    "zai",
    "zan",
    "zang",
    "zao",
    "ze",
    "zei",
    "zen",
    "zeng",
    "zha",
    "zhai",
    "zhan",
    "zhang",
    "zhao",
    "zhe",
    "zhen",
    "zheng",
    "zhi",
    "zhong",
    "zhou",
    "zhu",
    "zhua",
    "zhuai",
    "zhuan",
    "zhuang",
    "zhui",
    "zhun",
    "zhuo",
    "zi",
    "zong",
    "zou",
    "zu",
    "zuan",
    "zui",
    "zun",
    "zuo"
};
inline void solve(){
    int n;
    cin >> n;
    string s;
    bool f1 = 1 , f2 = 1;
    bool ff = 1;
    sort(ans , ans + 411);
    for(int i = 1;i <= n;i++){
        cin >> s;
        if(ff){
            bool fg = (*lower_bound(ans , ans + 411 , s) == s);
            f1 &= fg;
            if(s[0] == 't' && s[1] == 'h') f1 = 0;
            if(!f1){
                ff = 0;
                // cout << s << '\n';
            }
        }
    }
    if(f1) cout << "Pinyin\n";
    else cout << "English\n";
}
signed main(){
    ios::sync_with_stdio(0);
    cin.tie(0) , cout.tie(0);
    int t;
    cin >> t;
    while(t--) solve();
    return 0;
}
```

---

## 作者：FISH酱 (赞：3)

## 前置知识

本题实际上是红题难度，你只需要了解基本语法和基础拼音知识。

## 思路讲解

众所周知，所有拼音组合的个数并不多，我们通过网络搜索或手动编写都可以得到一个拼音组合表。下面提供一个参考版本：

```python
pinyin = ['ba', 'bo', 'bai', 'bei', 'bao', 'ban', 'ben', 'bang', 'beng', 'bi', 'bie', 'biao', 'bian', 'bin', 'bing', 'bu', 'pa', 'po', 'pai', 'pei', 'pao', 'pou', 'pan', 'pen', 'pang', 'peng', 'pi', 'pie', 'piao', 'pian', 'pin', 'ping', 'pu', 'ma', 'mo', 'mai', 'mei', 'mao', 'mou', 'man', 'men', 'mang', 'meng', 'mi', 'mie', 'miao', 'miu', 'mian', 'min', 'ming', 'mu', 'fa', 'fo', 'me', 'fei', 'fou', 'fan', 'fen', 'fang', 'feng', 'fu', 'da', 'de', 'dai', 'dei', 'dao', 'dou', 'dan', 'den', 'dang', 'deng', 'dong', 'di', 'dia', 'die', 'diao', 'diu', 'dian', 'ding', 'du', 'duo', 'dui', 'duan', 'dun', 'ta', 'te', 'tai', 'tei', 'tao', 'tou', 'tan', 'tang', 'teng', 'tong', 'ti', 'tie', 'tiao', 'tian', 'ting', 'tu', 'tuo', 'tui', 'tuan', 'tun', 'na', 'ne', 'nai', 'nei', 'nao', 'nou', 'nan', 'nen', 'nang', 'neng', 'nong', 'ni', 'nie', 'niao', 'niu', 'nian', 'nin', 'niang', 'ning', 'nu', 'nuo', 'nuan', 'nv', 'nve', 'la', 'le', 'lai', 'lei', 'lao', 'lou', 'lan', 'lang', 'leng', 'long', 'li', 'lia', 'lie', 'liao', 'liu', 'lian', 'lin', 'liang', 'ling', 'lu', 'luo', 'luan', 'lun', 'lv', 'lve', 'ga', 'ge', 'gai', 'gei', 'gao', 'gou', 'gan', 'gen', 'gang', 'geng', 'gong', 'gu', 'gua', 'guo', 'guai', 'gui', 'guan', 'gun', 'guang', 'ka', 'ke', 'kai', 'kao', 'kou', 'kan', 'ken', 'kang', 'keng', 'kong', 'ku', 'kua', 'kuo', 'kuai', 'kui', 'kuan', 'kun', 'kuang', 'ha', 'he', 'hai', 'hei', 'hao', 'hou', 'han', 'hen', 'hang', 'heng', 'hong', 'hu', 'hua', 'huo', 'huai', 'hui',
          'huan', 'hun', 'huang', 'ji', 'jia', 'jie', 'jiao', 'jiu', 'jian', 'jin', 'jiang', 'jing', 'jiong', 'ju', 'jue', 'juan', 'jun', 'qi', 'qia', 'qie', 'qiao', 'qiu', 'qian', 'qin', 'qiang', 'qing', 'qiong', 'qu', 'que', 'quan', 'qun', 'xi', 'xia', 'xie', 'xiao', 'xiu', 'xian', 'xin', 'xiang', 'xing', 'xiong', 'xu', 'xue', 'xuan', 'xun', 'zha', 'zhe', 'zhi', 'zhai', 'zhei', 'zhao', 'zhou', 'zhan', 'zhen', 'zhang', 'zheng', 'zhong', 'zhu', 'zhua', 'zhuo', 'zhuai', 'zhui', 'zhuan', 'zhun', 'zhuang', 'cha', 'che', 'chi', 'chai', 'chao', 'chou', 'chan', 'chen', 'chang', 'cheng', 'chong', 'chu', 'chuo', 'chuai', 'chui', 'chuan', 'chun', 'chuang', 'sha', 'she', 'shi', 'shai', 'shei', 'shao', 'shou', 'shan', 'shen', 'shang', 'sheng', 'shu', 'shua', 'shuo', 'shuai', 'shui', 'shuan', 'shun', 'shuang', 're', 'ri', 'rao', 'rou', 'ran', 'ren', 'rang', 'reng', 'rong', 'ru', 'ruo', 'rui', 'ruan', 'run', 'za', 'ze', 'zi', 'zai', 'zei', 'zao', 'zou', 'zan', 'zen', 'zang', 'zeng', 'zong', 'zu', 'zuo', 'zui', 'zuan', 'zun', 'ca', 'ce', 'ci', 'cai', 'cao', 'cou', 'can', 'cen', 'cang', 'ceng', 'cong', 'cu', 'cuo', 'cui', 'cuan', 'cun', 'sa', 'se', 'si', 'sai', 'sao', 'sou', 'san', 'sen', 'sang', 'seng', 'song', 'su', 'suo', 'sui', 'suan', 'sun', 'a', 'o', 'e', 'er', 'ai', 'ei', 'ao', 'ou', 'an', 'en', 'ang', 'eng', 'yi', 'ya', 'ye', 'yao', 'you', 'yan', 'yin', 'yang', 'ying', 'yong', 'wu', 'wa', 'wo', 'wai', 'wei', 'wan', 'wen', 'wang', 'weng', 'yu', 'yue', 'yuan', 'yun']
```

既然如此，那我们就可以通过暴力枚举，统计文本中的拼音组合个数和英文单词个数，并且进行比较，若拼音组合个数更多，那么就判为拼音，否则就判为英语。

同时补充一点，不要过度纠结拼音组合表，因为它不需要特别完美全面，只要覆盖大部分拼音组合即可。

至于英文单词和拼音组合相同，被误判为拼音的问题，完全不需要担心，因为这个误差很小，并不会影响最终答案。

## 代码实现

代码非常好写，注意输入部分和打表部分即可，下面是我的满分代码：

```python
# 定义拼音组合表
pinyin = ['ba', 'bo', 'bai', 'bei', 'bao', 'ban', 'ben', 'bang', 'beng', 'bi', 'bie', 'biao', 'bian', 'bin', 'bing', 'bu', 'pa', 'po', 'pai', 'pei', 'pao', 'pou', 'pan', 'pen', 'pang', 'peng', 'pi', 'pie', 'piao', 'pian', 'pin', 'ping', 'pu', 'ma', 'mo', 'mai', 'mei', 'mao', 'mou', 'man', 'men', 'mang', 'meng', 'mi', 'mie', 'miao', 'miu', 'mian', 'min', 'ming', 'mu', 'fa', 'fo', 'me', 'fei', 'fou', 'fan', 'fen', 'fang', 'feng', 'fu', 'da', 'de', 'dai', 'dei', 'dao', 'dou', 'dan', 'den', 'dang', 'deng', 'dong', 'di', 'dia', 'die', 'diao', 'diu', 'dian', 'ding', 'du', 'duo', 'dui', 'duan', 'dun', 'ta', 'te', 'tai', 'tei', 'tao', 'tou', 'tan', 'tang', 'teng', 'tong', 'ti', 'tie', 'tiao', 'tian', 'ting', 'tu', 'tuo', 'tui', 'tuan', 'tun', 'na', 'ne', 'nai', 'nei', 'nao', 'nou', 'nan', 'nen', 'nang', 'neng', 'nong', 'ni', 'nie', 'niao', 'niu', 'nian', 'nin', 'niang', 'ning', 'nu', 'nuo', 'nuan', 'nv', 'nve', 'la', 'le', 'lai', 'lei', 'lao', 'lou', 'lan', 'lang', 'leng', 'long', 'li', 'lia', 'lie', 'liao', 'liu', 'lian', 'lin', 'liang', 'ling', 'lu', 'luo', 'luan', 'lun', 'lv', 'lve', 'ga', 'ge', 'gai', 'gei', 'gao', 'gou', 'gan', 'gen', 'gang', 'geng', 'gong', 'gu', 'gua', 'guo', 'guai', 'gui', 'guan', 'gun', 'guang', 'ka', 'ke', 'kai', 'kao', 'kou', 'kan', 'ken', 'kang', 'keng', 'kong', 'ku', 'kua', 'kuo', 'kuai', 'kui', 'kuan', 'kun', 'kuang', 'ha', 'he', 'hai', 'hei', 'hao', 'hou', 'han', 'hen', 'hang', 'heng', 'hong', 'hu', 'hua', 'huo', 'huai', 'hui',
          'huan', 'hun', 'huang', 'ji', 'jia', 'jie', 'jiao', 'jiu', 'jian', 'jin', 'jiang', 'jing', 'jiong', 'ju', 'jue', 'juan', 'jun', 'qi', 'qia', 'qie', 'qiao', 'qiu', 'qian', 'qin', 'qiang', 'qing', 'qiong', 'qu', 'que', 'quan', 'qun', 'xi', 'xia', 'xie', 'xiao', 'xiu', 'xian', 'xin', 'xiang', 'xing', 'xiong', 'xu', 'xue', 'xuan', 'xun', 'zha', 'zhe', 'zhi', 'zhai', 'zhei', 'zhao', 'zhou', 'zhan', 'zhen', 'zhang', 'zheng', 'zhong', 'zhu', 'zhua', 'zhuo', 'zhuai', 'zhui', 'zhuan', 'zhun', 'zhuang', 'cha', 'che', 'chi', 'chai', 'chao', 'chou', 'chan', 'chen', 'chang', 'cheng', 'chong', 'chu', 'chuo', 'chuai', 'chui', 'chuan', 'chun', 'chuang', 'sha', 'she', 'shi', 'shai', 'shei', 'shao', 'shou', 'shan', 'shen', 'shang', 'sheng', 'shu', 'shua', 'shuo', 'shuai', 'shui', 'shuan', 'shun', 'shuang', 're', 'ri', 'rao', 'rou', 'ran', 'ren', 'rang', 'reng', 'rong', 'ru', 'ruo', 'rui', 'ruan', 'run', 'za', 'ze', 'zi', 'zai', 'zei', 'zao', 'zou', 'zan', 'zen', 'zang', 'zeng', 'zong', 'zu', 'zuo', 'zui', 'zuan', 'zun', 'ca', 'ce', 'ci', 'cai', 'cao', 'cou', 'can', 'cen', 'cang', 'ceng', 'cong', 'cu', 'cuo', 'cui', 'cuan', 'cun', 'sa', 'se', 'si', 'sai', 'sao', 'sou', 'san', 'sen', 'sang', 'seng', 'song', 'su', 'suo', 'sui', 'suan', 'sun', 'a', 'o', 'e', 'er', 'ai', 'ei', 'ao', 'ou', 'an', 'en', 'ang', 'eng', 'yi', 'ya', 'ye', 'yao', 'you', 'yan', 'yin', 'yang', 'ying', 'yong', 'wu', 'wa', 'wo', 'wai', 'wei', 'wan', 'wen', 'wang', 'weng', 'yu', 'yue', 'yuan', 'yun']

# 输入任务数量
t = int(input())

for q in range(t):
    # 读入单词个数和单词列表
    ls = input().split()
    n = int(ls[0])
    word = ls[1:]
    # 定义统计次数的变量，先假设全部为英文单词
    en=len(word)
    zh=0
    # 枚举每个词语
    for i in word:
        # 枚举每个拼音组合
        for j in pinyin:
            # 判断词语和拼音组合是否相同，如果相同就累加拼音组合个数，减少英文单词个数
            if i==j:
                zh+=1
                en-=1
    # 比较出现次数，输出答案
    if zh>en:
        print("Pinyin")
    else:
        print("English")
```

---

## 作者：GZXUEXUE (赞：2)

### 思路

我们直接把所有的拼音打表（你可以看[这个](https://img1.baidu.com/it/u=3261480863,2963823551&fm=253&fmt=auto&app=138&f=JPEG?w=800&h=1260)或者像我一样照着新华字典抄，注意 `ü` 记作 `v`），然后判断即可。

代码时间复杂度为 $O(Tn \log m)$，其中 $m$ 是拼音字符集大小。

### 实现

```cpp
# include <iostream>
# include <set>
using namespace std;
set<string> py = {"a","ai","an","ang","ao","ba","bai","ban","bang","bao","bei","ben","beng","bi","bian","biao","bie","bin","bing","bo","bu","ca","cai","can","cang","cao","ce","cen","ceng","cha","chai","chan","chang","chao","che","chen","cheng","chi","chong","chou","chu","chua","chuai","chuan","chuang","chui","chun","chuo","ci","cong","cou","cu","cuan","cui","cun","cuo","da","dai","dan","dang","dao","de","dei","den","deng","di","dian","diao","die","ding","diu","dong","dou","du","duan","dui","dun","duo","e","ei","en","eng","er","fa","fan","fang","fei","fen","feng","fo","fou","fu","ga","gai","gan","gang","gao","ge","gei","gen","geng","gong","gou","gu","gua","guai","guan","guang","gui","gun","guo","ha","hai","han","hang","hao","he","hei","hen","heng","hong","hou","hu","hua","huai","huan","huang","hui","hun","huo","ji","jia","jian","jiang","jiao","jie","jin","jing","jiong","jiu","ju","juan","jue","jun","ka","kai","kan","kang","kao","ke","ken","keng","kong","kou","ku","kua","kuai","kuan","kuang","kui","kun","kuo","la","lai","lan","lang","lao","le","lei","leng","li","lia","lian","liang","liao","lie","lin","ling","liu","long","lou","lu","lv","luan","lve","lun","luo","ma","mai","man","mang","mao","me","mei","men","meng","mi","mian","miao","mie","min","ming","miu","mo","mou","mu","na","nai","nan","nang","nao","ne","nei","nen","neng","ni","nian","niang","niao","nie","nin","ning","niu","nong","nou","nu","nv","nuan","nve","nuo","o","ou","pa","pai","pan","pang","pao","pei","pen","peng","pi","pian","piao","pie","pin","ping","po","pou","pu","qi","qia","qian","qiang","qiao","qie","qin","qing","qiong","qiu","qu","quan","que","qun","ran","rang","rao","re","ren","reng","ri","rong","rou","ru","ruan","rui","run","ruo","sa","sai","san","sang","sao","se","sen","seng","sha","shai","shan","shang","shao","she","shei","shen","sheng","shi","shou","shu","shua","shuai","shuan","shuang","shui","shun","shuo","si","song","sou","su","suan","sui","sun","suo","ta","tai","tan","tang","tao","te","teng","ti","tian","tiao","tie","ting","tong","tou","tu","tuan","tui","tun","tuo","wa","wai","wan","wang","wei","wen","weng","wo","wu","xi","xia","xian","xiang","xiao","xie","xin","xing","xiong","xiu","xu","xuan","xue","xun","ya","yan","yang","yao","ye","yi","yin","ying","yong","you","yu","yuan","yue","yun","za","zai","zan","zang","zao","ze","zei","zen","zeng","zha","zhai","zhan","zhang","zhao","zhe","zhei","zhen","zheng","zhi","zhong","zhou","zhu","zhua","zhuai","zhuan","zhuang","zhui","zhun","zhuo","zi","zong","zou","zu","zuan","zui","zun","zuo"};
int main(){
    int T; cin >> T;
    while (T--){
        int n; cin >> n;
        string s; bool pinyin = true;
        for (int i = 0;i < n;++i){
            cin >> s;
            if (!py.count(s)) pinyin = false;
        }cout << (pinyin ? "Pinyin" : "English") << endl;
    }return 0;
}
```

### 感谢

感谢 @[LionBlaze](https://www.luogu.com.cn/user/911054) 以及 @[dg114514](https://www.luogu.com.cn/user/1373205) 指正！

---

## 作者：封禁用户 (赞：2)

这道题让我们判断一篇文章是用拼音写的还是英语写的。

一般来说，一定是英语的情况有这几种：

* 出现 $7$ 个字母及以上的单词。汉语拼音中最长的拼音长度也只有 $6$（有 $3$ 个，分别是 `chuang`、`zhuang` 和 `shuang`），因此 $7$ 个字母及以上的单词可以直接判掉。如果单词 $6$ 个字母但是末尾不是 `huang`，也可以直接判掉。
* 出现 `i`、`is`、`am`、`are` 这些常见英文单词。
* 出现子串 `th`。在汉语中任何拼音都没有子串 `th`，所以看到子串 `th` 就知道是英语。

有几个注意事项：

* `str.size()` 返回的是 `unsigned int`！
* 确定了一篇文章后不要直接 `break`，因为本题是多测，后面可能还有字符串没读。

放上代码：

```cpp
#include<bits/stdc++.h>
using namespace std;
#define endl "\n"
typedef long long ll;
typedef pair<int,int> pii;
bool eng;
int main(){
	ios::sync_with_stdio(false);cin.tie(0);cout.tie(0);
	int T;
	cin>>T;
	while(T--){
		eng=false;
		int n;
		cin>>n;
		for(int i=1;i<=n;i++){
			string s;
			cin>>s;
			if(s.size()>6||(s.size()==6&&s.substr(1,5)!="huang")||s=="i"||s=="is"||s=="am"||s=="are"||s=="in"||s=="or"||s=="and"||s=="if"||s=="be"||s=="no")eng=true;
            for(int i=0;i<=(int)s.size()-2;i++)if(s.substr(i,2)=="th")eng=true;
		}
		if(eng)puts("English");
		else puts("Pinyin");
	}
}
```

---

## 作者：easy42 (赞：2)

[English](https://www.luogu.com.cn/article/szw7cmpo).

让我们挖掘直觉。

拼音中没有 `th`，但英语中却很常见，如 `th` `these` 等。

直接判断即可。

代码：

使用了 `getline` 和 `find` 函数，代码极短。

```cpp
#include<bits/stdc++.h>
using namespace std;
int t,n;
string s;
int main(){
	cin>>t;
	while(t--){
		cin>>n;
		getline(cin,s);
		if(int(s.find("th"))!=-1) cout<<"English\n";
		else cout<<"Pinyin\n";
	}
	return 0;
}
```

---

## 作者：a202401006 (赞：2)

[题目传送门](https://www.luogu.com.cn/problem/B3759)
# 解析
## 题目大意
几行测试数据，有的是全用拼音组成的，有的是全用英文单词组成的，判断是中文拼音还是英文单词组成的。
## 考察知识
本题考查字符串的运用。
## 思路
**给一个新颖的思路。**

单独输入每一行，由于拼音中最长的拼音是六个字符组成的，所以可以判断是否句子中有单词为六个字符以上所组成，若是，则为英文，否则为拼音，判断代码如下。

```cpp
bool english=false;//定义bool型数据判断是否为英语 
int n;//表示有多少个“单词” 
cin>>n;//输入“单词”数 
for(int i=1;i<=n;i++)//逐步输入单词 
{
    string s;//用字符串型，省略空格 
    cin>>s;//直接输入 
    if(s.size()>6)//判断是否“单词”长度大于6，因为在拼音中，最长的拼音是6个字符（例如：装zhuang），（其实是数据太水，因为也可以有hack数据：Is it you） 
    {
	english=true;//设为真 
    }
}
```
# 代码
注释版如下。

```cpp
#include<bits/stdc++.h>
using namespace std;
int t;//测试数据数量 
int main()
{
	cin>>t;//输入 
    while(t--)//就是循环t次 
    {
		
    	bool english=false;//定义bool型数据判断是否为英语 
	    int n;//表示有多少个“单词” 
		cin>>n;//输入“单词”数 
	    for(int i=1;i<=n;i++)//逐步输入单词 
	    {
	    	string s;//用字符串型，省略空格 
			cin>>s;//直接输入 
	        if(s.size()>6)//判断是否“单词”长度大于6，因为在拼音中，最长的拼音是6个字符（例如：装zhuang），（其实是数据太水，因为也可以有hack数据：Is it you） 
			{
				english=true;//设为真 
			}
	    }
	    if(english)//如果真 
	    {
	    	cout<<"English"<<endl;
		}
		else
		{
			cout<<"Pinyin"<<endl;
		}
		/*输出*/
	}
}
```
无注释版如下。

```cpp
#include<bits/stdc++.h>
using namespace std;
int t;
int main()
{
    cin>>t;
    while(t--) 
    {
		
    	bool english=false;
    	int n; 
    	cin>>n;
    	for(int i=1;i<=n;i++)
      {
    	    string s;
    	    cin>>s;
    	    if(s.size()>6)
    	    {
          		english=true;
    	    }
    	}
    	if(english)
    	{
    	    cout<<"English"<<endl;
      }
    	else
    	{
            cout<<"Pinyin"<<endl;
    	}	
    }
}
```

---

## 作者：kunkun127 (赞：2)

## 题意

给你一个小文段，看它是英文还是拼音。

并不难理解，难在代码实现。

## 思路

我们直接看样例，很容易发现给我们的提示：

- `zhe ge ti mu qi shi bi ni xiang xiang de yao jian dan`，很容易辨认出汉字形式为：`这个题目其实比你想想的要简单`。~~但是为什么有两个 `想`？~~
- `this problem has a simple solution`，英文翻译后得到：`这个问题有一个简单的解决方式`。

因此，我们不妨想想拼音和英文的不同之处。

知识渊博的读者可能已经想到单词长度这方面。英文单词有十分长的，例如 `Hippopotomonstrosesquippedaliophobia`，$36$ 个字母它正代表着 `长单词恐惧症`。但是拼音最长长度只有 $6$，例如 `双`，拼音为 `shuang`。因此我们直接根据直觉：单词长度大于 $6$ 即判定为英文，反之则为拼音。

## 参考代码

```cpp
#include <bits/stdc++.h>
using namespace std;

void solve()
{
    bool isE = false;
    int n; cin >> n;
    for (int i = 1; i <= n; i++)
    {
        string s; cin >> s;
        if (s.size() > 6) isE = true;
    }
    cout << (isE ? "English" : "Pinyin") << endl;
}

int main()
{
    int t; cin >> t;
    while (t--) solve();
    return 0;
}
```

### 最稳的做法

当你在考场上觉得没什么事做的时候，又正好有这一题，你可以试着把所有拼音的组成方式打出来。前提是你的语文够好。或者说可以加一层保险，特判英文常用，而拼音又没有的字母组合。例如：`th`。但是根据样例，我们也可以信任出题人，这题并没有这么复杂。

---

## 作者：lby_commandBlock (赞：1)

## 思路

注意到拼音的最长长度为 $6$（如 `shuang`），所以判断一下一段拼音的长度与 $6$ 的大小关系即可。

## 代码

```cpp
#include <bits/stdc++.h>
#define endl '\n'
using namespace std;

int T, n;

string s;

void slove() {
	cin >> n;
	bool flag = true;
	for (int i = 1; i <= n; i++) {
		cin >> s;
		if (s.size() > 6)
			flag = false;
	}
	if (flag)
		cout << "Pinyin" << endl;
	else
		cout << "English" << endl;
}

int main() {
	ios::sync_with_stdio(false);
	cin.tie(0);
	cin >> T;
	while (T--) 
		slove();
	return 0;
}
```

---

## 作者：jiqihang (赞：1)

### 题目链接
[B3759 [信息与未来 2021] 文本分类](https://www.luogu.com.cn/problem/B3759)
### 题意
给定 $T$ 个字符串，判断这些字符串是拼音还是英文。
### 分析
样例中为拼音的那句翻译后是：这个题目其实比你想想的要简单。

英文那句翻译后是：这个问题有一个简单的解决方式。

根据这个，这题肯定有好的快速的解法。

众所周知，拼音最长只有 $6$ 个字符。

而英语单词字符数大多大于 $6$ 个。

我们赌一把，只要一句话有单词字符数大于 $6$ 个，就是英语，对了，太意外了。
### 代码

```cpp
#include<bits/stdc++.h>
using namespace std;
int main()
{
    int t; 
	cin>>t;
    while(t--) 
	{
		bool pd=0;
		int n; 
		cin>>n;
        for(int i=1;i<=n;i++)
        {
            string s;
			cin>>s;
            if(s.size()>6) pd=1;
    }
    if(pd==1) cout<<"English"<<endl;
    else cout<<"Pinyin"<<endl;
	}
    return 0;
}
```

---

## 作者：Danny_chan (赞：1)

我们发现，一个拼音是不会超过 $6$ 个字符的，所以我们可以通过判断一段词有没有超过 $6$ 个字符的词组看是拼音还是英文。

代码：

```cpp
#include<bits/stdc++.h> 
using namespace std;
string s;
int t;
bool f=false;
int main() {
	cin>>t;
	while(t--) {
		int n;
		cin>>n;
		f=false;
		while(n--) {
			cin>>s;
			if(s.size()>6) {
				f=true;
			} 
		}
		if(f==true){
			cout<<"English"<<endl;
		}
		else{
			
			cout<<"Pinyin"<<endl;
		}
	}
	return 0;
}
```
但是我们发现，有一些特殊的样例会卡掉这种做法，所以我们可以用打表来解决这种问题，代码就不贴了，相信大家都会写。

---

## 作者：wurang (赞：1)

这题其实是一道模拟，如果文本中有一个字符串是英文，那么文本肯定是英文，否则是拼音。

两个需要注意的点：

- 汉语拼音表必须准确无误。
- 如果已经判断有英文单词，一定不能提前跳出，否则剩下本应读入的字符串将会影响下一组测试的判断。

```cpp
#include <bits/stdc++.h>
using namespace std;
const int len = 416;
string py[416]={
	"a", "ai", "an", "ang", "ao", "ba", "bai", "ban", "bang", "bao", "bei", "ben", "beng", "bi", "bian", "biao", "bie", "bin", "bing", "bo", "bu",
    "ca", "cai", "can", "cang", "cao", "ce", "cen", "ceng", "cha", "chai", "chan", "chang", "chao", "che", "chen", "cheng", "chi", "chong", "chou", "chu", "chua", "chuai", "chuan", "chuang", "chui", "chun", "chuo", "ci", "cong", "cou", "cu", "cuan", "cui", "cun", "cuo",
    "da", "dai", "dan", "dang", "dao", "de", "dei", "den", "deng", "di", "dian", "diao", "die", "ding", "diu", "dong", "dou", "du", "duan", "dui", "dun", "duo",
    "e", "ei", "en", "eng", "er",
    "fa", "fan", "fang", "fei", "fen", "feng", "fo", "fou", "fu",
    "ga", "gai", "gan", "gang", "gao", "ge", "gei", "gen", "geng", "gong", "gou", "gu", "gua", "guai", "guan", "guang", "gui", "gun", "guo",
    "ha", "hai", "han", "hang", "hao", "he", "hei", "hen", "heng", "hong", "hou", "hu", "hua", "huai", "huan", "huang", "hui", "hun", "huo",
    "ji", "jia", "jian", "jiang", "jiao", "jie", "jin", "jing", "jiong", "jiu", "ju", "juan", "jue", "jun",
    "ka", "kai", "kan", "kang", "kao", "ke", "ken", "keng", "kong", "kou", "ku", "kua", "kuai", "kuan", "kuang", "kui", "kun", "kuo",
    "la", "lai", "lan", "lang", "lao", "le", "lei", "leng", "li", "lia", "lian", "liang", "liao", "lie", "lin", "ling", "liu", "long", "lou", "lu", "lv", "luan", "lve", "lun", "luo",
    "ma", "mai", "man", "mang", "mao", "me", "mei", "men", "meng", "mi", "mian", "miao", "mie", "min", "ming", "miu", "mo", "mou", "mu",
    "na", "nai", "nan", "nang", "nao", "ne", "nei", "nen", "neng", "ni", "nian", "niang", "niao", "nie", "nin", "ning", "niu", "nong", "nou", "nu", "nv", "nuan", "nve", "nuo",
    "o", "ou",
    "pa", "pai", "pan", "pang", "pao", "pei", "pen", "peng", "pi", "pian", "piao", "pie", "pin", "ping", "po", "pou", "pu",
    "qi", "qia", "qian", "qiang", "qiao", "qie", "qin", "qing", "qiong", "qiu", "qu", "quan", "que", "qun",
    "ran", "rang", "rao", "re", "ren", "reng", "ri", "rong", "rou", "ru", "ruan", "rui", "run", "ruo",
    "sa", "sai", "san", "sang", "sao", "se", "sen", "seng", "sha", "shai", "shan", "shang", "shao", "she", "shei", "shen", "sheng", "shi", "shou", "shu", "shua", "shuai", "shuan", "shuang", "shui", "shun", "shuo", "si", "song", "sou", "su", "suan", "sui", "sun", "suo",
    "ta", "tai", "tan", "tang", "tao", "te", "teng", "ti", "tian", "tiao", "tie", "ting", "tong", "tou", "tu", "tuan", "tui", "tun", "tuo",
    "wa", "wai", "wan", "wang", "wei", "wen", "weng", "wo", "wu",
    "xi", "xia", "xian", "xiang", "xiao", "xie", "xin", "xing", "xiong", "xiu", "xu", "xuan", "xue", "xun",
    "ya", "yan", "yang", "yao", "ye", "yi", "yin", "ying", "yong", "you", "yu", "yuan", "yue", "yun",
    "za", "zai", "zan", "zang", "zao", "ze", "zei", "zen", "zeng", "zha", "zhai", "zhan", "zhang", "zhao", "zhe", "zhei", "zhen", "zheng", "zhi", "zhong", "zhou", "zhu", "zhua", "zhuai", "zhuan", "zhuang", "zhui", "zhun", "zhuo", "zi", "zong", "zou", "zu", "zuan", "zui", "zun", "zuo"
};

bool f;
int t,n;
string s;
int sum1,sum2;

int main()
{
	cin >> t;
	while(t--)
	{
        f = true;//默认没有英文单词 
		cin >> n;
		for(int i = 1; i <= n; i++)
		{
			cin >> s;
			bool flag = false;//默认该字符串非拼音
			for(int j = 0; j < len; j++)
			{
				if(s == py[j])//这个字符串是拼音 
				{
					flag = true;//记录
					break;
				}
			}
			if(!flag)f = false;//非拼音，则有英文单词
		}
		if(f)//没有英文单词 
			cout << "Pinyin\n";//拼音  
		else//有英文单词 
			cout << "English\n";//英语
	}
	return 0;
}
```

---

## 作者：wmrqwq (赞：1)

# 题目链接

[B3759 [信息与未来 2021] 文本分类](https://www.luogu.com.cn/problem/B3759)

# 解题思路

你是一名 OIer，在 5202J-PSC 的第一题，你看到了辨别一段文字是否为拼音的题目。

考场上，你发现你迅速会了一个暴力做法，直接暴力打表拼音即可。

考完之后，由于样例太水，你发现你挂分了。

赛后，你发现有人直接特判长度是否 $\le 6$ 来通过此题。

这一世，你重生了，重生在了考场上。

你发现不能像上一次一样判所有拼音，直接判断高频字符即可，于是你做完了，这次，你通过了这道题。

# 参考代码

```cpp
void solve()
{
    _clear();
	cin>>n;
	forl(i,1,n)
		cin>>s[i];
	forl(i,1,n)
		if(s[i]=="the" || s[i]=="this" || s[i]=="they" || s[i]=="but" || s[i]=="however" || s[i]=="i" || s[i]=="are" || s[i]=="is" || s[i]=="and" || s[i]=="to" || s[i]=="be" || s[i]=="for")
		{
			cout<<"English\n";
			return ;
		}
	forl(i,1,n)
		if(s[i].back()=='s')
		{
			cout<<"English\n";
			return ;
		}
	cout<<"Pinyin\n";
}
```

---


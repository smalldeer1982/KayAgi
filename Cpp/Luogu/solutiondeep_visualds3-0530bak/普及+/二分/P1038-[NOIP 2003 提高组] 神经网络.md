# 题目信息

# [NOIP 2003 提高组] 神经网络

## 题目背景

人工神经网络（Artificial Neural Network）是一种新兴的具有自我学习能力的计算系统，在模式识别、函数逼近及贷款风险评估等诸多领域有广泛的应用。对神经网络的研究一直是当今的热门方向，兰兰同学在自学了一本神经网络的入门书籍后，提出了一个简化模型，他希望你能帮助他用程序检验这个神经网络模型的实用性。



## 题目描述

在兰兰的模型中，神经网络就是一张有向图，图中的节点称为神经元，而且两个神经元之间至多有一条边相连，下图是一个神经元的例子：

![](https://cdn.luogu.com.cn/upload/image_hosting/61qm40kj.png)

神经元（编号为 $i$）


图中，$X_1 \sim X_3$ 是信息输入渠道，$Y_1 \sim Y_2$ 是信息输出渠道，$C_i$ 表示神经元目前的状态，$U_i$ 是阈值，可视为神经元的一个内在参数。

神经元按一定的顺序排列，构成整个神经网络。在兰兰的模型之中，神经网络中的神经元分为几层；称为输入层、输出层，和若干个中间层。每层神经元只向下一层的神经元输出信息，只从上一层神经元接受信息。下图是一个简单的三层神经网络的例子。

![](https://cdn.luogu.com.cn/upload/image_hosting/4xd7f8yz.png)

兰兰规定，$C_i$ 服从公式：（其中 $n$ 是网络中所有神经元的数目）

$$C_i=\left(\sum\limits_{(j,i) \in E} W_{ji}C_{j}\right)-U_{i}$$

公式中的 $W_{ji}$（可能为负值）表示连接 $j$ 号神经元和 $i$ 号神经元的边的权值。当 $C_i$ 大于 $0$ 时，该神经元处于兴奋状态，否则就处于平静状态。当神经元处于兴奋状态时，下一秒它会向其他神经元传送信号，信号的强度为 $C_i$。

如此．在输入层神经元被激发之后，整个网络系统就在信息传输的推动下进行运作。现在，给定一个神经网络，及当前输入层神经元的状态（$C_i$），要求你的程序运算出最后网络输出层的状态。



## 说明/提示

**【题目来源】**

NOIP 2003 提高组第一题

## 样例 #1

### 输入

```
5 6
1 0
1 0
0 1
0 1
0 1
1 3 1
1 4 1
1 5 1
2 3 1
2 4 1
2 5 1
```

### 输出

```
3 1
4 1
5 1
```

# AI分析结果



# 神经网络题解分析与可视化设计

## 算法分类
**无算法分类（拓扑排序）**

---

## 题解思路与难点分析

### 核心思路
1. **拓扑排序框架**：所有题解均基于拓扑排序处理神经元激活顺序，按层传递信号。
2. **阈值处理**：非输入层神经元初始时直接减去阈值`U[i]`，输入层保留原值。
3. **队列优化**：使用队列维护激活节点，仅当节点的输入信号累加完毕且状态>0时传递信号。
4. **输出层判断**：出度为0的节点为输出层，且最终状态需>0才输出。

### 解决难点对比
| 难点                | Lucaster_解法                     | zzlzk解法                        |
|---------------------|-----------------------------------|----------------------------------|
| 输入层处理          | 初始状态>0直接入队，不减U          | 公式变形，预处理非输入层的U减法  |
| 信号传递条件        | 仅当`c[h]>0`时向下传递            | 通过公式保证仅激活节点参与计算   |
| 输出排序            | 结构体排序输出                    | 遍历时按编号顺序输出             |
| 队列去重            | `vis[]`数组标记已入队节点          | 隐式保证（依赖拓扑顺序）         |

---

## 题解评分（≥4星）

### 1. Lucaster_（⭐⭐⭐⭐⭐）
- **亮点**：代码结构清晰，预处理U减法，队列去重逻辑严谨。
- **关键代码**：
  ```cpp
  if(c[h]>0) {
    for(边遍历) c[t] += w * c[h];
    if(!vis[t]) q.push(t);
  }
  ```

### 2. zzlzk（⭐⭐⭐⭐）
- **亮点**：公式推导简化实现，直接处理非输入层U值。
- **关键点**：`C[i] + U[i] = Σ(Wji*Cj)`，预处理减法。

### 3. teafrogsf（⭐⭐⭐⭐）
- **亮点**：反向建图记忆化搜索，递归实现拓扑逻辑。
- **代码片段**：
  ```cpp
  int DFS(int p){
    if(vis[p]) return c[p];
    for(前驱节点) c[p] += DFS(前驱) * w;
    return max(0, c[p] - U[p]);
  }
  ```

---

## 最优技巧提炼
1. **预处理阈值**：非输入层初始时直接`c[i] -= u[i]`，避免后续重复判断。
2. **队列去重**：通过`vis[]`数组确保每个节点只入队一次，防止重复计算。
3. **输出层快速判断**：记录节点的出度，出度=0即为输出层。

---

## 同类型题与算法套路
- **拓扑排序应用场景**：任务调度、依赖解析、课程安排。
- **类似题目**：
  - 洛谷P1113（杂物）：拓扑排序计算最长路径。
  - 洛谷P4017（最大食物链计数）：DAG上的拓扑DP。
  - 洛谷P1983（车站分级）：层级划分与拓扑排序。

---

## 可视化设计（复古像素风格）

### 动画方案
1. **节点表示**：8位像素风格神经元，颜色区分状态：
   - **绿色**：已激活（C>0）
   - **红色**：平静（C≤0）
   - **黄色边框**：当前处理的节点
2. **队列动态**：右侧显示队列中的节点ID，入队时像素方块弹出效果。
3. **信号传递**：处理节点时，与其连接的边高亮显示，传递数值以像素粒子动画呈现。

### 交互设计
- **控制面板**：暂停/继续、步进模式、速度滑块。
- **音效**：
  - 节点激活：8-bit "哔"声。
  - 队列更新：短促"滴"声。
  - 错误提示：低频"嗡"声。

### 核心代码片段（Canvas动画）
```javascript
// 绘制神经元节点
function drawNode(ctx, node, x, y) {
  ctx.fillStyle = node.c > 0 ? '#00FF00' : '#FF0000';
  ctx.fillRect(x, y, 32, 32);
  if (node.isProcessing) {
    ctx.strokeStyle = '#FFFF00';
    ctx.strokeRect(x-2, y-2, 36, 36);
  }
}

// 队列更新动画
function animateQueue(queue) {
  queue.forEach((id, index) => {
    const x = 400 + index * 40;
    drawNode(ctx, nodes[id], x, 50);
  });
}
```

---

## 个人心得摘录
- **Lucaster_**：调试中发现输入层U未正确处理，通过预减U解决。
- **zzlzk**：公式变形后减少条件判断，代码量降低30%。
- **hibiki**：初始误以为输入层需特殊处理U，导致WA多次。

---
处理用时：67.29秒
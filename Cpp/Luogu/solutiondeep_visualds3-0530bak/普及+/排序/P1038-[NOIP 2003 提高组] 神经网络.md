# 题目信息

# [NOIP 2003 提高组] 神经网络

## 题目背景

人工神经网络（Artificial Neural Network）是一种新兴的具有自我学习能力的计算系统，在模式识别、函数逼近及贷款风险评估等诸多领域有广泛的应用。对神经网络的研究一直是当今的热门方向，兰兰同学在自学了一本神经网络的入门书籍后，提出了一个简化模型，他希望你能帮助他用程序检验这个神经网络模型的实用性。



## 题目描述

在兰兰的模型中，神经网络就是一张有向图，图中的节点称为神经元，而且两个神经元之间至多有一条边相连，下图是一个神经元的例子：

![](https://cdn.luogu.com.cn/upload/image_hosting/61qm40kj.png)

神经元（编号为 $i$）


图中，$X_1 \sim X_3$ 是信息输入渠道，$Y_1 \sim Y_2$ 是信息输出渠道，$C_i$ 表示神经元目前的状态，$U_i$ 是阈值，可视为神经元的一个内在参数。

神经元按一定的顺序排列，构成整个神经网络。在兰兰的模型之中，神经网络中的神经元分为几层；称为输入层、输出层，和若干个中间层。每层神经元只向下一层的神经元输出信息，只从上一层神经元接受信息。下图是一个简单的三层神经网络的例子。

![](https://cdn.luogu.com.cn/upload/image_hosting/4xd7f8yz.png)

兰兰规定，$C_i$ 服从公式：（其中 $n$ 是网络中所有神经元的数目）

$$C_i=\left(\sum\limits_{(j,i) \in E} W_{ji}C_{j}\right)-U_{i}$$

公式中的 $W_{ji}$（可能为负值）表示连接 $j$ 号神经元和 $i$ 号神经元的边的权值。当 $C_i$ 大于 $0$ 时，该神经元处于兴奋状态，否则就处于平静状态。当神经元处于兴奋状态时，下一秒它会向其他神经元传送信号，信号的强度为 $C_i$。

如此．在输入层神经元被激发之后，整个网络系统就在信息传输的推动下进行运作。现在，给定一个神经网络，及当前输入层神经元的状态（$C_i$），要求你的程序运算出最后网络输出层的状态。



## 说明/提示

**【题目来源】**

NOIP 2003 提高组第一题

## 样例 #1

### 输入

```
5 6
1 0
1 0
0 1
0 1
0 1
1 3 1
1 4 1
1 5 1
2 3 1
2 4 1
2 5 1
```

### 输出

```
3 1
4 1
5 1
```

# AI分析结果



## 唯一算法分类
**拓扑排序**

---

## 综合分析与结论
### 核心算法流程
1. **预处理阈值**  
   - 输入层的神经元状态无需减去阈值（`U[i]`），其他层在初始化时直接减去阈值
2. **拓扑排序传播信号**  
   - 用队列维护激活的神经元（初始为输入层节点）
   - 遍历邻接表，若当前神经元处于激活状态（`C[i] > 0`），则向下一层传播信号
3. **输出层筛选**  
   - 出度为0的神经元为输出层
   - 仅输出状态 `C[i] > 0` 的神经元，按编号升序排列

### 可视化设计思路
1. **像素风格呈现**  
   - 使用 8-bit 像素画风，神经元显示为方块，输入层用绿色，中间层黄色，输出层红色
   - 信号传播时，连线上显示权重值，传播路径用闪烁动画表示
2. **动画控制**  
   - 步进模式：按空格键单步执行拓扑排序流程
   - 自动播放模式：用滑动条控制动画速度（0.5x~3x）
3. **音效反馈**  
   - 神经元激活时播放「滴」声，传播失败时播放「哔」声
   - 背景音乐采用芯片风格的 8-bit 循环旋律

---

## 题解清单 (≥4星)
1. **Lucaster_（4.5星）**  
   - 亮点：队列拓扑排序 + 邻接表存储，预处理阈值优化  
   - 关键代码：队列处理激活态神经元，动态更新下游节点状态

2. **zzlzk（4.5星）**  
   - 亮点：反向建图记忆化搜索，代码极简（仅30行）  
   - 关键思想：递归计算输出层节点的前驱贡献

3. **faker121（4星）**  
   - 亮点：显式维护入度数组，清晰展示拓扑排序过程  
   - 调试心得：因输出格式错误多次WA，最终发现NULL条件

---

## 核心代码实现
```cpp
// 邻接表拓扑传播（Lucaster_ 优化版）
queue<int> q;
for (int i=1; i<=n; i++) {
    if (c[i] > 0) { // 输入层直接入队
        q.push(i);
        vis[i] = true;
    } else if (非输入层) {
        c[i] -= u[i]; // 预处理阈值
    }
}

while (!q.empty()) {
    int u = q.front(); q.pop();
    if (c[u] <= 0) continue; // 不传播
    
    for (Edge e : adj[u]) { // 遍历邻接边
        c[e.v] += e.w * c[u];
        if (!vis[e.v]) {
            q.push(e.v);
            vis[e.v] = true;
        }
    }
}

// 输出层筛选
vector<int> output;
for (int i=1; i<=n; i++) {
    if (out_degree[i]==0 && c[i]>0)
        output.push_back(i);
}
sort(output.begin(), output.end());
```

---

## 同类型题与套路
1. **依赖顺序计算**：课程表安排（拓扑排序典型应用）
2. **分层信号传播**：模拟电路元件级联计算
3. **条件激活传播**：细胞自动机、消息广播网络

---

## 推荐题目
1. **P1113 杂务**（拓扑排序基础）  
2. **P4017 最大食物链计数**（拓扑排序+动态规划）  
3. **P1983 车站分级**（拓扑排序处理隐藏层级）

---

## 个人心得摘录
> "调了一天终于AC，输入层可能同时是输出层！测试数据第五个点卡了2小时，原来忘记判断输出层状态必须>0" —— Lucaster_

---

## 可视化代码片段（伪代码）
```javascript
// Canvas绘制神经元和连线
function drawNetwork() {
  ctx.fillStyle = '#8B8B8B'; // 灰色背景
  ctx.fillRect(0, 0, canvas.width, canvas.height);
  
  // 绘制神经元
  neurons.forEach(n => {
    ctx.fillStyle = n.active ? '#00FF00' : '#FF0000';
    ctx.fillRect(n.x, n.y, 20, 20); // 方块表示神经元
  });
  
  // 动态绘制传播连线
  if (currentEdge) {
    ctx.strokeStyle = '#FFFF00';
    ctx.beginPath();
    ctx.moveTo(currentEdge.from.x, currentEdge.from.y);
    ctx.lineTo(currentEdge.to.x, currentEdge.to.y);
    ctx.stroke();
  }
}
```

---
处理用时：72.16秒
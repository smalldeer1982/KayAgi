# 题目信息

# 英语1（eng1）- 英语作文

## 题目背景

蒟蒻 HansBug 在英语考场上，挠了无数次的头，可脑子里还是一片空白。

## 题目描述

眼下出现在 HansBug 蒟蒻面前的是一篇英语作文，然而智商捉急的 HansBug 已经草草写完了，此时他发现离考试结束还有 $40$ 分钟，于是他打算估计一下这篇共有 $M$ 个单词的英语作文的含金量如何。众所周知的是，在中高考英语作文中使用高级词汇可以有效提高文章的含金量，从而获得更好的分数。已知蒟蒻HansBug知道 $N$ 个高级词汇，该词汇为 $A_i$（词汇长度为 $L_i$ ，包含数字、大小写字母），该高级词汇的含金量为 $B_i$，则该高级词汇每出现一次便可增加 $B_i$ 的含金量。可是他脑细胞和 RP 已经消耗殆尽，所以这个伟大的任务就交给你啦！

## 说明/提示

样例 $1$ 中，共计出现了 $2$ 次`hansbug`、 $2$ 次`absi2011` 、 $1$ 次 `yyy` 、 $1$ 次`kkksc03`、 $1$ 次  `lzn` ，所以总含金量为 $1\times2+2\times4+3\times1+4\times1+100\times1=115$，对 $99$ 取模就是 $16$ 。

样例 $2$ 中，和样例 $1$ 基本一样，值得注意的是整体的 `yyyy` 不可以被认为是 `yyy` 出现 $2$ 次，请注意这是一篇英语作文，一切以单词为最小单位。

此题目中大小写敏感。

数据范围（设所有单词的最大长度为 $Lmax$ ）：

![](https://cdn.luogu.com.cn/upload/pic/2228.png)


## 样例 #1

### 输入

```
5 99
hansbug 1
kkksc03 2
yyy 3
absi2011 4
lzn 100
hansbug is a juruo!but absi2011 not.!?!
one day absi2011 laughed at yyy and hansbug.
then kkksc03 and lzn blamed him for that.
```

### 输出

```
16```

## 样例 #2

### 输入

```
5 99
yyyy 1
kkksc03 2
yyy 3
absi2011 4
lzn 100
yyyy is a juruo!but absi2011 not.!?!
one day absi2011 laughed at yyy and yyyy.
then kkksc03 and lzn blamed him for that.
```

### 输出

```
16```

# AI分析结果



### 算法分类选择
哈希表（Hash Table）

---

### 题解思路与核心难点分析
#### 核心逻辑
1. **单词分割**：正确识别由字母数字组成的单词（`isdigit(c)||isalpha(c)`），遇到分隔符时触发统计
2. **快速查找**：通过预存高级词汇的哈希值或字典结构，实现 O(1) 或 O(log n) 的查询效率
3. **模运算优化**：每次累加后立即取模，防止数值溢出

#### 关键难点对比
| 方法        | 实现复杂度 | 时间复杂度   | 空间复杂度   | 适用场景               |
|-----------|-------|---------|---------|--------------------|
| `std::map` | 低     | O(log n)| O(n)    | 代码简洁，小规模数据         |
| 哈希+二分查找 | 中     | O(1)    | O(n)    | 大规模数据，需处理哈希冲突      |
| Trie树     | 高     | O(L)    | O(AL)   | 前缀匹配场景，但空间消耗较大     |
| 排序+二分    | 中     | O(log n)| O(n)    | 无需动态更新数据，内存连续访问友好 |

---

### 题解评分（≥4星）
1. **Diamiko（4.5星）**  
   - 亮点：利用 `std::map` 实现极简代码（仅35行），通过逐字符读取自动处理单词分割  
   - 不足：未处理输入流末尾的未统计单词（但测试数据未触发此问题）

2. **BackSlashDelta（4星）**  
   - 亮点：双种子哈希减少冲突概率，二分查找保证稳定时间复杂度  
   - 不足：哈希函数设计复杂，可读性较差

3. **little_gift（4星）**  
   - 亮点：使用 `__gnu_pbds::tree` 实现红黑树，配合 `fread` 优化输入速度  
   - 不足：依赖 GNU 扩展库，跨平台兼容性受限

---

### 最优思路提炼
1. **输入流逐字符处理**  
   ```cpp
   while(scanf("%c",&c)!=EOF) {
       if(!isalnum(c)) { // 分隔符触发统计
           ans = (ans + map[word]) % mod;
           word.clear();
       } else word += c;
   }
   ```
2. **哈希冲突解决方案**  
   ```cpp
   ulint hash = (s[i] * base + (hash ^ seed1)) ^ seed2; // 两次异或增强随机性
   ```
3. **模块化单词读取**  
   ```cpp
   bool get_word() { // 独立函数处理单词提取
       while(!isalnum(c)) c=getchar();
       for(;isalnum(c);c=getchar()) str+=c;
   }
   ```

---

### 同类型题目推荐
1. **P1308 [NOIP2011 普及组] 统计单词数**  
   （字符串精确匹配与位置统计）
2. **P3370 【模板】字符串哈希**  
   （多字符串快速比对场景）
3. **P2580 于是他错误的点名开始了**  
   （Trie树经典应用场景）

---

### 可视化设计
#### 动画流程（Canvas 实现）
1. **输入预处理**  
   - 文本流以绿色方块流动进入画面
   - 非字母数字字符显示为红色障碍物，触发单词分割

2. **哈希表查询演示**  
   ```javascript
   // 伪代码示例
   function highlightHashProcess(word) {
       let hash = calculateHash(word);
       let bucket = hashtable[hash % size];
       bucket.highlightYellow(); // 高亮目标桶
       bucket.items.forEach(item => {
           if(item.word == currentWord) item.highlightGreen(); // 匹配成功
       });
   }
   ```

3. **8位像素风格要素**  
   - **调色板**：16色，采用 NES 经典绿/蓝/红配色
   - **音效**：  
     - 单词匹配成功：FC 风格 8-bit "coin" 音效（[jsfxr](https://sfxr.me/)生成）
     - 哈希冲突：短促蜂鸣声
   - **积分显示**：顶部像素字体实时更新得分，带闪烁特效

#### 交互功能
- **速度调节**：滑块控制动画速度（0.5x~5x）
- **单步调试**：空格键逐单词执行
- **视角切换**：按键1/2/3切换 map/哈希/Trie 的显示视角

---

### 核心代码片段
```cpp
// Diamiko 题解核心逻辑
string t = "";
char c;
while(scanf("%c",&c)!=EOF) {
    if(!isalnum(c)) {
        ans = (ans + a[t]) % p; // map自动处理不存在键
        t.clear();
    } else t += c;
}

// 哈希函数实现（BackSlashDelta）
ulint hashit(string s) {
    ulint val = 0;
    for(char c : s) {
        val = c * base + (val ^ seed_1);
        val ^= seed_2;
    }
    return val;
}
```

---

### 个人心得摘录
> "Trie树本是自然解法，但MLE教训让我明白**空间复杂度与数据特征的强关联性**。当单词平均长度较大时，链式存储比传统Trie更优。" —— 户山香澄

> "`fread`缓存配合指针操作，相比`cin`提速3倍以上，**输入输出优化在大数据场景下具有决定性作用**" —— little_gift

---

### 扩展思考
当需要支持模糊匹配（如拼写容错）时，可结合**BK树**（Burkhard-Keller tree）实现编辑距离检索，此时算法复杂度将上升至 O(n log n)，但极大扩展应用场景。

---
处理用时：79.40秒
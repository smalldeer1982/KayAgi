# 题目信息

# [NOIP 2003 提高组] 神经网络

## 题目背景

人工神经网络（Artificial Neural Network）是一种新兴的具有自我学习能力的计算系统，在模式识别、函数逼近及贷款风险评估等诸多领域有广泛的应用。对神经网络的研究一直是当今的热门方向，兰兰同学在自学了一本神经网络的入门书籍后，提出了一个简化模型，他希望你能帮助他用程序检验这个神经网络模型的实用性。



## 题目描述

在兰兰的模型中，神经网络就是一张有向图，图中的节点称为神经元，而且两个神经元之间至多有一条边相连，下图是一个神经元的例子：

![](https://cdn.luogu.com.cn/upload/image_hosting/61qm40kj.png)

神经元（编号为 $i$）


图中，$X_1 \sim X_3$ 是信息输入渠道，$Y_1 \sim Y_2$ 是信息输出渠道，$C_i$ 表示神经元目前的状态，$U_i$ 是阈值，可视为神经元的一个内在参数。

神经元按一定的顺序排列，构成整个神经网络。在兰兰的模型之中，神经网络中的神经元分为几层；称为输入层、输出层，和若干个中间层。每层神经元只向下一层的神经元输出信息，只从上一层神经元接受信息。下图是一个简单的三层神经网络的例子。

![](https://cdn.luogu.com.cn/upload/image_hosting/4xd7f8yz.png)

兰兰规定，$C_i$ 服从公式：（其中 $n$ 是网络中所有神经元的数目）

$$C_i=\left(\sum\limits_{(j,i) \in E} W_{ji}C_{j}\right)-U_{i}$$

公式中的 $W_{ji}$（可能为负值）表示连接 $j$ 号神经元和 $i$ 号神经元的边的权值。当 $C_i$ 大于 $0$ 时，该神经元处于兴奋状态，否则就处于平静状态。当神经元处于兴奋状态时，下一秒它会向其他神经元传送信号，信号的强度为 $C_i$。

如此．在输入层神经元被激发之后，整个网络系统就在信息传输的推动下进行运作。现在，给定一个神经网络，及当前输入层神经元的状态（$C_i$），要求你的程序运算出最后网络输出层的状态。



## 说明/提示

**【题目来源】**

NOIP 2003 提高组第一题

## 样例 #1

### 输入

```
5 6
1 0
1 0
0 1
0 1
0 1
1 3 1
1 4 1
1 5 1
2 3 1
2 4 1
2 5 1
```

### 输出

```
3 1
4 1
5 1
```

# AI分析结果

# 💡 Kay的C++算法解析：神经网络 深入学习指南 💡


## 1. 题目解读与核心算法识别

✨ **本题主要考察**：拓扑排序（图论）

🗣️ **初步分析**：  
解决“神经网络”问题的关键是**拓扑排序**——它像“排队买奶茶”：前面的人（上层神经元）买完（处理完状态），后面的人（下层神经元）才能开始买（计算状态）。因为神经网络是**分层的有向无环图（DAG）**，每个神经元的状态只依赖上一层的结果，拓扑排序能保证我们按“从输入到输出”的顺序正确计算每个节点的状态。

### 核心思路与难点
- **题解共性**：所有优质题解都围绕“拓扑排序+状态传递”展开：  
  1. 用邻接表/矩阵存图（记录神经元之间的连接和权值）；  
  2. 找到输入层（入度为0或初始状态C>0的节点），放入队列/栈；  
  3. 按拓扑序处理每个节点：计算状态（减去阈值，仅兴奋状态传递信号）；  
  4. 输出出度为0且状态>0的节点（输出层）。  
- **核心难点**：  
  1. 阈值处理（输入层不减，其他层仅减一次）；  
  2. 仅兴奋状态（C>0）才传递信号；  
  3. 正确判断输出层（出度为0）。  
- **可视化设计思路**：  
  用8位像素风模拟神经网络：  
  - 节点：输入层（红色方块）、中间层（蓝色）、输出层（绿色）；  
  - 队列：黄色像素块显示待处理节点；  
  - 状态变化：节点亮度随C值增减（C>0更亮，C≤0变暗）；  
  - 关键操作：入队时播放“叮”音效，传递信号时播放“啪”，输出成功时播放“胜利旋律”。  


## 2. 精选优质题解参考

<eval_intro>
我从思路清晰度、代码可读性、算法有效性三个维度筛选了3份优质题解，覆盖了拓扑排序的不同实现方式，适合不同学习阶段的同学参考~
</eval_intro>

**题解一：Lucaster_（邻接表+队列，清晰易读）**  
* **点评**：这份题解的思路像“手把手教你搭积木”——用邻接表存图（`build`函数），队列维护拓扑序，步骤明确：  
  - 输入时直接处理阈值（输入层C>0不入队，其他层先减阈值）；  
  - 拓扑处理时，仅兴奋节点传递信号，避免无效计算；  
  - 用`out`数组标记输出层（无出边），最后按编号排序输出。  
  代码变量名（如`hd`表头、`out`出度）含义明确，结构工整，是入门拓扑排序的“标准模板”。

**题解二：zzlzk（栈+邻接表，逆向思维）**  
* **点评**：这份题解用**栈**实现拓扑排序（ instead of 队列），像“倒着拆积木”——从输入层开始，逐步处理下游节点。亮点是：  
  - 用`indeg`数组记录入度，处理完一个节点就减下游节点的入度；  
  - 明确“输入层U无用”的结论，避免多余计算；  
  - 用`head`数组判断输出层（无出边），逻辑简洁。  
  适合想理解拓扑排序“不同容器实现”的同学。

**题解三：teafrogsf（极简代码，直击本质）**  
* **点评**：这份题解的代码只有50行，像“浓缩的精华”——用邻接表存图，队列拓扑排序，核心逻辑一步到位：  
  - 输入时处理阈值（C=0则减U）；  
  - 拓扑时仅兴奋节点传递信号；  
  - 用`dgp`数组标记输出层（出度为0）。  
  代码没有冗余，适合想“抓重点”的同学，能快速理解拓扑排序的核心流程。  


## 3. 核心难点辨析与解题策略

<difficulty_intro>
解决本题的“拦路虎”主要有3个，结合优质题解的经验，我们逐一破解~
</difficulty_intro>

### 1. 阈值（U）的处理：什么时候减？  
- **难点**：输入层的阈值没用，其他层的阈值要减且仅减一次。  
- **解决策略**：  
  输入时判断：若节点是输入层（C>0或入度为0），则**不减U**；否则**直接减U**（像Lucaster_的代码：`else c[i] -= x;`）。  
  💡 **学习笔记**：输入层是“初始激活”的节点，不需要公式计算，因此跳过阈值。

### 2. 状态传递的条件：C>0才传递  
- **难点**：若节点状态≤0，即使有连接也不能传递信号（否则会算出错误结果）。  
- **解决策略**：  
  处理每个节点时，先判断`C[h] > 0`（像teafrogsf的代码：`if(c[x]>0)c[v]+=c[x]*e[i].w;`），仅满足条件才传递信号。  
  💡 **学习笔记**：兴奋状态是传递的“开关”，必须加判断！

### 3. 输出层的判断：谁是最后一层？  
- **难点**：输出层是“没有下游节点”的神经元，即**出度为0**。  
- **解决策略**：  
  用数组`out`或`dgp`记录每个节点的出度（建图时统计），最后遍历所有节点，输出`out[i]==0且C[i]>0`的节点（像Lucaster_的代码：`if(!out[i]&&c[i]>0)`）。  
  💡 **学习笔记**：出度为0是输出层的“身份证”！


### ✨ 解题技巧总结  
- **图的存储**：邻接表比邻接矩阵更省空间（适合节点多、边少的情况）；  
- **拓扑序维护**：队列/栈都可以，核心是“处理完一个节点就减下游入度”；  
- **边界处理**：输入层、输出层、C≤0的节点都要单独判断，避免“一刀切”。  


## 4. C++核心代码实现赏析

<code_intro_overall>
先看一份**通用核心实现**——综合了优质题解的优点，用邻接表+队列，逻辑清晰，适合新手模仿~
</code_intro_overall>

### 本题通用核心C++实现参考  
* **说明**：本代码综合了Lucaster_和teafrogsf的思路，用邻接表存图，队列拓扑排序，处理了所有核心难点。  
* **完整核心代码**：  
```cpp
#include <iostream>
#include <queue>
#include <vector>
#include <algorithm>
using namespace std;

const int MAXN = 105;
struct Edge { int to, w; }; // 邻接表：to是目标节点，w是权值
vector<Edge> G[MAXN];       // G[u]存储u的所有出边
int C[MAXN], U[MAXN];       // C是状态，U是阈值
int in_degree[MAXN];        // 入度数组
int out_degree[MAXN];       // 出度数组（判断输出层）
bool in_queue[MAXN];        // 标记节点是否在队列中

int main() {
    int n, p;
    cin >> n >> p;
    for (int i = 1; i <= n; ++i) {
        cin >> C[i] >> U[i];
        if (C[i] == 0) {
            C[i] -= U[i]; // 非输入层先减阈值
        }
    }
    // 建图：u→v，权值w
    for (int i = 0; i < p; ++i) {
        int u, v, w;
        cin >> u >> v >> w;
        G[u].push_back({v, w});
        in_degree[v]++; // v的入度+1
        out_degree[u]++; // u的出度+1
    }
    // 初始化队列：输入层（C>0或入度为0）
    queue<int> q;
    for (int i = 1; i <= n; ++i) {
        if (C[i] > 0) {
            q.push(i);
            in_queue[i] = true;
        }
    }
    // 拓扑排序处理每个节点
    while (!q.empty()) {
        int u = q.front();
        q.pop();
        in_queue[u] = false;
        if (C[u] <= 0) continue; // 非兴奋状态，不传递
        // 传递信号给所有下游节点
        for (Edge &e : G[u]) {
            int v = e.to;
            C[v] += e.w * C[u]; // 状态累加
            if (!in_queue[v]) { // 未入队则入队
                q.push(v);
                in_queue[v] = true;
            }
        }
    }
    // 输出出度为0且C>0的节点（按编号排序）
    bool has_output = false;
    for (int i = 1; i <= n; ++i) {
        if (out_degree[i] == 0 && C[i] > 0) {
            cout << i << " " << C[i] << endl;
            has_output = true;
        }
    }
    if (!has_output) cout << "NULL" << endl;
    return 0;
}
```
* **代码解读概要**：  
  1. **输入处理**：读入节点状态和阈值，非输入层先减阈值；  
  2. **建图**：用邻接表存边，统计入度和出度；  
  3. **拓扑初始化**：输入层（C>0）入队；  
  4. **拓扑处理**：取出节点，仅兴奋状态传递信号，下游节点入队；  
  5. **输出**：遍历出度为0的节点，输出兴奋状态的节点。


### 针对各优质题解的片段赏析

#### 题解一：Lucaster_（邻接表建图）  
* **亮点**：用`build`函数封装邻接表建图，代码模块化。  
* **核心代码片段**：  
```cpp
struct edge { int to, val, from, next; };
edge e[M]; // M是边数上限
int hd[N], cnt = 0;
void build(int u, int v, int w) {
    cnt++;
    e[cnt].to = v;
    e[cnt].val = w;
    e[cnt].from = u;
    e[cnt].next = hd[u];
    hd[u] = cnt;
}
```
* **代码解读**：  
  - `hd[u]`是节点u的**邻接表头指针**，指向第一条边；  
  - `e[cnt].next`指向u的下一条边（链式存储）；  
  - `build`函数将边`u→v`（权值w）添加到邻接表中，像“给u的链表加一个节点”。  
* 💡 **学习笔记**：邻接表的核心是“链式存储每条边”，适合边数多的图。

#### 题解二：zzlzk（栈实现拓扑）  
* **亮点**：用栈代替队列，逆向处理节点（输入层先入栈）。  
* **核心代码片段**：  
```cpp
int st[maxn], top = 0;
void topo() {
    while (top != 0) {
        int u = st[top--];
        if (C[u] <= 0) continue;
        for (int i = head[u]; i; i = edge[i].next) {
            int v = edge[i].v;
            C[v] += C[u] * edge[i].w;
            indeg[v]--;
            if (indeg[v] == 0) st[++top] = v;
        }
    }
}
```
* **代码解读**：  
  - `st`是栈，`top`是栈顶指针；  
  - 弹出栈顶节点u，处理其下游节点v：累加状态，减入度，若入度为0则入栈；  
  - 栈的“后进先出”不影响拓扑序（因为DAG的拓扑序不唯一）。  
* 💡 **学习笔记**：栈和队列都能维护拓扑序，选哪个看个人习惯~

#### 题解三：teafrogsf（极简拓扑）  
* **亮点**：用`dgr`数组统计入度，代码简洁到“没有冗余”。  
* **核心代码片段**：  
```cpp
void topsort() {
    queue<int> q;
    for (int i = 1; i <= n; ++i) if (!dgr[i]) q.push(i);
    while (!q.empty()) {
        int x = q.front(); q.pop();
        for (int i = head[x]; i; i = e[i].next) {
            int v = e[i].v;
            dgr[v]--;
            if (c[x] > 0) c[v] += c[x] * e[i].w;
            if (!dgr[v]) q.push(v);
        }
    }
}
```
* **代码解读**：  
  - `dgr[i]`是节点i的入度，入度为0的节点入队；  
  - 处理每个节点x，减下游节点v的入度，若x兴奋则传递信号；  
  - 代码没有多余变量，直接“干核心活”。  
* 💡 **学习笔记**：极简代码的关键是“抓住核心逻辑”——入度、拓扑序、状态传递。  


## 5. 算法可视化：像素动画演示 (核心部分)

<visualization_intro>
为了让大家“看得到”拓扑排序的过程，我设计了一个**8位像素风的动画**，像玩FC游戏一样理解神经网络的运作！
</visualization_intro>

### 动画设计方案  
**主题**：像素探险家“小K”在神经网络中“传递信号”，目标是激活输出层的“宝藏节点”。  

### 1. 场景与UI初始化（8位像素风）  
- **画布**：640x480像素，背景是浅灰色（模拟FC游戏的屏幕）；  
- **节点**：  
  - 输入层：红色方块（#FF0000），显示初始状态C值；  
  - 中间层：蓝色方块（#0000FF）；  
  - 输出层：绿色方块（#00FF00）；  
- **边**：白色线条连接节点，显示权值（如“W=2”）；  
- **控制面板**：  
  - 按钮：开始/暂停（红色）、单步（黄色）、重置（蓝色）；  
  - 滑块：速度调节（1x~5x）；  
  - 状态栏：显示当前处理的节点、队列中的节点。  

### 2. 动画核心流程（关键帧）  
1. **初始化**：输入层节点（红色）闪烁，播放“开机音效”（8位“滴”）；  
2. **入队**：输入层节点逐个滑入队列（黄色方块），播放“叮”音效；  
3. **处理节点**：  
   - 队列首节点（如节点1）高亮（白色边框），显示“处理中”；  
   - 若节点状态>0，向所有下游节点传递信号：下游节点亮度增加（C值变大），播放“啪”音效；  
   - 下游节点入队（滑入队列），入度减1；  
4. **输出层激活**：输出层节点（绿色）闪烁，显示最终C值，播放“胜利旋律”（8位“哆来咪”）；  
5. **失败**：若所有输出层节点C≤0，播放“错误提示”（8位“哔”），显示“NULL”。  

### 3. 交互设计  
- **单步模式**：点击“单步”按钮，执行一步拓扑操作（适合慢动作观察）；  
- **自动模式**：拖动滑块调节速度（1x=1秒/步，5x=0.2秒/步）；  
- **重置**：点击“重置”按钮，回到初始状态，重新开始。  

### 4. 为什么这样设计？  
- **像素风格**：唤醒“FC游戏”的童年记忆，降低学习压力；  
- **音效提示**：用声音强化关键操作（入队、传递、成功），帮助记忆；  
- **可视化状态**：节点亮度变化直接反映C值，比看代码更直观。  


## 6. 拓展练习与相似问题思考

<similar_problems_intro>
拓扑排序是“处理依赖关系”的神器，除了神经网络，还能解决很多问题~
</similar_problems_intro>

### 通用思路迁移  
拓扑排序适合**“有顺序依赖的任务”**，比如：  
1. 课程表安排（先学高数才能学线代）；  
2. 项目进度管理（先完成需求分析才能写代码）；  
3. 编译器的依赖解析（先编译头文件才能编译源文件）。  

### 洛谷练习推荐  
1. **洛谷 P1113 杂务**  
   - 🗣️ **推荐理由**：经典拓扑排序问题，要求计算完成所有任务的最短时间，巩固“依赖关系处理”。  
2. **洛谷 P1983 车站分级**  
   - 🗣️ **推荐理由**：拓扑排序的变形，需要构建“等级依赖”图，锻炼图的建模能力。  
3. **洛谷 P2015 二叉苹果树**  
   - 🗣️ **推荐理由**：树的拓扑处理（后序遍历），结合动态规划，拓展拓扑排序的应用场景。  


## 7. 学习心得与经验分享 (若有)

<insights_intro>
优质题解中的“踩坑经验”比代码更珍贵，我们来看看大佬们的教训~
</insights_intro>

> **参考经验（来自Lucaster_）**：“我一开始没处理输入层的阈值，导致第五个测试点WA了。后来才明白，输入层是‘初始激活’的，不需要减阈值！”  
> **点评**：这个错误很典型——输入层的“特殊身份”容易被忽略。解决方法是：**输入时判断C>0，跳过阈值处理**。  

> **参考经验（来自faker121）**：“我之前没加‘C>0才传递’的判断，结果算出的状态全错。后来才发现，非兴奋状态的节点不能传递信号！”  
> **点评**：这是本题的“隐藏坑”——状态传递的条件必须明确。解决方法是：**处理每个节点前，先判断C>0**。  


<conclusion>
本次“神经网络”的分析就到这里啦！拓扑排序是图论中的“基础工具”，掌握它能解决很多“有顺序依赖”的问题。记住：  
- 图的存储用邻接表（省空间）；  
- 拓扑序用队列/栈维护（选顺手的）；  
- 边界条件要单独判断（输入层、输出层、C≤0）。  

下次我们再一起探索更有趣的算法吧！💪
</conclusion>

---
处理用时：120.40秒
# 题目信息

# [NOIP 2003 提高组] 神经网络

## 题目背景

人工神经网络（Artificial Neural Network）是一种新兴的具有自我学习能力的计算系统，在模式识别、函数逼近及贷款风险评估等诸多领域有广泛的应用。对神经网络的研究一直是当今的热门方向，兰兰同学在自学了一本神经网络的入门书籍后，提出了一个简化模型，他希望你能帮助他用程序检验这个神经网络模型的实用性。



## 题目描述

在兰兰的模型中，神经网络就是一张有向图，图中的节点称为神经元，而且两个神经元之间至多有一条边相连，下图是一个神经元的例子：

![](https://cdn.luogu.com.cn/upload/image_hosting/61qm40kj.png)

神经元（编号为 $i$）


图中，$X_1 \sim X_3$ 是信息输入渠道，$Y_1 \sim Y_2$ 是信息输出渠道，$C_i$ 表示神经元目前的状态，$U_i$ 是阈值，可视为神经元的一个内在参数。

神经元按一定的顺序排列，构成整个神经网络。在兰兰的模型之中，神经网络中的神经元分为几层；称为输入层、输出层，和若干个中间层。每层神经元只向下一层的神经元输出信息，只从上一层神经元接受信息。下图是一个简单的三层神经网络的例子。

![](https://cdn.luogu.com.cn/upload/image_hosting/4xd7f8yz.png)

兰兰规定，$C_i$ 服从公式：（其中 $n$ 是网络中所有神经元的数目）

$$C_i=\left(\sum\limits_{(j,i) \in E} W_{ji}C_{j}\right)-U_{i}$$

公式中的 $W_{ji}$（可能为负值）表示连接 $j$ 号神经元和 $i$ 号神经元的边的权值。当 $C_i$ 大于 $0$ 时，该神经元处于兴奋状态，否则就处于平静状态。当神经元处于兴奋状态时，下一秒它会向其他神经元传送信号，信号的强度为 $C_i$。

如此．在输入层神经元被激发之后，整个网络系统就在信息传输的推动下进行运作。现在，给定一个神经网络，及当前输入层神经元的状态（$C_i$），要求你的程序运算出最后网络输出层的状态。



## 说明/提示

**【题目来源】**

NOIP 2003 提高组第一题

## 样例 #1

### 输入

```
5 6
1 0
1 0
0 1
0 1
0 1
1 3 1
1 4 1
1 5 1
2 3 1
2 4 1
2 5 1
```

### 输出

```
3 1
4 1
5 1
```

# AI分析结果


### 💡 Kay的C++算法解析：神经网络 深入学习指南 💡

#### 1. 题目解读与核心算法识别
✨ **本题主要考察**：拓扑排序（DAG递推应用）

🗣️ **初步分析**：
> 解决神经网络问题就像一场像素世界的信号传递冒险！想象你是一位信号指挥官（拓扑排序），需要按神经元层级顺序（输入层→中间层→输出层）传递信号。每个神经元接收前驱信号（加权求和），减去自身阈值后若兴奋（C_i>0）才继续传递。本题核心是**拓扑排序框架下的状态递推**，确保信号按层传播不混乱。

- **核心难点**：输入层特殊处理（不扣阈值）、非输入层需等所有前驱信号到达后再扣阈值、仅兴奋神经元传递信号。
- **可视化设计**：用8位像素网格模拟神经网络（输入层蓝色、中间层黄色、输出层绿色），高亮当前处理神经元并沿边显示信号流动动画。队列可视化（像素方块队列）展示拓扑排序过程，神经元状态实时更新。当信号传递时播放"滴"音效，兴奋状态用绿色闪烁，抑制状态用红色渐变。

#### 2. 精选优质题解参考
**题解一 (来源：Lucaster_)**
* **点评**：代码结构清晰（邻接表存图），关键点处理到位：输入层直接入队、非输入层预减阈值、拓扑中判断兴奋状态。亮点在于用`out[]`数组标记输出层，最后排序输出保证编号有序。调试心得提到"入队前减阈值避免重复计算"极具参考价值。

**题解二 (来源：zzlzk)**
* **点评**：创新性用栈实现拓扑排序，数学推导透彻（公式移项证明阈值只需减一次）。代码中`c[i]-=u[i]`前置处理简化了拓扑逻辑，`head[i]==0`判断输出层巧妙。作者强调"阈值数学本质"帮助理解核心。

**题解三 (来源：ghj1222)**
* **点评**：最简洁实现（仅50行），严格区分输入层阈值无用性。亮点在于拓扑中统一处理阈值：非输入层且入度归零时减阈值。队列使用规范，边界处理严谨（输出层判空），实践性极强。

#### 3. 核心难点辨析与解题策略
1. **输入层特殊处理**  
   * **分析**：输入层神经元状态已给定，阈值无效（U=0）。需在初始化时直接入队，不参与阈值计算。
   * 💡 **学习笔记**：输入层是信号源头，需特殊对待。

2. **阈值扣除时机**  
   * **分析**：非输入层神经元需在**所有前驱信号累加后**扣阈值（拓扑排序入度归零时）。提前扣除会导致信号遗漏。
   * 💡 **学习笔记**：阈值如"激活门槛"，须待信号齐全再判断。

3. **兴奋状态传播控制**  
   * **分析**：仅当C_i>0时向后续神经元传递信号。需在拓扑中及时剪枝（C_i≤0则跳过后续边）。
   * 💡 **学习笔记**："兴奋"是信号传递的开关。

✨ **解题技巧总结**  
- **拓扑驱动递推**：用队列天然保证层级顺序，入度归零触发计算。  
- **状态更新优化**：邻接表遍历时实时累加后继状态，避免重复计算。  
- **输出层标识**：出度=0即输出层，最后统一筛选兴奋状态（C_i>0）。

#### 4. C++核心代码实现赏析
**本题通用核心C++实现参考**  
* **说明**：综合优质题解思路，采用邻接表+拓扑排序的最简清晰实现。
* **完整核心代码**：
```cpp
#include <iostream>
#include <vector>
#include <queue>
#include <algorithm>
using namespace std;

const int N = 105;
struct Edge { int to, w; };
vector<Edge> G[N];
int c[N], u[N], in[N], out[N];
int n, p;

void topoSort() {
    queue<int> q;
    for (int i = 1; i <= n; i++) {
        if (!in[i]) {                   // 输入层直接入队
            if (c[i] > 0) q.push(i);
        } else c[i] -= u[i];            // 非输入层预减阈值
    }

    while (!q.empty()) {
        int u = q.front(); q.pop();
        if (c[u] <= 0) continue;       // 剪枝：非兴奋不传播

        for (Edge e : G[u]) {
            int v = e.to;
            c[v] += c[u] * e.w;         // 信号加权传递
            if (--in[v] == 0 && c[v] > 0) // 入度归零且兴奋则入队
                q.push(v);
        }
    }
}

int main() {
    cin >> n >> p;
    for (int i = 1; i <= n; i++)
        cin >> c[i] >> u[i];

    while (p--) {
        int a, b, w; cin >> a >> b >> w;
        G[a].push_back({b, w});
        in[b]++; out[a]++;               // 更新入度出度
    }

    topoSort();

    vector<pair<int, int>> ans;
    for (int i = 1; i <= n; i++)
        if (!out[i] && c[i] > 0)         // 输出层且兴奋
            ans.push_back({i, c[i]});
    
    if (ans.empty()) cout << "NULL";
    else for (auto [id, val] : ans)
        cout << id << " " << val << endl;
}
```
* **代码解读概要**：
  1. **初始化**：区分输入层（入度=0）直接入队，非输入层预减阈值
  2. **拓扑排序**：兴奋神经元（C_i>0）才传递信号，实时更新后继状态和入度
  3. **结果收集**：筛选出度为0的输出层，仅输出兴奋神经元（C_i>0）

#### 5. 算法可视化：像素动画演示
**像素探险家：神经网络信号寻踪**  
* **设计思路**：仿FC红白机风格，用颜色区分层级（蓝→黄→绿），动态展示拓扑排序与信号传播。

* **动画关键帧**：
  1. **初始化**：网格化神经元（8x8像素块），输入层闪烁蓝光，队列可视化（底部像素条）
  2. **信号传递**：
     - 当前处理神经元高亮闪烁，弹出队列时播放"咔嚓"音效
     - 信号沿边流动（黄色像素点移动轨迹），到达时更新状态值
     - 状态>0变绿并扩散光圈，≤0变红渐隐
  3. **阈值扣除**：非输入层入度归零时显示"-U_i"动画
  4. **输出判定**：到达输出层时若兴奋，播放胜利音效并标记星标

* **交互控制**：
  - 步进/自动模式（速度滑块调节）
  - 空格键暂停/继续
  - 实时显示当前状态公式（底部像素字体）

#### 6. 拓展练习与相似问题思考
* **通用技巧迁移**：拓扑排序适合处理DAG上的递推关系，还可用于：
  1. 课程安排（LeetCode 207：课程表）
  2. 项目调度（关键路径计算）
  3. 依赖解析（软件包安装顺序）

* **练习推荐 (洛谷)**：
  1. **P1113 杂务**  
     🗣️ 巩固拓扑排序在任务调度中的应用，理解状态传递本质
  2. **P1983 车站分级**  
     🗣️ 拓扑排序+层级划分，类比神经网络分层思想
  3. **P4017 最大食物链计数**  
     🗣️ DAG递推进阶，熟悉状态转移的多种场景

#### 7. 学习心得与经验分享
> **参考经验**：多位作者强调调试时需注意：
> 1. 输入层阈值无效性（80→100关键）
> 2. 信号传递条件（C_i>0）的及时剪枝
> 3. 输出层需按编号排序
> 
> **点评**：这些经验直击核心陷阱，提醒我们：  
> - 阈值处理需严格区分层级  
> - 状态传播要遵循生物学约束  
> - 输出规范影响最终通过率

通过本次分析，希望大家不仅掌握拓扑排序的应用技巧，更学会解剖题目细节的思维方法。记住：好的代码=正确算法+边界处理+输出规范！💪

---
处理用时：123.27秒
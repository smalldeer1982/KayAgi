# 题目信息

# 狩猎（2021 CoE-II D）

## 题目描述

母狮 $\text{Dina}$ 的领地里有固定的 $n$ 个狩猎点，第 $i$ 个狩猎点有 $p_i$ 的概率可以捕捉到猎物，$\text{Dina}$ 的巢穴和 $n$ 个狩猎点相互之间存在若干条直接连接的双向道路。

每天早晨，$\text{Dina}$ 从她的巢穴出发，随机选择一个与巢穴相邻的狩猎点 $u$ 进行一次捕猎，如果她未捕捉到猎物，她会随机选择一个与当前狩猎点 $u$ 相邻的其他狩猎点 $v$ 继续进行一次捕猎，如果在狩猎点 $v$ 仍未捕捉到猎物，$\text{Dina}$ 会按照前述过程继续捕猎。如果在某个狩猎点捕捉到了猎物，$\text{Dina}$ 会立即返回巢穴，结束捕猎。若当前狩猎点 $u$ 与巢穴相邻，而与其他狩猎点不相邻，$\text{Dina}$ 也会选择立即返回巢穴，然后从与巢穴相邻的狩猎点中，随机选择一个狩猎点继续上述捕猎过程。$\text{Dina}$ 在每个狩猎点只进行一次捕猎，然后离开，但后续可能还会回到该狩猎点再次进行捕猎。在本题环境下，如果地点 $u$ 和地点 $v$ 之间有一条直接连接的双向道路，称地点 $u$ 和地点 $v$ **相邻**，否则称地点 $u$ 和地点 $v$ **不相邻**。

令巢穴的编号为 $0$，$n$ 个狩猎点的编号从 $1$ 到 $n$，$\text{Dina}$ 从编号为 $u$ 的地点到达另外一个编号为 $v$ 的地点需要消耗 $h_{u,v}$ 体力和 $t_{u,v}$ 时间。在第 $i$ 个狩猎点每进行一次捕猎，$\text{Dina}$ 会消耗 $h_i$ 体力和 $t_i$ 时间。每当 $\text{Dina}$ 到达某个狩猎点并进行一次捕猎后，她会评估自己的体力消耗和时间花费，如果体力消耗已经达到（或超过）限值 $H$，她就选择立即返回巢穴结束捕猎。如果时间花费已经达到（或超过）限值 $T$，她也会选择立即返回巢穴结束捕猎。$\text{Dina}$ 只有在到达狩猎点并进行一次捕猎后才进行评估，在任何其他时刻均不会进行评估。如果当前位于巢穴，她会在到达巢穴时就进行评估，因为巢穴并无猎物可供捕捉。

需要注意，$\text{Dina}$ 在沿着两个地点间的双向道路移动的过程中并不会评估，因此可能会出现以下情形：到达某个狩猎点且尚未进行捕猎时，$\text{Dina}$ 已消耗的体力或者已花费的时间已经超过限值。在这种情形下，$\text{Dina}$ 仍然会进行一次捕猎，之后再进行评估。

当 $\text{Dina}$ 因为捕猎成功、体力消耗或时间花费达到（或超过）相应限值、当前狩猎点与其他狩猎点不相邻而返回巢穴时，她总会选择一条具有最少时间花费的路径。如果存在多条具有最少时间花费的路径返回巢穴，她会选择其中体力消耗最少的路径。$\text{Dina}$ 在返回巢穴的过程中不会进行捕猎。

将 $\text{Dina}$ 从巢穴出发，因满足以下三个条件之一：

- 捕猎成功
- 体力消耗达到（或超过）限值 $H$
- 时间花费达到（或超过）限值 $T$

返回到达巢穴并结束捕猎的过程称为一次狩猎。给出巢穴和狩猎点之间的道路、每条道路所需要消耗的体力和花费的时间、每个狩猎点进行一次捕猎能够捕获猎物的概率以及所需消耗的体力、花费的时间，试确定 $\text{Dina}$ 完成一次狩猎所消耗体力和花费时间的平均值。

## 说明/提示

**子任务测试采用捆绑方式计分。**

**样例说明**

输入 #1

![](https://cdn.luogu.com.cn/upload/image_hosting/62vbngdn.png)

该输入只包含一个狩猎点，从巢穴到狩猎点 $1$ 之间的道路需要消耗 $2$ 体力和 $3$ 时间，体力的限值为 $10$，时间的限值为 $20$，在狩猎点 $1$ 进行一次捕猎需要消耗 $1$ 体力和 $2$ 时间，在狩猎点 $1$ 捕获猎物的概率为 $1.00$，即一定会捕捉到猎物。容易知道，进行一次狩猎所消耗的体力和花费时间的平均值分别为 $5.0=(2+1+2) \times 100\%$ 和 $8.0=(3+2+3) \times 100\%$。

输入 #2

![](https://cdn.luogu.com.cn/upload/image_hosting/k4q1qkwr.png)

相较于第一组输入，新增了两个狩猎点，但只有狩猎点 $1$ 和狩猎点 $2$ 与巢穴有直接道路相连。三个狩猎点之间无直接道路相连，但狩猎点 $1$ 可以间接通过巢穴与狩猎点 $2$ 连通。从巢穴到狩猎点 $2$ 的道路需要消耗 $4$ 体力和 $5$ 时间，在狩猎点 $2$ 进行一次捕猎需要消耗 $2$ 体力和 $3$ 时间。在狩猎点 $1$ 捕获猎物的概率为 $1.00$，即一定会捕捉到猎物，因此 $\text{Dina}$ 会立即返回巢穴并结束狩猎。在狩猎点 $2$ 捕获猎物的概率为 $0.50$，即有 $50\%$ 的概率会捕捉到猎物，但由于狩猎点 $2$ 没有其他狩猎点与之直接连通，因此不管在狩猎点 $2$ 是否捕获到猎物，$\text{Dina}$ 都会选择立即返回巢穴，在返回巢穴时，已经消耗 $10$ 体力，根据题意，不管 $\text{Dina}$ 是否已经捕捉到了猎物，她都会结束狩猎。由于是随机选择，故在巢穴时选择狩猎点 $1$ 和 $2$ 进行狩猎的概率均为 $50\%$，根据计算可知，进行一次狩猎所消耗的体力和花费时间的平均值分别为 $7.5=(2+1+2) \times 50\%+(4+2+4) \times 50\%$ 和 $10.5=(3+2+3) \times 50\%+(5+3+5) \times 50\%$。

------------

**数据范围**

- Subtask $1$：$n=1$，$10$ 分。
- Subtask $2$：$1 \le n \le 20$，每个狩猎点和其他狩猎点均无直接道路相连，$20$ 分。
- Subtask $3$：无特殊限制，$70$ 分。

对于 $100\%$ 的数据，$1 \le n \le 200$，$1 \le h_i \le 10$，$1 \le t_i \le 10$，$0 \le p_i \le 1$，$1 \le m \le \text{min}(n (n+1) / 2$，$2000$)，$1 \le h_{u,v} \le 20$，$1 \le t_{u,v} \le 20$，$1 \le H \le 200$，$1 \le T \le 200$。

------------

**约定**

- 地点 $u$ 和地点 $v$ 之间至多有一条直接连接的双向道路，两个地点之间的直连双向道路不会重复给出。
- 忽略 $\text{Dina}$ 进行评估所需要的时间。
- 在输入中，表示概率 $p_i$ 的数值是一个具有两位小数的实数。

## 样例 #1

### 输入

```
1
1 2 1.00
1
0 1 2 3
10 20```

### 输出

```
5.0 8.0```

## 样例 #2

### 输入

```
3
1 2 1.00
2 3 0.50
3 4 0.70
2
0 1 2 3
0 2 4 5
10 20```

### 输出

```
7.5 10.5```

# AI分析结果


### 💡 Kay的C++算法解析：狩猎（2021 CoE-II D） 深入学习指南 💡

**引言**  
今天我们将深入分析「狩猎」这道结合图论与概率期望的C++编程题。本指南将帮助你理解随机游走过程中的状态转移设计、概率期望计算和路径优化技巧，并通过像素动画直观展示算法流程。

---

## 1. 题目解读与核心算法识别
✨ **本题主要考察**：概率动态规划（DP） + 图论（最短路径）

🗣️ **初步分析**  
> 本题可形象化为「母狮在像素森林中的随机冒险」：  
> - **核心思想**：将母狮的每次移动视为状态转移，捕猎结果视为概率事件，用三维DP记录位置+体力+时间组合的期望值  
> - **难点**：状态空间庞大（200×200×200），需处理概率分支和路径优化  
> - **解决方案**：  
>   - 预处理各点到巢穴的最优返回路径（Dijkstra算法）  
>   - 记忆化搜索避免重复计算  
>   - 分4类状态转移：捕猎成功/失败超限/失败无路/失败转移  
> - **可视化设计**：  
>   - 用像素网格表示狩猎点，母狮精灵沿路径移动  
>   - 高亮当前状态（位置/体力/时间）和关键操作（捕猎判定/路径选择）  
>   - 加入8-bit音效：捕猎时"拉弓声"，成功时"胜利旋律"，超限时"警报音"

---

## 2. 精选优质题解参考
**题解（来源：metaphysis）**  
* **点评**：  
  思路清晰度 ⭐⭐⭐⭐⭐  
  → 完美分解巢穴/狩猎点行为差异，用DFS+Memo自然实现概率DP  
  代码规范性 ⭐⭐⭐⭐  
  → 变量名`hp`/`elapsed`直指核心，但嵌套稍深可加空行优化  
  算法有效性 ⭐⭐⭐⭐⭐  
  → 预处理返回路径+三维状态覆盖，时空复杂度O(n·H·T)合理  
  实践价值 ⭐⭐⭐⭐⭐  
  → 完整处理边界：体力超限、时间耗尽、孤立狩猎点等特殊情况  

---

## 3. 核心难点辨析与解题策略
1. **状态爆炸的应对**  
   * **分析**：三维状态(u,h,t)组合达8e6量级，需避免重复计算  
   * **解法**：记忆化搜索（`visited`数组）+ 预处理返回路径降低转移复杂度  
   * 💡 **学习笔记**："空间换时间"是DP优化的核心思想  

2. **概率分支的数学建模**  
   * **分析**：捕猎成功(p)直接返回，失败(1-p)衍生3种子状态  
   * **解法**：期望值 = Σ(概率×子状态期望)，用DFS递归自然表达  
   * 💡 **学习笔记**：概率DP本质是带权重的状态转移图  

3. **路径优化的预处理**  
   * **分析**：返回巢穴需时间最短+体力最省的双重优化  
   * **解法**：改造Dijkstra（优先队列），双关键字排序  
   * 💡 **学习笔记**：图论预处理能为复杂逻辑提供"快捷查询表"  

### ✨ 解题技巧总结
- **状态压缩法**：用三维数组表示位置+资源组合  
- **记忆化递归**：DFS+Memo代替迭代DP，避免转移顺序问题  
- **双关键字优化**：图算法中主次优化目标的处理范式  
- **边界防御编程**：显式检查H/T超限，避免无效状态扩展  

---

## 4. C++核心代码实现赏析
**本题通用核心C++实现参考**  
* **说明**：综合题解思路，精简变量命名并增加注释  
```cpp
#include <bits/stdc++.h>
using namespace std;
const int MAX = 210, INF = 0x7f7f7f7f;

struct Edge { int to, h, t; }; // 路径数据结构
vector<Edge> G[MAX];         // 邻接表
double p[MAX], dp_h[MAX][260][260], dp_t[MAX][260][260]; // 三维DP状态
int vis[MAX][260][260], neighbors[MAX], cost_h[MAX], cost_t[MAX]; 
int n, H_lim, T_lim; // 狩猎点数, 体力/时间上限

void precompute_path() { /* 见完整版: Dijkstra求返巢最优路径 */ }

void dfs(int u, int ch, int ct) { // 记忆化搜索核心
    if (vis[u][ch][ct]) return;
    vis[u][ch][ct] = 1;
    // 分巢穴/狩猎点四类情况处理（详见下文分段解析）
}
```

**分段解析**  
```cpp
// 狩猎点行为决策
if (u != 0) { 
    // 1. 捕猎成功: 直接返巢
    dp_h[u][ch][ct] += p[u] * (ch + cost_h[u]); 
    // 2. 捕猎失败但超限: 强制返巢
    if (ch >= H_lim || ct >= T_lim) { ... }
    // 3. 无相邻点: 只能返巢
    else if (neighbors[u] == 0) { ... }
    // 4. 有相邻点: 随机转移
    else for (auto &e : G[u]) 
        dfs(e.to, ch + e.h + cost_h[e.to], ct + ...);
}
// 巢穴行为决策
else { 
    if (ch >= H_lim || ct >= T_lim) // 超限终止
        dp_h[0][ch][ct] = ch; 
    else for (auto &e : G[0])  // 选择新起点
        dfs(e.to, ch + e.h + ..., ct + ...);
}
```
* 💡 **学习笔记**：状态转移树是概率DP的骨架，需严谨覆盖所有分支  

---

## 5. 算法可视化：像素动画演示  
**主题**：8-bit狮王冒险记（复古RPG风格）  

**核心演示**  
1. **场景构建**  
   - 巢穴为蓝色城堡，狩猎点为绿色树屋  
   - 道路为棕色像素线，体力/时间条在顶部显示  

2. **关键帧流程**  
   ```mermaid
   graph LR
   A[巢穴出发] --> B{选择路径}
   B -->|随机| C[狩猎点]
   C --> D{捕猎判定}
   D -->|成功| E[返巢: 金色路径]
   D -->|失败| F{超限?}
   F -->|是| G[返巢: 红色警报]
   F -->|否| H{有相邻点?}
   H -->|无| I[返巢: 灰色路径]
   H -->|有| J[随机新目标]
   ```

3. **交互设计**  
   - **音效系统**：  
     - 移动："脚步声"8-bit音效  
     - 捕猎成功：上升音阶  
     - 超限：低沉警报声  
   - **控制面板**：  
     - 速度滑块：调节自动演示速度  
     - 单步按钮：逐步观察状态转移  
     - 路径高亮：当前选择路径闪烁绿色  

4. **动态教学**  
   - 旁白提示框："正在计算狩猎点3的期望值..."  
   - 数据结构可视化：右侧显示dp_h[u][h][t]数值变化  

---

## 6. 拓展练习与相似问题思考
**技巧迁移场景**  
1. 游戏AI决策：随机事件+资源消耗的期望计算  
2. 网络路由优化：概率丢包下的最短路径期望  
3. 风险管理模型：超限阈值触发机制  

**洛谷练习推荐**  
1. **P1850 换教室**  
   → 同类技巧：概率DP+图论路径优化  
2. **P2473 奖励关**  
   → 强化：状态压缩+期望值计算  
3. **P4548 随机游走**  
   → 基础：随机过程期望值训练  

---

## 7. 学习心得与经验分享  
> **参考经验**  
> "调试时发现未预处理返回路径会导致30%超时，优化后效率提升5倍"  
>  
> **Kay点评**  
> 预处理是复杂DP的常见优化手段，类似"预先准备工具包"，建议：  
> 1. 对图论问题先独立验证路径计算正确性  
> 2. 使用`constexpr`定义状态上限避免溢出  

---

**结语**  
通过「状态空间分解+概率转移+路径优化」的组合拳，这类随机过程问题便迎刃而解。记住：好算法是计算出来的，更是设计出来的！下次冒险再见！ 🦁✨

---
处理用时：195.93秒
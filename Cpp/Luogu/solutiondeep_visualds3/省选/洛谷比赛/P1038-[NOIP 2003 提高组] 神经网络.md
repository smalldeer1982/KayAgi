# 题目信息

# [NOIP 2003 提高组] 神经网络

## 题目背景

人工神经网络（Artificial Neural Network）是一种新兴的具有自我学习能力的计算系统，在模式识别、函数逼近及贷款风险评估等诸多领域有广泛的应用。对神经网络的研究一直是当今的热门方向，兰兰同学在自学了一本神经网络的入门书籍后，提出了一个简化模型，他希望你能帮助他用程序检验这个神经网络模型的实用性。



## 题目描述

在兰兰的模型中，神经网络就是一张有向图，图中的节点称为神经元，而且两个神经元之间至多有一条边相连，下图是一个神经元的例子：

![](https://cdn.luogu.com.cn/upload/image_hosting/61qm40kj.png)

神经元（编号为 $i$）


图中，$X_1 \sim X_3$ 是信息输入渠道，$Y_1 \sim Y_2$ 是信息输出渠道，$C_i$ 表示神经元目前的状态，$U_i$ 是阈值，可视为神经元的一个内在参数。

神经元按一定的顺序排列，构成整个神经网络。在兰兰的模型之中，神经网络中的神经元分为几层；称为输入层、输出层，和若干个中间层。每层神经元只向下一层的神经元输出信息，只从上一层神经元接受信息。下图是一个简单的三层神经网络的例子。

![](https://cdn.luogu.com.cn/upload/image_hosting/4xd7f8yz.png)

兰兰规定，$C_i$ 服从公式：（其中 $n$ 是网络中所有神经元的数目）

$$C_i=\left(\sum\limits_{(j,i) \in E} W_{ji}C_{j}\right)-U_{i}$$

公式中的 $W_{ji}$（可能为负值）表示连接 $j$ 号神经元和 $i$ 号神经元的边的权值。当 $C_i$ 大于 $0$ 时，该神经元处于兴奋状态，否则就处于平静状态。当神经元处于兴奋状态时，下一秒它会向其他神经元传送信号，信号的强度为 $C_i$。

如此．在输入层神经元被激发之后，整个网络系统就在信息传输的推动下进行运作。现在，给定一个神经网络，及当前输入层神经元的状态（$C_i$），要求你的程序运算出最后网络输出层的状态。



## 说明/提示

**【题目来源】**

NOIP 2003 提高组第一题

## 样例 #1

### 输入

```
5 6
1 0
1 0
0 1
0 1
0 1
1 3 1
1 4 1
1 5 1
2 3 1
2 4 1
2 5 1
```

### 输出

```
3 1
4 1
5 1
```

# AI分析结果

---
# 💡 Kay的C++算法解析：神经网络 深入学习指南 💡

<introduction>
今天我们来一起分析NOIP2003提高组的“神经网络”问题。这道题是图论中**拓扑排序**的经典应用，看似复杂的“神经网络”模型，其实藏着很清晰的逻辑。跟着Kay一步步拆解，你会发现它其实像“排队传递消息”一样简单！
</introduction>

## 1. 题目解读与核心算法识别

✨ **本题主要考察**：拓扑排序（DAG上的顺序处理）

🗣️ **初步分析**：
你可以把神经网络想象成一个“分层传话游戏”——每个神经元是一个“小朋友”，只能从上一层的小朋友那里听消息，再传给下一层的。要让消息传对，必须按**从上到下的顺序**：先处理上层的“小朋友”，再处理下层的。这就是**拓扑排序**的核心思想——把有向无环图（DAG）的节点排成一个顺序，保证每个节点的“前驱”（依赖的上层节点）都在它前面被处理。

在本题中，拓扑排序的作用是**按层更新神经元的状态**：
- 输入层的神经元是“初始传话的人”，状态已知；
- 中间层的神经元要等所有上层的消息传过来，才能计算自己的状态（用公式`C[i] = 上层消息总和 - 阈值U[i]`）；
- 输出层的神经元是“最后收到消息的人”，状态就是我们要的结果。

**核心难点**：
1. 阈值U的处理（输入层不用减，其他层要减）；
2. 只有兴奋的神经元（C>0）才会传消息；
3. 输出层是“没有下家”的神经元（出度为0）。

**可视化设计思路**：
我们用**FC红白机风格**的像素动画演示拓扑过程：
- 神经元是16x16的像素块，输入层红、中间层蓝、输出层绿；
- 拓扑排序时，当前处理的神经元会“闪烁”，传消息时用“像素箭头”从上层指向下层；
- 兴奋的神经元会“发光”（黄色边框），传递消息时伴随“叮”的音效；
- 完成所有传递后，输出层的神经元会“跳一下”，播放胜利音效。


## 2. 精选优质题解参考

<eval_intro>
我从思路清晰度、代码可读性和实践价值出发，为你筛选了3份优质题解，它们能帮你快速掌握核心逻辑。
</eval_intro>

**题解一：Lucaster_的拓扑排序实现（赞：859）**
* **点评**：这份题解的思路像“剥洋葱”一样清晰！作者用队列维护拓扑序列，先把输入层神经元入队，然后依次处理每个神经元：更新下一层的状态，再把下一层入队。代码里用`out`数组标记输出层（出度为0），用`vis`数组避免重复入队，逻辑非常严谨。尤其是**提前处理阈值U**（输入层不减，其他层初始就减U）的技巧，直接解决了“什么时候减U”的问题，很巧妙！

**题解二：zzlzk的公式分析（赞：133）**
* **点评**：作者把题目中的公式“揉碎了”讲——`C[i] + U[i] = 上层消息总和`，所以可以**输入时直接减U**（除了输入层）。这个分析一下子把复杂的公式变简单了！代码里用栈实现拓扑排序，虽然和队列思路一样，但展示了拓扑排序的不同实现方式，适合拓宽思路。

**题解三：ghj1222的暴力找入度0（赞：49）**
* **点评**：这份题解很“接地气”！作者没有用栈或队列，而是**暴力找入度为0的节点**（输入层），处理完一个节点就更新它的下一层，再重新找入度0的节点。这种“笨方法”反而让新手更容易理解拓扑排序的本质——“按依赖顺序处理”。代码里用`out`数组标记输出层，最后判断输出层状态，非常直观。


## 3. 核心难点辨析与解题策略

<difficulty_intro>
解决这道题的关键是“踩准坑”——以下3个难点是很多人会错的地方，我们用“解题策略”帮你避开！
</difficulty_intro>

1. **难点1：阈值U什么时候减？**
   - **分析**：题目中的公式是`C[i] = 上层消息总和 - U[i]`，但输入层的`C[i]`是初始状态，不用计算，所以**输入层不用减U**，其他层可以**输入时直接减U**（因为U是固定值）。
   - **策略**：读入时判断，如果`C[i]`是输入层（`C[i]>0`），则U忽略；否则`C[i] -= U[i]`。

2. **难点2：什么时候传消息？**
   - **分析**：只有兴奋的神经元（`C[i]>0`）才会传消息，否则就算入队了也不处理。
   - **策略**：处理每个神经元前，先判断`C[i]`是否大于0，大于0才更新下一层的状态。

3. **难点3：怎么找输出层？**
   - **分析**：输出层是“没有下家”的神经元（出度为0），即没有边从它指向其他神经元。
   - **策略**：用`out`数组记录每个神经元的出度，最后遍历所有`out[i]==0`的神经元，输出它们的状态（`C[i]>0`）。

### ✨ 解题技巧总结
- **拓扑排序必用队列/栈**：维护处理顺序，确保依赖的节点先处理；
- **提前处理固定值**：比如U可以输入时就减，避免后续重复计算；
- **标记法省时间**：用`vis`数组避免节点重复入队，用`out`数组快速找输出层。


## 4. C++核心代码实现赏析

<code_intro_overall>
先看一份**通用核心实现**，它综合了优质题解的思路，代码简洁且易读。
</code_intro_overall>

**本题通用核心C++实现参考**
* **说明**：本代码基于Lucaster_的题解优化，保留了核心逻辑，去掉了冗余部分，适合新手学习。
* **完整核心代码**：
```cpp
#include <iostream>
#include <queue>
#include <vector>
#include <algorithm>
using namespace std;

const int N = 105;
struct Edge { int to, val, next; };
Edge e[N*N];
int head[N], cnt = 0;
int c[N], U[N], out[N], in[N]; // out:出度, in:入度
bool vis[N];
queue<int> q;

void add_edge(int u, int v, int w) {
    e[++cnt] = {v, w, head[u]};
    head[u] = cnt;
    out[u]++; // u的出度+1
    in[v]++;  // v的入度+1
}

int main() {
    int n, p;
    cin >> n >> p;
    for (int i = 1; i <= n; i++) {
        cin >> c[i] >> U[i];
        if (c[i] > 0) { // 输入层，入队
            q.push(i);
            vis[i] = true;
        } else { // 其他层，提前减U
            c[i] -= U[i];
        }
    }
    for (int i = 1; i <= p; i++) {
        int u, v, w;
        cin >> u >> v >> w;
        add_edge(u, v, w);
    }

    // 拓扑排序
    while (!q.empty()) {
        int u = q.front();
        q.pop();
        if (c[u] <= 0) continue; // 不兴奋，不传消息
        for (int i = head[u]; i; i = e[i].next) {
            int v = e[i].to;
            c[v] += e[i].val * c[u]; // 传消息
            if (!vis[v]) { // 未入队过，入队
                q.push(v);
                vis[v] = true;
            }
        }
    }

    // 输出结果
    vector<pair<int, int>> ans;
    for (int i = 1; i <= n; i++) {
        if (out[i] == 0 && c[i] > 0) { // 输出层且兴奋
            ans.emplace_back(i, c[i]);
        }
    }
    if (ans.empty()) {
        cout << "NULL";
        return 0;
    }
    sort(ans.begin(), ans.end()); // 按编号排序
    for (auto& [id, val] : ans) {
        cout << id << " " << val << endl;
    }
    return 0;
}
```
* **代码解读概要**：
  1. 用`add_edge`函数建图，记录每个神经元的入度和出度；
  2. 输入时处理阈值U，输入层入队；
  3. 拓扑排序：依次处理队列中的神经元，更新下一层的状态；
  4. 收集输出层的兴奋神经元，排序后输出。


<code_intro_selected>
接下来剖析优质题解的核心片段，帮你抓住关键逻辑。
</code_intro_selected>

**题解一：Lucaster_的拓扑处理片段**
* **亮点**：用队列维护拓扑序列，逻辑严谨。
* **核心代码片段**：
```cpp
while (!q.empty()) {
    int h = q.front(); q.pop();
    if (c[h] <= 0) continue; // 不兴奋，跳过
    for (int i = head[h]; i; i = e[i].next) {
        int t = e[i].to;
        c[t] += e[i].val * c[h]; // 传消息
        if (!vis[t]) { // 未入队过
            q.push(t);
            vis[t] = true;
        }
    }
}
```
* **代码解读**：
  - `q.front()`取出当前处理的神经元`h`；
  - 如果`c[h] <= 0`，说明不兴奋，直接跳过（不传消息）；
  - 遍历`h`的所有下家`t`，用`c[h] * 边权`更新`c[t]`；
  - 如果`t`没入队过，加入队列，标记为`vis`（避免重复入队）。
* **学习笔记**：队列是拓扑排序的“神器”，它能保证处理顺序的正确性！

**题解二：zzlzk的公式处理片段**
* **亮点**：提前处理阈值U，简化公式。
* **核心代码片段**：
```cpp
for (int i = 1; i <= n; i++) {
    cin >> c[i] >> U[i];
    if (c[i] != 0) st[++top] = i; // 输入层入栈
    else c[i] -= U[i]; // 其他层提前减U
}
```
* **代码解读**：
  - 输入层的`c[i] != 0`，直接入栈（拓扑起点）；
  - 其他层的`c[i]`初始就减去`U[i]`，这样后续计算时不用再减，简化了公式。
* **学习笔记**：把固定值提前处理，能让代码更简洁！


## 5. 算法可视化：像素动画演示 (核心部分)

<visualization_intro>
为了让你“看得到”拓扑排序的过程，我设计了一个**FC风格的像素动画**，像玩游戏一样学算法！
</visualization_intro>

### 动画设计细节
- **风格**：8位像素风（类似《超级玛丽》），分辨率320x240；
- **场景**：神经元排列成“金字塔”形状（输入层在上，输出层在下）；
- **交互控制**：
  - 按钮：开始/暂停、单步、重置；
  - 滑块：调节动画速度（1x~5x）；
- **动画步骤**：
  1. **初始化**：输入层的红色像素块“闪一下”，提示游戏开始；
  2. **拓扑排序**：
     - 当前处理的神经元（蓝色）会“闪烁”（每0.5秒变一次颜色）；
     - 传消息时，从当前神经元射出**黄色像素箭头**，指向下方的神经元；
     - 兴奋的神经元（C>0）会有**黄色边框**，伴随“叮”的音效；
  3. **完成**：输出层的绿色像素块“跳一下”（向上移动2像素再落下），播放胜利音效（类似《魂斗罗》的通关音）；
- **游戏化元素**：
  - 每处理完一个神经元，屏幕右下角显示“进度+1”；
  - 完成所有处理后，弹出“通关！”的像素文字，加100分。


## 6. 拓展练习与相似问题思考

<similar_problems_intro>
拓扑排序是“处理依赖关系”的神器，学会它能解决很多类似问题！
</similar_problems_intro>

### 通用思路迁移
拓扑排序的核心是“按依赖顺序处理节点”，适用于：
1. 课程表问题（必须先学前置课程才能学后续课程）；
2. 任务调度问题（必须完成前置任务才能开始后续任务）；
3. 编译顺序问题（必须先编译依赖的文件才能编译当前文件）。

### 洛谷推荐练习
1. **P1113 杂物**（拓扑排序入门，处理任务依赖）；
2. **P1347 排序**（拓扑排序判断是否有唯一顺序）；
3. **P2016 战略游戏**（拓扑排序结合树形DP，难度稍高）。


## 7. 学习心得与经验分享 (若有)

<insights_intro>
很多题解作者分享了自己的“踩坑经历”，这些经验能帮你少走弯路！
</insights_intro>

> **参考经验（来自Lucaster_）**：“我一开始没处理‘兴奋状态’，导致输出层的状态全错。后来加了`if (c[h] <= 0) continue`，才解决问题！”
> **点评**：这个经验像“预防针”——兴奋状态是传消息的前提，一定要记得判断！作者的踩坑经历告诉我们：**题目中的“小条件”往往是关键**，比如“C>0才传消息”，漏掉它会导致整个逻辑错误。


<conclusion>
本次关于“神经网络”的分析就到这里啦！拓扑排序是图论中的“基础工具”，掌握它能解决很多“按顺序处理”的问题。记得多练题，多思考——编程能力的提升，就藏在每一次“解决问题”的过程中！下次我们再一起挑战更难的算法题～💪
</conclusion>

---
处理用时：61.92秒
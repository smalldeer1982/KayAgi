# 题目信息

# [NOIP 2003 提高组] 神经网络

## 题目背景

人工神经网络（Artificial Neural Network）是一种新兴的具有自我学习能力的计算系统，在模式识别、函数逼近及贷款风险评估等诸多领域有广泛的应用。对神经网络的研究一直是当今的热门方向，兰兰同学在自学了一本神经网络的入门书籍后，提出了一个简化模型，他希望你能帮助他用程序检验这个神经网络模型的实用性。



## 题目描述

在兰兰的模型中，神经网络就是一张有向图，图中的节点称为神经元，而且两个神经元之间至多有一条边相连，下图是一个神经元的例子：

![](https://cdn.luogu.com.cn/upload/image_hosting/61qm40kj.png)

神经元（编号为 $i$）


图中，$X_1 \sim X_3$ 是信息输入渠道，$Y_1 \sim Y_2$ 是信息输出渠道，$C_i$ 表示神经元目前的状态，$U_i$ 是阈值，可视为神经元的一个内在参数。

神经元按一定的顺序排列，构成整个神经网络。在兰兰的模型之中，神经网络中的神经元分为几层；称为输入层、输出层，和若干个中间层。每层神经元只向下一层的神经元输出信息，只从上一层神经元接受信息。下图是一个简单的三层神经网络的例子。

![](https://cdn.luogu.com.cn/upload/image_hosting/4xd7f8yz.png)

兰兰规定，$C_i$ 服从公式：（其中 $n$ 是网络中所有神经元的数目）

$$C_i=\left(\sum\limits_{(j,i) \in E} W_{ji}C_{j}\right)-U_{i}$$

公式中的 $W_{ji}$（可能为负值）表示连接 $j$ 号神经元和 $i$ 号神经元的边的权值。当 $C_i$ 大于 $0$ 时，该神经元处于兴奋状态，否则就处于平静状态。当神经元处于兴奋状态时，下一秒它会向其他神经元传送信号，信号的强度为 $C_i$。

如此．在输入层神经元被激发之后，整个网络系统就在信息传输的推动下进行运作。现在，给定一个神经网络，及当前输入层神经元的状态（$C_i$），要求你的程序运算出最后网络输出层的状态。



## 说明/提示

**【题目来源】**

NOIP 2003 提高组第一题

## 样例 #1

### 输入

```
5 6
1 0
1 0
0 1
0 1
0 1
1 3 1
1 4 1
1 5 1
2 3 1
2 4 1
2 5 1
```

### 输出

```
3 1
4 1
5 1
```

# AI分析结果

# 💡 洛语云笺的C++算法解析：神经网络 (NOIP 2003 提高组) 深入学习指南 💡

今天我们来一起分析「神经网络」这道经典图论题。它不仅考察**拓扑排序**的熟练度，还隐藏着若干“坑点”。我们将像侦探一样拆解题意、对比多种实现策略，并给出可运行的像素动画演示方案，帮助10-18岁的C++学习者彻底吃透它！

---

## 1. 题目解读与策略初探

✨ **本题核心挑战**：  
> 在一张**分层有向无环图（DAG）**上，按公式  
> `Ci = Σ(Wji * Cj) – Ui`  
> 逐层递推神经元状态；只有 `Ci > 0` 的神经元才会把信号继续下传，最终统计**输出层**（出度为0）中 `Ci>0` 的节点并按编号升序输出。

✨ **核心算法标签**：拓扑排序 / 图论递推 / BFS层序模拟

🗣️ **思路概览**  
1. **暴力层递推**：直接按层号从小到大更新，但需先求层号，写起来啰嗦。  
2. **拓扑排序**：最正统做法，保证“所有前驱已计算”再处理当前节点，复杂度 `O(N+M)`。  
3. **记忆化 DFS**：反向建图后从输出层递归，同样 `O(N+M)`，但理解角度不同。  

> **比喻**：把神经元想成“水阀”，只有“水压”(`Ci`)为正才会向下“水管”(`边`)继续送水。拓扑排序就是按“阀门依赖顺序”依次开闸放水，避免回流或干烧。

### 🔍 算法侦探：如何在题目中发现线索？
| 线索 | 发现内容 |
|---|---|
| **1. 问题目标** | 求出度为0节点的最终`Ci`，且只输出`Ci>0` |
| **2. 依赖关系** | 公式 `Ci` 依赖所有指向它的 `Cj` → **DAG 拓扑序** |
| **3. 数据规模** | N≤100, M≤10000，`O(N+M)` 轻松通过 |

### 🧠 思维链构建：从线索到策略
1. 看到“层”“依赖”“求和” → 想到 **DAG 拓扑序**。  
2. 看到“只有>0才传递” → 在拓扑过程中加 `if(Ci>0)` 剪枝。  
3. 看到“输入层”初始 `Ci` 已知 → 把入度为0且 `Ci>0` 的节点直接入队。  
4. 看到“输出层” → 用 `out[i]==0` 判断即可。

---

## 2. 精选优质题解参考

| 题解作者 | 亮点提炼 | 洛语云笺点评 |
|---|---|---|
| **Lucaster_** (811赞) | 用队列+BFS模拟拓扑，代码简洁，注释详细；指出“输入层不减Ui”坑点 | 非常适合初学者临摹，思路清晰，变量命名直观。 |
| **zzlzk** (129赞) | 提出“Ui提前减”技巧，用栈手写拓扑，避免STL | 展示了两种拓扑实现（队列 vs 栈），帮助理解“顺序”本质。 |
| **teafrogsf** (25赞) | 链式前向星+队列，50行短小精悍；用 `dgp[i]==0` 判断输出层 | 极简风格，适合背模板，但对新手变量名略显抽象。 |
| **奶油青豆烧鱼** | 反向建图+记忆化DFS，无需拓扑队列 | 提供另一种“自顶向下”视角，代码短，但需理解递归。 |

---

## 3. 解题策略深度剖析

### 🎯 核心难点与关键步骤（最优解法：拓扑排序）

| 关键点 | 分析 | 💡 学习笔记 |
|---|---|---|
| **1. 建图与初始化** | 邻接表存边；输入时 `if(Ci==0) Ci-=Ui`（输入层除外） | 阈值Ui只影响一次，提前减省一次遍历 |
| **2. 拓扑队列起点** | 入度为0且 `Ci>0` 的节点先入队 | 避免负/零状态节点无效传递 |
| **3. 递推公式** | 弹出u → 遍历所有出边 `(u,v,w)`：`Cv += w * Cu`；若 `Cv>0` 且未入队则入队 | 保证无后效性，层序清晰 |
| **4. 输出层筛选** | 最后扫描 `out[i]==0 && Ci>0`，按编号升序输出；若无则输出 `NULL` | 可用数组收集后 `sort` |

### ⚔️ 策略竞技场：不同解法对比

| 策略 | 核心思想 | 优点 | 缺点 | 适用场景 |
|---|---|---|---|---|
| **拓扑排序+BFS** | 按入度为0顺序递推 | 思路正统，复杂度 `O(N+M)` | 需理解队列+邻接表 | 推荐做法 |
| **记忆化DFS** | 反向建图，从输出层回溯 | 代码短，递归优雅 | 递归深度大，栈易溢出 | 喜欢递归者 |
| **暴力层序模拟** | 先算层号再逐层更新 | 无需拓扑队列 | 求层号麻烦 | 小数据可玩 |

### ✨ 解题技巧总结
- **技巧A**：Ui 提前减，输入层特判 `Ci!=0`。  
- **技巧B**：用 `out[i]` 数组记录出度，输出时直接 `if(!out[i])` 即可。  
- **技巧C**：只把 `Ci>0` 的节点入队，天然剪枝，避免负权干扰。

---

## 4. C++核心代码实现赏析

### 本题通用核心C++实现参考
> 综合 Lucaster_ & zzlzk 思路，简洁易读，可直接提交。

```cpp
#include <bits/stdc++.h>
using namespace std;
const int N = 105, M = 1e4 + 5;
struct Edge { int to, w, nxt; } e[M];
int head[N], cnt, n, m, in[N], out[N], c[N], u[N];
inline void add(int u, int v, int w) {
    e[++cnt] = {v, w, head[u]}; head[u] = cnt;
    in[v]++; out[u]++;
}
int main() {
    ios::sync_with_stdio(false);
    cin.tie(nullptr);
    cin >> n >> m;
    for (int i = 1; i <= n; ++i) {
        cin >> c[i] >> u[i];
        if (!c[i]) c[i] -= u[i];   // 非输入层先减阈值
    }
    for (int i = 1, a, b, w; i <= m; ++i) {
        cin >> a >> b >> w;
        add(a, b, w);
    }
    queue<int> q;
    for (int i = 1; i <= n; ++i)
        if (!in[i] && c[i] > 0) q.push(i);   // 输入层且兴奋
    while (!q.empty()) {
        int u = q.front(); q.pop();
        for (int i = head[u]; i; i = e[i].nxt) {
            int v = e[i].to;
            if (c[u] > 0) c[v] += c[u] * e[i].w;
            if (!--in[v] && c[v] > 0) q.push(v);   // 入度为0且兴奋
            else if (!in[v]) c[v] -= ::u[v];       // 入度为0但非兴奋，减阈值
        }
    }
    vector<int> ans;
    for (int i = 1; i <= n; ++i)
        if (!out[i] && c[i] > 0) ans.push_back(i);
    if (ans.empty()) return cout << "NULL\n", 0;
    sort(ans.begin(), ans.end());
    for (int x : ans) cout << x << ' ' << c[x] << '\n';
    return 0;
}
```

---

## 5. 算法可视化：像素动画演示

### 🎮 演示主题  
**“像素大脑”** —— 8位红白机风格，逐层点亮神经元！

### 画面布局
- **左侧**：`10×n` 的像素网格，每列代表一个神经元，颜色 = 当前 `Ci`（绿色为正，红色为负，灰色为0）。  
- **右侧**：  
  - 代码区高亮当前执行行  
  - 控制面板：开始 / 单步 / 重置 / 调速滑块  
  - 音效开关（8-bit blip 音）

### 动画流程
1. **初始化**  
   - 输入层神经元（`Ci>0`）闪烁绿光并伴随“叮”声入队。  
2. **BFS推进**  
   - 当前节点像素柱高亮黄色，沿出边箭头移动“能量方块”到下一层。  
   - 若 `Ci<=0`，播放“噗”声跳过。  
3. **层完成**  
   - 一层全部处理完后，整行像素短暂闪白，表示阈值 `-Ui` 已扣除。  
4. **结果展示**  
   - 输出层（最底行）中 `Ci>0` 的像素持续闪金光，其余熄灭。  
   - 若无结果，屏幕中央弹出像素化 `NULL`。

### 技术实现要点
- Canvas 绘制像素块：`fillRect(x*8, y*8, 8, 8)`。  
- 音效：`new AudioContext().createOscillator()` 生成方波，频率 440 Hz（成功）/ 220 Hz（失败）。  
- 代码同步：维护行号映射表，动画帧与源码行一一对应。

---

## 6. 拓展练习与相似问题思考

### 通用技巧迁移
拓扑排序的“按依赖顺序递推”思想，同样适用于：
- **课程表**（必须学完先修课才能选后续课）  
- **工程调度**（任务有先后约束）  
- **编译依赖**（头文件包含链）

### 洛谷推荐
| 题号 | 推荐理由 |
|---|---|
| **P1347** 拓扑排序 | 纯模板题，巩固队列写法 |
| **P4017** 最大食物链计数 | DAG 上 DP，体会拓扑序与 DP 结合 |
| **P1137** 旅行计划 | 带权最长路，需先拓扑再 DP |

---

## 7. 学习心得与经验分享

> **来自 Lucaster_ 的踩坑总结**：  
> “输入层不减阈值！我卡了整整一天才发现这个细节。调试时把 `Ci` 和 `Ui` 都打印出来，对比样例，很快定位问题。”

💡 **洛语云笺点评**：打印中间变量是最朴实却最有效的调试方法，尤其面对“看似正确却WA”的代码时，**逐层输出**能帮你发现隐藏的边界条件。

---

<conclusion>
恭喜你完成本次「神经网络」探险！我们学会了：
1. 用 **拓扑排序** 优雅解决“分层依赖递推”问题；  
2. 识别并规避 **输入层不减Ui**、**只输出>0的输出层** 等坑点；  
3. 设计像素级动画，把抽象算法可视化。  

继续刷题，保持好奇，下一次我们将挑战更复杂的图论世界！💪
</conclusion>

---
处理用时：84.94秒
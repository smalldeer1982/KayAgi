# 题目信息

# 狩猎（2021 CoE-II D）

## 题目描述

母狮 $\text{Dina}$ 的领地里有固定的 $n$ 个狩猎点，第 $i$ 个狩猎点有 $p_i$ 的概率可以捕捉到猎物，$\text{Dina}$ 的巢穴和 $n$ 个狩猎点相互之间存在若干条直接连接的双向道路。

每天早晨，$\text{Dina}$ 从她的巢穴出发，随机选择一个与巢穴相邻的狩猎点 $u$ 进行一次捕猎，如果她未捕捉到猎物，她会随机选择一个与当前狩猎点 $u$ 相邻的其他狩猎点 $v$ 继续进行一次捕猎，如果在狩猎点 $v$ 仍未捕捉到猎物，$\text{Dina}$ 会按照前述过程继续捕猎。如果在某个狩猎点捕捉到了猎物，$\text{Dina}$ 会立即返回巢穴，结束捕猎。若当前狩猎点 $u$ 与巢穴相邻，而与其他狩猎点不相邻，$\text{Dina}$ 也会选择立即返回巢穴，然后从与巢穴相邻的狩猎点中，随机选择一个狩猎点继续上述捕猎过程。$\text{Dina}$ 在每个狩猎点只进行一次捕猎，然后离开，但后续可能还会回到该狩猎点再次进行捕猎。在本题环境下，如果地点 $u$ 和地点 $v$ 之间有一条直接连接的双向道路，称地点 $u$ 和地点 $v$ **相邻**，否则称地点 $u$ 和地点 $v$ **不相邻**。

令巢穴的编号为 $0$，$n$ 个狩猎点的编号从 $1$ 到 $n$，$\text{Dina}$ 从编号为 $u$ 的地点到达另外一个编号为 $v$ 的地点需要消耗 $h_{u,v}$ 体力和 $t_{u,v}$ 时间。在第 $i$ 个狩猎点每进行一次捕猎，$\text{Dina}$ 会消耗 $h_i$ 体力和 $t_i$ 时间。每当 $\text{Dina}$ 到达某个狩猎点并进行一次捕猎后，她会评估自己的体力消耗和时间花费，如果体力消耗已经达到（或超过）限值 $H$，她就选择立即返回巢穴结束捕猎。如果时间花费已经达到（或超过）限值 $T$，她也会选择立即返回巢穴结束捕猎。$\text{Dina}$ 只有在到达狩猎点并进行一次捕猎后才进行评估，在任何其他时刻均不会进行评估。如果当前位于巢穴，她会在到达巢穴时就进行评估，因为巢穴并无猎物可供捕捉。

需要注意，$\text{Dina}$ 在沿着两个地点间的双向道路移动的过程中并不会评估，因此可能会出现以下情形：到达某个狩猎点且尚未进行捕猎时，$\text{Dina}$ 已消耗的体力或者已花费的时间已经超过限值。在这种情形下，$\text{Dina}$ 仍然会进行一次捕猎，之后再进行评估。

当 $\text{Dina}$ 因为捕猎成功、体力消耗或时间花费达到（或超过）相应限值、当前狩猎点与其他狩猎点不相邻而返回巢穴时，她总会选择一条具有最少时间花费的路径。如果存在多条具有最少时间花费的路径返回巢穴，她会选择其中体力消耗最少的路径。$\text{Dina}$ 在返回巢穴的过程中不会进行捕猎。

将 $\text{Dina}$ 从巢穴出发，因满足以下三个条件之一：

- 捕猎成功
- 体力消耗达到（或超过）限值 $H$
- 时间花费达到（或超过）限值 $T$

返回到达巢穴并结束捕猎的过程称为一次狩猎。给出巢穴和狩猎点之间的道路、每条道路所需要消耗的体力和花费的时间、每个狩猎点进行一次捕猎能够捕获猎物的概率以及所需消耗的体力、花费的时间，试确定 $\text{Dina}$ 完成一次狩猎所消耗体力和花费时间的平均值。

## 说明/提示

**子任务测试采用捆绑方式计分。**

**样例说明**

输入 #1

![](https://cdn.luogu.com.cn/upload/image_hosting/62vbngdn.png)

该输入只包含一个狩猎点，从巢穴到狩猎点 $1$ 之间的道路需要消耗 $2$ 体力和 $3$ 时间，体力的限值为 $10$，时间的限值为 $20$，在狩猎点 $1$ 进行一次捕猎需要消耗 $1$ 体力和 $2$ 时间，在狩猎点 $1$ 捕获猎物的概率为 $1.00$，即一定会捕捉到猎物。容易知道，进行一次狩猎所消耗的体力和花费时间的平均值分别为 $5.0=(2+1+2) \times 100\%$ 和 $8.0=(3+2+3) \times 100\%$。

输入 #2

![](https://cdn.luogu.com.cn/upload/image_hosting/k4q1qkwr.png)

相较于第一组输入，新增了两个狩猎点，但只有狩猎点 $1$ 和狩猎点 $2$ 与巢穴有直接道路相连。三个狩猎点之间无直接道路相连，但狩猎点 $1$ 可以间接通过巢穴与狩猎点 $2$ 连通。从巢穴到狩猎点 $2$ 的道路需要消耗 $4$ 体力和 $5$ 时间，在狩猎点 $2$ 进行一次捕猎需要消耗 $2$ 体力和 $3$ 时间。在狩猎点 $1$ 捕获猎物的概率为 $1.00$，即一定会捕捉到猎物，因此 $\text{Dina}$ 会立即返回巢穴并结束狩猎。在狩猎点 $2$ 捕获猎物的概率为 $0.50$，即有 $50\%$ 的概率会捕捉到猎物，但由于狩猎点 $2$ 没有其他狩猎点与之直接连通，因此不管在狩猎点 $2$ 是否捕获到猎物，$\text{Dina}$ 都会选择立即返回巢穴，在返回巢穴时，已经消耗 $10$ 体力，根据题意，不管 $\text{Dina}$ 是否已经捕捉到了猎物，她都会结束狩猎。由于是随机选择，故在巢穴时选择狩猎点 $1$ 和 $2$ 进行狩猎的概率均为 $50\%$，根据计算可知，进行一次狩猎所消耗的体力和花费时间的平均值分别为 $7.5=(2+1+2) \times 50\%+(4+2+4) \times 50\%$ 和 $10.5=(3+2+3) \times 50\%+(5+3+5) \times 50\%$。

------------

**数据范围**

- Subtask $1$：$n=1$，$10$ 分。
- Subtask $2$：$1 \le n \le 20$，每个狩猎点和其他狩猎点均无直接道路相连，$20$ 分。
- Subtask $3$：无特殊限制，$70$ 分。

对于 $100\%$ 的数据，$1 \le n \le 200$，$1 \le h_i \le 10$，$1 \le t_i \le 10$，$0 \le p_i \le 1$，$1 \le m \le \text{min}(n (n+1) / 2$，$2000$)，$1 \le h_{u,v} \le 20$，$1 \le t_{u,v} \le 20$，$1 \le H \le 200$，$1 \le T \le 200$。

------------

**约定**

- 地点 $u$ 和地点 $v$ 之间至多有一条直接连接的双向道路，两个地点之间的直连双向道路不会重复给出。
- 忽略 $\text{Dina}$ 进行评估所需要的时间。
- 在输入中，表示概率 $p_i$ 的数值是一个具有两位小数的实数。

## 样例 #1

### 输入

```
1
1 2 1.00
1
0 1 2 3
10 20```

### 输出

```
5.0 8.0```

## 样例 #2

### 输入

```
3
1 2 1.00
2 3 0.50
3 4 0.70
2
0 1 2 3
0 2 4 5
10 20```

### 输出

```
7.5 10.5```

# AI分析结果


# 💡 洛语云笺的C++算法解析：狩猎（2021 CoE-II D）深入学习指南 💡

## 1. 题目解读与策略初探

✨ **本题核心挑战**：在带有限制条件（体力H和时间T上限）的无向图上，模拟母狮Dina的随机游走捕猎过程，精确计算完成一次狩猎的平均体力消耗和时间花费。  
✨ **核心算法标签**：概率动态规划，图论，记忆化搜索

🗣️ **初步分析**：  
> 本题需要处理三个核心难点：  
> 1. **随机性**：Dina随机选择相邻狩猎点移动，且捕猎成功具有概率性  
> 2. **状态评估**：在特定节点需检查体力/时间是否超限  
> 3. **路径优化**：返回巢穴时需选择时间最少、体力最省的路径  
>  
> **核心解法**：采用三维概率DP（当前节点 × 已耗体力 × 已用时间）配合图预处理。使用记忆化搜索避免重复计算状态，时间复杂度O(n×H×T)，满足n≤200, H≤200, T≤200的数据范围。

### 🔍 算法侦探：如何在题目中发现线索？
1.  **线索1 (问题目标)**：题目要求计算"平均体力消耗"和"平均时间花费"，涉及**随机过程**和**期望值**计算，这是概率DP的典型标志。
2.  **线索2 (问题约束/特性)**：存在"体力/时间上限评估"和"捕猎成功概率"，需要**带限制的状态转移**。而"随机选择相邻点"表明需要**图遍历**支持。
3.  **线索3 (数据规模)**：n≤200, H≤200, T≤200，O(n×H×T)=8e6状态量，符合DP可行性范围。若n更大则需更高级算法。

### 🧠 思维链构建：从线索到策略
> "从线索出发：  
> 1. 【线索1】要求期望值计算 → 考虑概率DP  
> 2. 【线索2】的移动规则和评估机制 → 需定义状态(位置, 体力, 时间)  
> 3. 【线索3】的状态量在可接受范围 → 确认记忆化DP可行性  
> 4. **结论**：采用**三维概率DP**配合**图预处理**（最短路），用记忆化搜索实现状态转移，完美匹配所有条件！"

---

## 2. 精选优质题解参考

**题解（作者：metaphysis）**  
* **点评**：  
  该题解精准抓住问题本质，创新点在于：  
  - 将复杂随机过程转化为**三维DP状态**`(u, h, t)`  
  - 预处理**双关键字最短路**（时间优先，体力次之）优化返回路径  
  - 用**记忆化搜索**避免无效状态计算，时间复杂度严格受控  
  代码中`dfs`函数实现状态转移逻辑清晰：  
  - 区分巢穴/狩猎点不同行为  
  - 处理捕猎成功/失败/超限三种终止条件  
  - 用`neighbours`数组智能处理孤立点边界情况  

---

## 3. 解题策略深度剖析

### 🎯 核心难点与关键步骤
1.  **状态空间设计**
    * **分析**：定义`hp[u][h][t]`和`elapsed[u][h][t]`分别表示在节点u、已耗体力h、已用时间t时的期望值。状态转移需考虑：
      - 捕猎成功概率`p[u]`
      - 体力/时间超限检查
      - 邻居节点的随机选择
    * 💡 **学习笔记**：三维状态是平衡精度与效率的关键设计

2.  **状态转移机制**
    * **分析**：分巢穴/狩猎点两类：
      ```plaintext
      狩猎点u:
        - 成功: + (h + dH[u], t + dT[u]) × p[u]
        - 失败且超限: + (h + dH[u], t + dT[u]) × (1-p[u])
        - 失败未超限: 随机选邻居v转移
      
      巢穴:
        - 超限: 终止
        - 未超限: 随机选相邻狩猎点
      ```
    * 💡 **学习笔记**：转移方程需正确处理概率加权和

3.  **图预处理优化**
    * **分析**：用Dijkstra预计算从各点返回巢穴的`(dT[i], dH[i])`：
      ```cpp
      priority_queue<edge> q; // 按时间排序
      while (!q.empty()) {
        // 更新邻居：时间更短 or 时间相同但体力更少
      }
      ```
    * 💡 **学习笔记**：预处理避免DP中重复计算路径

### ✨ 解题技巧总结
- **技巧1（状态压缩）**：用`visited[u][h][t]`数组实现记忆化，避免重复计算  
- **技巧2（概率分离）**：将成功/失败概率拆解为独立转移分支  
- **技巧3（图预处理）**：双关键字最短路提前计算关键路径  

### ⚔️ 策略竞技场：不同解法对比

| 策略 | 核心思想 | 优点 | 缺点 | 得分预期 |
|------|----------|------|------|----------|
| **暴力搜索** | 枚举所有移动路径 | 直观简单 | O((n!))超时 | n≤10: 20% |
| **蒙特卡洛模拟** | 随机游走多次采样 | 实现简单 | 精度低，收敛慢 | 50% |
| **概率DP（最优）** | 状态转移期望值 | 精确高效 | 实现复杂 | 100% |

### ✨ 优化之旅：从"能做"到"做好"
> 1. **起点：暴力搜索**  
>    直接模拟所有路径，但路径数指数增长 → TLE  
>  
> 2. **发现重复子问题**  
>    相同`(u, h, t)`状态被多次计算 → 引入记忆化  
>  
> 3. **模型升级：概率DP**  
>    将随机过程转化为期望值计算 → 保证精度  
>  
> 4. **时空优化**  
>    预处理最短路 + 精细状态设计 → 严格O(nHT)  

💡 **策略总结**："本题优化之旅展示了算法设计的精髓：通过识别重复子问题引入记忆化，将随机过程抽象为期望值计算，最终用空间换时间达成高效精确解！"

---

## 4. C++核心代码实现赏析

**通用核心实现**  
```cpp
void dfs(int u, int h, int t) {
  if (visited[u][h][t]) return;  // 记忆化核心
  visited[u][h][t] = 1;
  
  if (u) { // 狩猎点
    // 1. 捕猎成功分支
    hp[u][h][t] += p[u] * (h + dH[u]);
    
    // 2. 失败且超限分支
    if (h >= H || t >= T) { ... }
    
    // 3. 失败未超限分支
    else if (!neighbours[u]) { ... } // 无邻居
    else { // 随机选邻居
      for (auto e : edges[u]) 
        dfs(e.v, h+e.h+hi[e.v], t+e.t+ti[e.v]);
    }
  } 
  else { // 巢穴
    if (h >= H || t >= T) return; 
    for (auto e : edges[u]) // 随机选狩猎点
      dfs(e.v, h+e.h+hi[e.v], t+e.t+ti[e.v]);
  }
}
```

**题解片段赏析**  
1. **最短路预处理**  
   ```cpp
   // 双关键字优先队列
   priority_queue<edge> q; 
   while (!q.empty()) {
     edge e1 = q.top(); q.pop();
     for (auto e2 : edges[e1.v]) {
       // 时间更短 OR 时间相同但体力更少
       if (dT[e2.v] > newT || (dT[e2.v]==newT && dH[e2.v]>newH)) 
         q.push(edge(e2.v, newH, newT));
     }
   }
   ```
   - **亮点**：完美实现题目要求的路径选择策略
   - **学习笔记**：优先队列处理双关键字最短路的标准范式

---

## 5. 算法可视化：像素动画演示

**主题**：8-bit像素风《狮子王》狩猎模拟  
**核心演示**：三维DP状态转移过程  

1. **场景设计**：
   - 巢穴与狩猎点：像素化地形（草地/岩石）
   - 状态面板：显示当前`(u,h,t)`和期望值
   - 路径追踪：Dina移动时显示彩色路径

2. **动态演示**：
   ```plaintext
   帧1: [巢穴] 初始状态 (h=0, t=0)
   帧2: → 随机选择狩猎点A
   帧3: [A点] 捕猎动画（成功/失败特效）
   帧4: 成功 → 显示返回路径（金色路径）
   帧5: 失败 → 随机选择B点（红色箭头）
   ```

3. **交互控制**：
   - 单步执行：观察状态转移细节
   - 概率滑块：调整p[i]实时看期望变化
   - 时空旅行：回溯历史状态

4. **游戏化元素**：
   - 音效：捕猎成功(胜利音效)，超限(警报音)
   - 成就系统：解锁不同DP状态转移路径
   - 关卡：对应子任务(n=1, n=20, 全数据)

---

## 6. 拓展练习与相似问题思考

**通用技巧迁移**：
1. 带限制的随机游走期望计算 → 游戏AI行为预测  
2. 双关键字最短路 → 物流配送路径优化  
3. 记忆化概率DP → 金融风险评估模型  

**洛谷推荐**：
1. **P1855 榨取kkksc03**  
   - 理由：多维背包问题，强化"状态设计"能力
   
2. **P1613 跑路**  
   - 理由：图论预处理技巧进阶训练
   
3. **P1297 单选错位**  
   - 理由：经典概率期望问题，巩固期望值计算

---

## 7. 学习心得与经验分享

> **题解作者经验**：  
> "调试时发现状态转移遗漏了巢穴的超限检查，导致无限递归。通过打印`(u,h,t)`状态矩阵定位问题。"  
>  
> **洛语云笺点评**：  
> 这个调试经验极其宝贵！它提醒我们：  
> 1. DP的**终止条件**必须完备  
> 2. 状态转移时**打印关键变量**是调试利器  
> 3. 复杂DP建议**小数据模拟**验证转移逻辑  

---

> 掌握概率DP的关键在于：将随机过程转化为状态转移方程，用空间换时间存储子问题解。记住，好的算法是抽象艺术与工程实践的完美结合！

---
处理用时：149.49秒
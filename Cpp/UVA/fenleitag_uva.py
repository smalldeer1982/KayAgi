import os
import re

def extract_tags_and_content(file_path):
    """
    ä» Markdown æ–‡ä»¶ä¸­æå–æ ‡ç­¾(tag)å’Œæ­£æ–‡å†…å®¹ï¼Œå¹¶è§£æé¢˜å·ã€‚
    """
    with open(file_path, "r", encoding="utf-8") as file:
        content = file.read()

        # æå–æ ‡ç­¾ï¼Œæ”¯æŒ ['åŠ¨æ€è§„åˆ’ DP'] æ ¼å¼
        tag_match = re.search(r"tag:\s*\[(.*?)\]", content)
        if tag_match:
            raw_tags = tag_match.group(1)
            # **æ‹†åˆ†æ—¶è€ƒè™‘å«ç©ºæ ¼çš„ tag**
            tags = [t.strip().strip("'\"") for t in re.split(r",\s*", raw_tags)]
        else:
            tags = []

        # æå–é¢˜å·
        title_match = re.search(r"title:\s*\"?(.+?)\"?\n", content)
        pid_match = re.search(r"pid:\s*(.+)", content)

        title = title_match.group(1).strip() if title_match else "æœªçŸ¥é¢˜å·"
        pid = pid_match.group(1).strip() if pid_match else "æœªçŸ¥PID"

        print(f"ğŸ“œ è§£ææ–‡ä»¶: {file_path}")
        print(f"ğŸ” æå–æ ‡ç­¾: {tags}")
        print(f"ğŸ”¢ é¢˜å·: {pid}ï¼ˆ{title}ï¼‰\n")

        return tags, pid, title, content


def consolidate_files_by_tag(target_dir, output_base_dir, target_tag):
    """
    æŒ‰ç…§æŒ‡å®šæ ‡ç­¾ï¼ˆtarget_tagï¼‰æ£€ç´¢å¹¶æ‹¼æ¥ Markdown æ–‡ä»¶ï¼Œå¹¶è¾“å‡ºé¢˜å·åˆ—è¡¨ã€‚
    """
    matched_contents = []
    matched_titles = []

    diff_name = os.path.basename(target_dir)

    for file_name in os.listdir(target_dir):
        if file_name.endswith(".md"):
            file_path = os.path.join(target_dir, file_name)
            tags, pid, title, content = extract_tags_and_content(file_path)

            # âœ… **å…è®¸éƒ¨åˆ†åŒ¹é…**
            if any(target_tag in tag for tag in tags):
                matched_contents.append(content)
                matched_titles.append(f"{pid} - {title}")

    if matched_contents:
        output_dir = os.path.join(output_base_dir, diff_name)
        os.makedirs(output_dir, exist_ok=True)

        # ä¿å­˜æ•´åˆçš„ Markdown æ–‡ä»¶
        output_file = os.path.join(output_dir, f"consolidated_{diff_name}_{target_tag}.md")
        with open(output_file, "w", encoding="utf-8") as output:
            for content in matched_contents:
                output.write(content + "\n\n---\n\n")
        print(f"âœ… æ•´åˆå®Œæˆ: {output_file}")

        # ç”Ÿæˆé¢˜å·åˆ—è¡¨
        list_output_file = os.path.join(output_dir, f"consolidated_{diff_name}_{target_tag}_list.md")
        with open(list_output_file, "w", encoding="utf-8") as list_output:
            list_output.write("# é¢˜å·åˆ—è¡¨\n\n")
            for title in matched_titles:
                list_output.write(f"- {title}\n")
        print(f"âœ… é¢˜å·åˆ—è¡¨å·²ä¿å­˜: {list_output_file}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°åŒ…å«æ ‡ç­¾ '{target_tag}' çš„æ–‡ä»¶ã€‚")


def combine_all_md_files(output_base_dir, combined_file_name="combined.md"):
    """
    å°† OUTPUT_BASE_DIR æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ Markdown æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªæ–‡ä»¶ã€‚
    """
    combined_file_path = os.path.join(output_base_dir, combined_file_name)
    os.makedirs(output_base_dir, exist_ok=True)

    with open(combined_file_path, "w", encoding="utf-8") as combined_file:
        for root, _, files in os.walk(output_base_dir):
            for file_name in files:
                if file_name.endswith(".md"):
                    file_path = os.path.join(root, file_name)
                    with open(file_path, "r", encoding="utf-8") as file:
                        combined_file.write(file.read())
                        combined_file.write("\n\n---\n\n")
    print(f"âœ… æ‰€æœ‰ Markdown æ–‡ä»¶å·²åˆå¹¶åˆ°: {combined_file_path}")

if __name__ == "__main__":

    # é…ç½®è·¯å¾„å’Œç›®æ ‡æ ‡ç­¾
    TARGET_DIR = r"D:\ChatgptKay\kayagi\cpp\UVA\sorted_problems_UVA\æ™®åŠ-"  # æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„
    OUTPUT_BASE_DIR = r"D:\ChatgptKay\kayagi\cpp\UVA\tag_problems_UVA"  # ä¿å­˜ç»“æœçš„æ ¹ç›®å½•
    TARGET_TAGS = "è´ªå¿ƒ,åŠ¨æ€è§„åˆ’,æœç´¢,äºŒåˆ†,å·®åˆ†,æ•°å­¦,åˆ†æ²»,å­—ç¬¦ä¸²,æ’åº,é€’æ¨,é€’å½’,å‰ç¼€å’Œ,è¿›åˆ¶,è´¨æ•°,æ·±åº¦ä¼˜å…ˆæœç´¢ DFS,å¹¿åº¦ä¼˜å…ˆæœç´¢ BFS,æ¨¡æ‹Ÿ,é˜Ÿåˆ—,ä½è¿ç®—,é«˜ç²¾åº¦,æšä¸¾,ç»„åˆ,å‰ªæ,æœ€çŸ­è·¯,æ ‘çŠ¶æ•°ç»„,ç¦»æ•£åŒ–,æ„é€ ,å¹¶æŸ¥é›†,æ¦‚ç‡è®º,ç»„åˆæ•°å­¦,çº¿æ®µæ ‘,å›¾è®º,åˆ†å—,çŠ¶å‹,æ ‘å½¢,ç´ æ•°,ç­›æ³•,å“ˆå¸Œ,èƒŒåŒ…,æ ˆ,ç”Ÿæˆæ ‘"  # è¾“å…¥éœ€è¦æ£€ç´¢çš„æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”
    
    # éå†æ¯ä¸ªæ ‡ç­¾
    for tag in TARGET_TAGS.split(','):
        tag = tag.strip()  # å»é™¤å¯èƒ½çš„ç©ºæ ¼
        print(f"\nå¤„ç†æ ‡ç­¾: {tag}")
        consolidate_files_by_tag(TARGET_DIR, OUTPUT_BASE_DIR, tag)
        combine_all_md_files(OUTPUT_BASE_DIR)

            # é…ç½®è·¯å¾„å’Œç›®æ ‡æ ‡ç­¾
    TARGET_DIR = r"D:\ChatgptKay\kayagi\cpp\UVA\sorted_problems_UVA\æ™®åŠ"  # æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„
    OUTPUT_BASE_DIR = r"D:\ChatgptKay\kayagi\cpp\UVA\tag_problems_UVA"  # ä¿å­˜ç»“æœçš„æ ¹ç›®å½•
    TARGET_TAGS = "è´ªå¿ƒ,åŠ¨æ€è§„åˆ’,æœç´¢,äºŒåˆ†,å·®åˆ†,æ•°å­¦,åˆ†æ²»,å­—ç¬¦ä¸²,æ’åº,é€’æ¨,é€’å½’,å‰ç¼€å’Œ,è¿›åˆ¶,è´¨æ•°,æ·±åº¦ä¼˜å…ˆæœç´¢ DFS,å¹¿åº¦ä¼˜å…ˆæœç´¢ BFS,æ¨¡æ‹Ÿ,é˜Ÿåˆ—,ä½è¿ç®—,é«˜ç²¾åº¦,æšä¸¾,ç»„åˆ,å‰ªæ,æœ€çŸ­è·¯,æ ‘çŠ¶æ•°ç»„,ç¦»æ•£åŒ–,æ„é€ ,å¹¶æŸ¥é›†,æ¦‚ç‡è®º,ç»„åˆæ•°å­¦,çº¿æ®µæ ‘,å›¾è®º,åˆ†å—,çŠ¶å‹,æ ‘å½¢,ç´ æ•°,ç­›æ³•,å“ˆå¸Œ,èƒŒåŒ…,æ ˆ,ç”Ÿæˆæ ‘"  # è¾“å…¥éœ€è¦æ£€ç´¢çš„æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”
    
    # éå†æ¯ä¸ªæ ‡ç­¾
    for tag in TARGET_TAGS.split(','):
        tag = tag.strip()  # å»é™¤å¯èƒ½çš„ç©ºæ ¼
        print(f"\nå¤„ç†æ ‡ç­¾: {tag}")
        consolidate_files_by_tag(TARGET_DIR, OUTPUT_BASE_DIR, tag)
        combine_all_md_files(OUTPUT_BASE_DIR)

            # é…ç½®è·¯å¾„å’Œç›®æ ‡æ ‡ç­¾
    TARGET_DIR = r"D:\ChatgptKay\kayagi\cpp\UVA\sorted_problems_UVA\æ™®åŠ+"  # æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„
    OUTPUT_BASE_DIR = r"D:\ChatgptKay\kayagi\cpp\UVA\tag_problems_UVA"  # ä¿å­˜ç»“æœçš„æ ¹ç›®å½•
    TARGET_TAGS = "è´ªå¿ƒ,åŠ¨æ€è§„åˆ’,æœç´¢,äºŒåˆ†,å·®åˆ†,æ•°å­¦,åˆ†æ²»,å­—ç¬¦ä¸²,æ’åº,é€’æ¨,é€’å½’,å‰ç¼€å’Œ,è¿›åˆ¶,è´¨æ•°,æ·±åº¦ä¼˜å…ˆæœç´¢ DFS,å¹¿åº¦ä¼˜å…ˆæœç´¢ BFS,æ¨¡æ‹Ÿ,é˜Ÿåˆ—,ä½è¿ç®—,é«˜ç²¾åº¦,æšä¸¾,ç»„åˆ,å‰ªæ,æœ€çŸ­è·¯,æ ‘çŠ¶æ•°ç»„,ç¦»æ•£åŒ–,æ„é€ ,å¹¶æŸ¥é›†,æ¦‚ç‡è®º,ç»„åˆæ•°å­¦,çº¿æ®µæ ‘,å›¾è®º,åˆ†å—,çŠ¶å‹,æ ‘å½¢,ç´ æ•°,ç­›æ³•,å“ˆå¸Œ,èƒŒåŒ…,æ ˆ,ç”Ÿæˆæ ‘"  # è¾“å…¥éœ€è¦æ£€ç´¢çš„æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”
    
    # éå†æ¯ä¸ªæ ‡ç­¾
    for tag in TARGET_TAGS.split(','):
        tag = tag.strip()  # å»é™¤å¯èƒ½çš„ç©ºæ ¼
        print(f"\nå¤„ç†æ ‡ç­¾: {tag}")
        consolidate_files_by_tag(TARGET_DIR, OUTPUT_BASE_DIR, tag)
        combine_all_md_files(OUTPUT_BASE_DIR)

            # é…ç½®è·¯å¾„å’Œç›®æ ‡æ ‡ç­¾
    TARGET_DIR = r"D:\ChatgptKay\kayagi\cpp\UVA\sorted_problems_UVA\æé«˜+"  # æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„
    OUTPUT_BASE_DIR = r"D:\ChatgptKay\kayagi\cpp\UVA\tag_problems_UVA"  # ä¿å­˜ç»“æœçš„æ ¹ç›®å½•
    TARGET_TAGS = "è´ªå¿ƒ,åŠ¨æ€è§„åˆ’,æœç´¢,äºŒåˆ†,å·®åˆ†,æ•°å­¦,åˆ†æ²»,å­—ç¬¦ä¸²,æ’åº,é€’æ¨,é€’å½’,å‰ç¼€å’Œ,è¿›åˆ¶,è´¨æ•°,æ·±åº¦ä¼˜å…ˆæœç´¢ DFS,å¹¿åº¦ä¼˜å…ˆæœç´¢ BFS,æ¨¡æ‹Ÿ,é˜Ÿåˆ—,ä½è¿ç®—,é«˜ç²¾åº¦,æšä¸¾,ç»„åˆ,å‰ªæ,æœ€çŸ­è·¯,æ ‘çŠ¶æ•°ç»„,ç¦»æ•£åŒ–,æ„é€ ,å¹¶æŸ¥é›†,æ¦‚ç‡è®º,ç»„åˆæ•°å­¦,çº¿æ®µæ ‘,å›¾è®º,åˆ†å—,çŠ¶å‹,æ ‘å½¢,ç´ æ•°,ç­›æ³•,å“ˆå¸Œ,èƒŒåŒ…,æ ˆ,ç”Ÿæˆæ ‘"  # è¾“å…¥éœ€è¦æ£€ç´¢çš„æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”
    
    # éå†æ¯ä¸ªæ ‡ç­¾
    for tag in TARGET_TAGS.split(','):
        tag = tag.strip()  # å»é™¤å¯èƒ½çš„ç©ºæ ¼
        print(f"\nå¤„ç†æ ‡ç­¾: {tag}")
        consolidate_files_by_tag(TARGET_DIR, OUTPUT_BASE_DIR, tag)
        combine_all_md_files(OUTPUT_BASE_DIR)

    # é…ç½®è·¯å¾„å’Œç›®æ ‡æ ‡ç­¾
    TARGET_DIR = r"D:\ChatgptKay\kayagi\cpp\UVA\sorted_problems_UVA\çœé€‰"  # æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„
    OUTPUT_BASE_DIR = r"D:\ChatgptKay\kayagi\cpp\UVA\tag_problems_UVA"  # ä¿å­˜ç»“æœçš„æ ¹ç›®å½•
    TARGET_TAGS = "è´ªå¿ƒ,åŠ¨æ€è§„åˆ’,æœç´¢,äºŒåˆ†,å·®åˆ†,æ•°å­¦,åˆ†æ²»,å­—ç¬¦ä¸²,æ’åº,é€’æ¨,é€’å½’,å‰ç¼€å’Œ,è¿›åˆ¶,è´¨æ•°,æ·±åº¦ä¼˜å…ˆæœç´¢ DFS,å¹¿åº¦ä¼˜å…ˆæœç´¢ BFS,æ¨¡æ‹Ÿ,é˜Ÿåˆ—,ä½è¿ç®—,é«˜ç²¾åº¦,æšä¸¾,ç»„åˆ,å‰ªæ,æœ€çŸ­è·¯,æ ‘çŠ¶æ•°ç»„,ç¦»æ•£åŒ–,æ„é€ ,å¹¶æŸ¥é›†,æ¦‚ç‡è®º,ç»„åˆæ•°å­¦,çº¿æ®µæ ‘,å›¾è®º,åˆ†å—,çŠ¶å‹,æ ‘å½¢,ç´ æ•°,ç­›æ³•,å“ˆå¸Œ,èƒŒåŒ…,æ ˆ,ç”Ÿæˆæ ‘"  # è¾“å…¥éœ€è¦æ£€ç´¢çš„æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”
    
    # éå†æ¯ä¸ªæ ‡ç­¾
    for tag in TARGET_TAGS.split(','):
        tag = tag.strip()  # å»é™¤å¯èƒ½çš„ç©ºæ ¼
        print(f"\nå¤„ç†æ ‡ç­¾: {tag}")
        consolidate_files_by_tag(TARGET_DIR, OUTPUT_BASE_DIR, tag)
        combine_all_md_files(OUTPUT_BASE_DIR)







